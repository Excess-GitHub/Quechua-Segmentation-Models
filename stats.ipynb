{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c8caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STATS: OUTLIER REMOVAL EXPERIMENT FOR MORPHOLOGY PARSER\n",
    "=======================================================\n",
    "\n",
    "⚠️ EXPERIMENTAL NOTEBOOK ⚠️\n",
    "This notebook is an EXPERIMENTAL analysis to determine whether removing statistical outliers\n",
    "from the training data improves the performance of a BiLSTM+CRF morphology parser.\n",
    "\n",
    "PURPOSE:\n",
    "--------\n",
    "This file tests the hypothesis that removing outliers (words with unusual word-length to\n",
    "morpheme-count relationships) will help the model learn better segmentation patterns.\n",
    "\n",
    "The experiment trains and compares TWO models:\n",
    "  1. Model 1: Trained on FULL dataset (with outliers)\n",
    "  2. Model 2: Trained on FILTERED dataset (outliers removed)\n",
    "  \n",
    "The evaluation then compares both models side-by-side to determine if outlier removal helps.\n",
    "\n",
    "METHODOLOGY:\n",
    "------------\n",
    "1. Statistical Analysis: Analyzes correlation between word length and morpheme count\n",
    "2. Outlier Detection: Uses regression residuals to identify outliers (words where morpheme\n",
    "   count deviates significantly from the expected relationship with word length)\n",
    "3. Model Training: Trains BiLSTM+CRF models on both datasets (with checkpointing)\n",
    "4. Evaluation: Compares both models on test data with comprehensive metrics\n",
    "\n",
    "KEY FEATURES:\n",
    "-------------\n",
    "- BiLSTM+CRF architecture for sequence labeling (boundary prediction)\n",
    "- Statistical outlier detection using regression residuals (Linear, RandomForest, Polynomial)\n",
    "- Model checkpointing to avoid redundant training\n",
    "- Comprehensive evaluation comparing both models side-by-side\n",
    "- Shows difference between model with outlier removal vs. model without\n",
    "\n",
    "IMPORTANT:\n",
    "----------\n",
    "This file is JUST checking if removing outliers helps the model perform better.\n",
    "It is not the main production model - it's an experimental comparison.\n",
    "\n",
    "All data is read from the 'data' folder and models are saved to the 'models_stats' folder.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import json\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from matplotlib import cm\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b76884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcrf import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e818ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# DATA FOLDER CONFIGURATION\n",
    "# =========================\n",
    "# All data files should be read from and saved to the data folder\n",
    "DATA_FOLDER = \"data\"\n",
    "\n",
    "# Model folder named after this notebook\n",
    "MODEL_NAME = \"stats\"\n",
    "MODELS_FOLDER = f\"models_{MODEL_NAME}\"\n",
    "\n",
    "# Create folders if they don't exist\n",
    "os.makedirs(DATA_FOLDER, exist_ok=True)\n",
    "os.makedirs(MODELS_FOLDER, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# DEVICE CONFIGURATION\n",
    "# =========================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae7390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# LOAD GOLD STANDARD DATA\n",
    "# =========================\n",
    "# The gold standard dataset contains high-quality morphological segmentations\n",
    "# This will be used for statistical analysis and model training\n",
    "print(\"Loading gold standard data...\")\n",
    "gold_df = pd.read_parquet(os.path.join(DATA_FOLDER, \"Sue_kalt.parquet\"))\n",
    "gold_df['Word'] = gold_df['word']\n",
    "gold_df['morph'] = gold_df['morph'].str.replace('-', ' ')  # Normalize separators\n",
    "gold_df['Morph_split_str'] = gold_df['morph']  # String version\n",
    "gold_df['Morph_split'] = gold_df['morph'].str.split(' ')  # List version\n",
    "gold_df = gold_df[['Word', 'Morph_split', 'Morph_split_str']]\n",
    "gold_df = gold_df.drop_duplicates(subset=['Word']).reset_index(drop=True)\n",
    "gold_df = gold_df.dropna(subset=['Word'])\n",
    "print(f\"Loaded {len(gold_df):,} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cb07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a219a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# FEATURE EXTRACTION\n",
    "# =========================\n",
    "# Extract features for statistical analysis: word length and morpheme count\n",
    "gold_df['num_morphemes'] = gold_df['Morph_split'].apply(len)\n",
    "gold_df['word_len'] = gold_df['Word'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a974755",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8957e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# STATISTICAL ANALYSIS: VISUALIZATION\n",
    "# =========================\n",
    "# Create heatmap showing distribution of word length vs morpheme count\n",
    "# This helps visualize the relationship and identify potential outliers\n",
    "heatmap_data = gold_df.groupby(['word_len', 'num_morphemes']).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e21e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='d', cmap='YlGnBu')\n",
    "plt.title('Heatmap of Word Length vs. Morpheme Count')\n",
    "plt.xlabel('Number of Morphemes')\n",
    "plt.ylabel('Word Length (Characters)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dcf624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# STATISTICAL ANALYSIS: CORRELATION\n",
    "# =========================\n",
    "# Measure correlation between word length and morpheme count\n",
    "# This helps understand the relationship that will be used for outlier detection\n",
    "\n",
    "# Get the two series\n",
    "x = gold_df['word_len']\n",
    "y = gold_df['num_morphemes']\n",
    "\n",
    "# Pearson correlation (linear relationship)\n",
    "pearson_corr, pearson_p = pearsonr(x, y)\n",
    "\n",
    "# Spearman correlation (rank-based, non-parametric)\n",
    "spearman_corr, spearman_p = spearmanr(x, y)\n",
    "\n",
    "print(f\"Pearson correlation: {pearson_corr:.3f} (p={pearson_p:.3e})\")\n",
    "print(f\"Spearman correlation: {spearman_corr:.3f} (p={spearman_p:.3e})\")\n",
    "print(\"\\nStrong positive correlation indicates that longer words tend to have more morphemes.\")\n",
    "print(\"This relationship will be used to identify outliers (words that deviate from this pattern).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e1f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# OUTLIER DETECTION: LINEAR REGRESSION APPROACH\n",
    "# =========================\n",
    "# Use linear regression to model the relationship between word length and morpheme count\n",
    "# Words with large residuals (deviations from the regression line) are considered outliers\n",
    "\n",
    "gold_df1 = gold_df.copy()\n",
    "print(\"Original Size: \", gold_df1.shape)\n",
    "\n",
    "# Fit linear regression: num_morphemes ~ word_len\n",
    "X = gold_df1[['word_len']]\n",
    "y = gold_df1['num_morphemes']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "gold_df1['predicted'] = model.predict(X)\n",
    "gold_df1['residual'] = gold_df1['num_morphemes'] - gold_df1['predicted']  # Deviation from expected\n",
    "\n",
    "# Identify outliers: words where residual > 1 standard deviation\n",
    "std_residual = gold_df1['residual'].std()\n",
    "filtered_df = gold_df1[np.abs(gold_df1['residual']) <= std_residual]\n",
    "print(\"Cleaned Size (outliers removed): \", filtered_df.shape)\n",
    "print(f\"Outliers removed: {len(gold_df1) - len(filtered_df):,} examples\")\n",
    "\n",
    "X_filtered = filtered_df[['word_len']]\n",
    "y_filtered = filtered_df['num_morphemes']\n",
    "\n",
    "model_filtered = LinearRegression()\n",
    "model_filtered.fit(X_filtered, y_filtered)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=filtered_df, x='word_len', y='num_morphemes', alpha=0.5, label='Filtered Data')\n",
    "plt.plot(\n",
    "    X_filtered, \n",
    "    model_filtered.predict(X_filtered), \n",
    "    color='red', \n",
    "    linewidth=2, \n",
    "    label='Regression Line'\n",
    ")\n",
    "plt.title('Optimized Linear Regression: Word Length vs Morpheme Count')\n",
    "plt.xlabel('Word Length (Characters)')\n",
    "plt.ylabel('Number of Morphemes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc72906",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "print(f\"Pre_Refined Regression equation: num_morphemes ≈ {slope:.2f} × word_len + {intercept:.2f}\")\n",
    "\n",
    "slope = model_filtered.coef_[0]\n",
    "intercept = model_filtered.intercept_\n",
    "print(f\"Refined Regression equation: num_morphemes ≈ {slope:.2f} × word_len + {intercept:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe65bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# K-FOLD CROSS-VALIDATION FUNCTION\n",
    "# ===================================================================\n",
    "# This function performs k-fold cross-validation on the training data\n",
    "# It splits the data into k folds and trains/evaluates on each fold\n",
    "# For each fold, it trains a BiLSTM+CRF Segmenter model\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def run_kfold_cross_validation(\n",
    "    df,\n",
    "    n_folds=5,\n",
    "    emb_dim=64,\n",
    "    hidden_dim=128,\n",
    "    epochs=15,\n",
    "    batch_size=16,\n",
    "    lr=3e-3,\n",
    "    random_state=42,\n",
    "    device=device\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation on the training data with BiLSTM+CRF model.\n",
    "    \n",
    "    Args:\n",
    "        df: Training DataFrame with 'Word', 'char_seq', and 'boundary_labels' columns\n",
    "        n_folds: Number of folds for cross-validation (default: 5)\n",
    "        emb_dim: Embedding dimension\n",
    "        hidden_dim: LSTM hidden dimension\n",
    "        epochs: Number of training epochs per fold\n",
    "        batch_size: Training batch size\n",
    "        lr: Learning rate\n",
    "        random_state: Random seed for reproducibility\n",
    "        device: Device to run training on\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "        - fold_results: List of results for each fold\n",
    "        - mean_metrics: Average metrics across all folds\n",
    "        - std_metrics: Standard deviation of metrics across folds\n",
    "        - best_fold_idx: Index of the fold with best validation loss\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"K-FOLD CROSS-VALIDATION (k={n_folds}) WITH BILSTM+CRF\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Create k-fold splitter\n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    indices = np.arange(len(df))\n",
    "    \n",
    "    fold_results = []\n",
    "    all_metrics = {\n",
    "        'val_loss': [],\n",
    "        'exact_match': []\n",
    "    }\n",
    "    \n",
    "    # Train and evaluate on each fold\n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(kfold.split(indices), 1):\n",
    "        print(f\"\\n{'─'*80}\")\n",
    "        print(f\"FOLD {fold_idx}/{n_folds}\")\n",
    "        print(f\"{'─'*80}\")\n",
    "        print(f\"Train samples: {len(train_indices)}, Validation samples: {len(val_indices)}\")\n",
    "        \n",
    "        # Split data into train and validation\n",
    "        train_df_fold = df.iloc[train_indices].reset_index(drop=True)\n",
    "        val_df_fold = df.iloc[val_indices].reset_index(drop=True)\n",
    "        \n",
    "        # Create temporary JSONL files for this fold\n",
    "        import tempfile\n",
    "        import os as os_module\n",
    "        \n",
    "        # Create temporary directory for fold data\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        train_path_fold = os_module.path.join(temp_dir, f\"train_fold_{fold_idx}.jsonl\")\n",
    "        val_path_fold = os_module.path.join(temp_dir, f\"val_fold_{fold_idx}.jsonl\")\n",
    "        \n",
    "        # Write training data to JSONL\n",
    "        with open(train_path_fold, \"w\", encoding=\"utf-8\") as f:\n",
    "            for _, row in train_df_fold.iterrows():\n",
    "                record = {\n",
    "                    \"chars\": row['char_seq'],\n",
    "                    \"labels\": row['boundary_labels']\n",
    "                }\n",
    "                f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "        \n",
    "        # Write validation data to JSONL\n",
    "        with open(val_path_fold, \"w\", encoding=\"utf-8\") as f:\n",
    "            for _, row in val_df_fold.iterrows():\n",
    "                record = {\n",
    "                    \"chars\": row['char_seq'],\n",
    "                    \"labels\": row['boundary_labels']\n",
    "                }\n",
    "                f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "        \n",
    "        # Create datasets (vocabulary built from training fold only)\n",
    "        train_dataset_fold = MorphemeDataset(train_path_fold)\n",
    "        val_dataset_fold = MorphemeDataset(val_path_fold, char2idx=train_dataset_fold.char2idx)\n",
    "        train_loader_fold = DataLoader(train_dataset_fold, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "        val_loader_fold = DataLoader(val_dataset_fold, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "        \n",
    "        vocab_size_fold = len(train_dataset_fold.char2idx)\n",
    "        \n",
    "        # Create model\n",
    "        model_fold = Segmenter(vocab_size=vocab_size_fold, emb_dim=emb_dim, hidden_dim=hidden_dim).to(device)\n",
    "        \n",
    "        # Training loop\n",
    "        best_val_loss = float('inf')\n",
    "        best_epoch = 0\n",
    "        best_exact_match = 0.0\n",
    "        \n",
    "        optimizer_fold = torch.optim.Adam(model_fold.parameters(), lr=lr)\n",
    "        \n",
    "        for epoch in range(1, epochs+1):\n",
    "            # Training phase\n",
    "            model_fold.train()\n",
    "            total_loss = 0.0\n",
    "            for x, y, lengths, mask in train_loader_fold:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                lengths = lengths.to(device)\n",
    "                mask = mask.to(device)\n",
    "                \n",
    "                optimizer_fold.zero_grad()\n",
    "                loss = model_fold(x, lengths, labels=y, mask=mask)\n",
    "                loss.backward()\n",
    "                optimizer_fold.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            train_loss = total_loss / len(train_loader_fold)\n",
    "            \n",
    "            # Validation phase\n",
    "            model_fold.eval()\n",
    "            val_loss = 0.0\n",
    "            exact_matches = 0\n",
    "            total_val = 0\n",
    "            \n",
    "            # Define local predict_segments function for this fold\n",
    "            def predict_segments_fold(word, model, char2idx):\n",
    "                \"\"\"Fold-specific version of predict_segments.\"\"\"\n",
    "                model.eval()\n",
    "                x = torch.tensor([[char2idx.get(c, 0) for c in word]], dtype=torch.long).to(device)\n",
    "                lengths = torch.tensor([len(word)]).to(device)\n",
    "                mask = (x != 0).to(device)\n",
    "                with torch.no_grad():\n",
    "                    label_seq = model(x, lengths, labels=None, mask=mask)[0]\n",
    "                segments = []\n",
    "                start = 0\n",
    "                for i, label in enumerate(label_seq):\n",
    "                    if label == 1:\n",
    "                        segments.append(word[start:i+1])\n",
    "                        start = i + 1\n",
    "                if start < len(word):\n",
    "                    segments.append(word[start:])\n",
    "                return segments\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # Compute validation loss\n",
    "                for x, y, lengths, mask in val_loader_fold:\n",
    "                    x = x.to(device)\n",
    "                    y = y.to(device)\n",
    "                    lengths = lengths.to(device)\n",
    "                    mask = mask.to(device)\n",
    "                    \n",
    "                    loss = model_fold(x, lengths, labels=y, mask=mask)\n",
    "                    val_loss += loss.item()\n",
    "                \n",
    "                # Compute exact match accuracy on validation set\n",
    "                for i in range(len(val_dataset_fold)):\n",
    "                    word = val_df_fold.iloc[i]['Word']\n",
    "                    gold_split = val_df_fold.iloc[i]['Morph_split']\n",
    "                    \n",
    "                    # Predict segmentation using fold-specific function\n",
    "                    predicted_segments = predict_segments_fold(word, model_fold, train_dataset_fold.char2idx)\n",
    "                    \n",
    "                    # Check exact match\n",
    "                    if predicted_segments == gold_split:\n",
    "                        exact_matches += 1\n",
    "                    total_val += 1\n",
    "            \n",
    "            val_loss = val_loss / len(val_loader_fold)\n",
    "            exact_match_rate = exact_matches / total_val if total_val > 0 else 0.0\n",
    "            \n",
    "            print(f\"  Epoch {epoch:02d} | train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  exact_match={exact_match_rate:.3f}\")\n",
    "            \n",
    "            # Track best validation performance\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_exact_match = exact_match_rate\n",
    "                best_epoch = epoch\n",
    "        \n",
    "        print(f\"\\n  Best epoch: {best_epoch}\")\n",
    "        print(f\"  Best validation: Loss={best_val_loss:.4f}  Exact Match={best_exact_match:.3f}\")\n",
    "        \n",
    "        # Clean up temporary files\n",
    "        try:\n",
    "            os_module.remove(train_path_fold)\n",
    "            os_module.remove(val_path_fold)\n",
    "            os_module.rmdir(temp_dir)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Store fold results\n",
    "        fold_result = {\n",
    "            'fold': fold_idx,\n",
    "            'val_loss': best_val_loss,\n",
    "            'exact_match': best_exact_match,\n",
    "            'best_epoch': best_epoch\n",
    "        }\n",
    "        fold_results.append(fold_result)\n",
    "        \n",
    "        # Collect metrics for averaging\n",
    "        all_metrics['val_loss'].append(best_val_loss)\n",
    "        all_metrics['exact_match'].append(best_exact_match)\n",
    "    \n",
    "    # Calculate mean and std across folds\n",
    "    mean_metrics = {\n",
    "        'val_loss': np.mean(all_metrics['val_loss']),\n",
    "        'exact_match': np.mean(all_metrics['exact_match'])\n",
    "    }\n",
    "    \n",
    "    std_metrics = {\n",
    "        'val_loss': np.std(all_metrics['val_loss']),\n",
    "        'exact_match': np.std(all_metrics['exact_match'])\n",
    "    }\n",
    "    \n",
    "    # Find best fold (lowest validation loss)\n",
    "    best_fold_idx = min(range(len(fold_results)), key=lambda i: fold_results[i]['val_loss'])\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"K-FOLD CROSS-VALIDATION SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nPer-fold results:\")\n",
    "    for result in fold_results:\n",
    "        print(f\"  Fold {result['fold']}: \"\n",
    "              f\"Loss={result['val_loss']:.4f}, \"\n",
    "              f\"Exact Match={result['exact_match']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nMean ± Std across {n_folds} folds:\")\n",
    "    print(f\"  Validation Loss:   {mean_metrics['val_loss']:.4f} ± {std_metrics['val_loss']:.4f}\")\n",
    "    print(f\"  Exact Match Rate:  {mean_metrics['exact_match']:.3f} ± {std_metrics['exact_match']:.3f}\")\n",
    "    print(f\"\\nBest fold: Fold {fold_results[best_fold_idx]['fold']} \"\n",
    "          f\"(Loss: {fold_results[best_fold_idx]['val_loss']:.4f}, \"\n",
    "          f\"Exact Match: {fold_results[best_fold_idx]['exact_match']:.3f})\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'fold_results': fold_results,\n",
    "        'mean_metrics': mean_metrics,\n",
    "        'std_metrics': std_metrics,\n",
    "        'best_fold_idx': best_fold_idx,\n",
    "        'all_metrics': all_metrics\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94380a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# K-FOLD CROSS-VALIDATION DEMONSTRATION\n",
    "# ===================================================================\n",
    "# This cell demonstrates how to use k-fold cross-validation to evaluate\n",
    "# model performance more robustly by training on multiple train/val splits\n",
    "# Each fold trains its own BiLSTM+CRF Segmenter model\n",
    "#\n",
    "# NOTE: Run this cell AFTER the hyperparameters (EMB_DIM, HIDDEN_DIM, etc.)\n",
    "# are defined in the \"LOAD FULL DATASET AND INITIALIZE MODEL 1\" cell.\n",
    "# If those variables are not yet defined, the function will use default values.\n",
    "\n",
    "# Run 5-fold cross-validation on the FULL dataset (with outliers)\n",
    "# Uses hyperparameters if available, otherwise uses defaults from function signature\n",
    "kfold_results_full = run_kfold_cross_validation(\n",
    "    df=gold_df,  # Use the full gold_df for cross-validation\n",
    "    n_folds=5,  # Number of folds\n",
    "    emb_dim=EMB_DIM if 'EMB_DIM' in globals() else 64,\n",
    "    hidden_dim=HIDDEN_DIM if 'HIDDEN_DIM' in globals() else 128,\n",
    "    epochs=EPOCHS if 'EPOCHS' in globals() else 15,\n",
    "    batch_size=BATCH_SIZE if 'BATCH_SIZE' in globals() else 16,\n",
    "    lr=LR if 'LR' in globals() else 3e-3,\n",
    "    random_state=42,  # Use fixed seed for reproducibility\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# The results dictionary contains:\n",
    "# - fold_results: List of results for each fold\n",
    "# - mean_metrics: Average metrics across all folds\n",
    "# - std_metrics: Standard deviation of metrics across folds\n",
    "# - best_fold_idx: Index of the fold with best validation loss\n",
    "# - all_metrics: Raw metrics from all folds\n",
    "\n",
    "print(\"\\nK-fold cross-validation completed!\")\n",
    "print(f\"Average exact match rate: {kfold_results_full['mean_metrics']['exact_match']:.3f} ± {kfold_results_full['std_metrics']['exact_match']:.3f}\")\n",
    "print(f\"Average validation loss: {kfold_results_full['mean_metrics']['val_loss']:.4f} ± {kfold_results_full['std_metrics']['val_loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4a7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_full = r2_score(y, gold_df1['predicted'])\n",
    "print(f\"R2 (Original): {r2_full:.3f}\")\n",
    "\n",
    "y_pred_filtered = model_filtered.predict(X_filtered)\n",
    "r2_filtered = r2_score(y_filtered, y_pred_filtered)\n",
    "print(f\"R2 (Filtered): {r2_filtered:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f5940",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df2 = gold_df.copy()\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(gold_df2[['word_len']], gold_df2['num_morphemes'])\n",
    "\n",
    "gold_df2['predicted_rf'] = rf.predict(gold_df2[['word_len']])\n",
    "gold_df2['residual_rf'] = gold_df2['num_morphemes'] - gold_df2['predicted_rf']\n",
    "\n",
    "mse_full = mean_squared_error(gold_df2['num_morphemes'], gold_df2['predicted_rf'])\n",
    "mae_full = mean_absolute_error(gold_df2['num_morphemes'], gold_df2['predicted_rf'])\n",
    "r2_full = r2_score(gold_df2['num_morphemes'], gold_df2['predicted_rf'])\n",
    "\n",
    "std_residual = gold_df2['residual_rf'].std()\n",
    "filtered_df_rf = gold_df2[np.abs(gold_df2['residual_rf']) <= std_residual].copy()\n",
    "\n",
    "rf_filtered = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "X_filtered = filtered_df_rf[['word_len']]\n",
    "y_filtered = filtered_df_rf['num_morphemes']\n",
    "rf_filtered.fit(X_filtered, y_filtered)\n",
    "\n",
    "filtered_df_rf['predicted_rf'] = rf_filtered.predict(X_filtered)\n",
    "r2_filtered = r2_score(y_filtered, filtered_df_rf['predicted_rf'])\n",
    "mse_filtered = mean_squared_error(y_filtered, filtered_df_rf['predicted_rf'])\n",
    "mae_filtered = mean_absolute_error(y_filtered, filtered_df_rf['predicted_rf'])\n",
    "\n",
    "print(\"Random Forest Evaluation (Before Outlier Removal):\")\n",
    "print(f\"MSE: {mse_full:.3f}\")\n",
    "print(f\"MAE: {mae_full:.3f}\")\n",
    "print(f\"R²:  {r2_full:.3f}\")\n",
    "\n",
    "print(\"Random Forest Evaluation (After Outlier Removal):\")\n",
    "print(f\"MSE: {mse_filtered:.3f}\")\n",
    "print(f\"MAE: {mae_filtered:.3f}\")\n",
    "print(f\"R²:  {r2_filtered:.3f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=filtered_df_rf['word_len'], y=filtered_df_rf['num_morphemes'], alpha=0.5, label='Filtered Data')\n",
    "sns.lineplot(x=filtered_df_rf['word_len'], y=filtered_df_rf['predicted_rf'], color='red', label='RF Prediction (Filtered)')\n",
    "plt.xlabel('Word Length (Characters)')\n",
    "plt.ylabel('Number of Morphemes')\n",
    "plt.title('Random Forest Regression (Filtered)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc87067",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(gold_df2[['word_len']])\n",
    "model_poly = LinearRegression().fit(X_poly, gold_df2['num_morphemes'])\n",
    "preds_poly = model_poly.predict(X_poly)\n",
    "r2_before = r2_score(gold_df2['num_morphemes'], preds_poly)\n",
    "print(f\"Polynomial Regression R2 (Before Filtering): {r2_before:.3f}\")\n",
    "\n",
    "residuals_poly = gold_df2['num_morphemes'] - preds_poly\n",
    "std_resid_poly = residuals_poly.std()\n",
    "mask = np.abs(residuals_poly) <= std_resid_poly\n",
    "filtered_df_poly = gold_df2[mask].copy()\n",
    "\n",
    "X_filtered_poly = poly.fit_transform(filtered_df_poly[['word_len']])\n",
    "model_poly_filtered = LinearRegression().fit(X_filtered_poly, filtered_df_poly['num_morphemes'])\n",
    "preds_filtered = model_poly_filtered.predict(X_filtered_poly)\n",
    "r2_after = r2_score(filtered_df_poly['num_morphemes'], preds_filtered)\n",
    "print(f\"Polynomial Regression R2 (After Filtering):  {r2_after:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c01465",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_outliers = gold_df1[np.abs(gold_df1['residual']) > std_residual]\n",
    "rf_outliers = gold_df2[np.abs(gold_df2['residual_rf']) > std_residual]\n",
    "poly_outliers = gold_df2[np.abs(residuals_poly) > std_resid_poly]\n",
    "\n",
    "all_outliers = pd.concat([linear_outliers, rf_outliers, poly_outliers])\n",
    "all_outliers = all_outliers[['word_len', 'num_morphemes']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e3681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data = gold_df.groupby(['word_len', 'num_morphemes']).size().unstack(fill_value=0)\n",
    "\n",
    "outlier_coords = all_outliers[['word_len', 'num_morphemes']]\n",
    "outlier_coords = outlier_coords[\n",
    "    (outlier_coords['word_len'].isin(heatmap_data.index)) & \n",
    "    (outlier_coords['num_morphemes'].isin(heatmap_data.columns))\n",
    "]\n",
    "outlier_coords = outlier_coords.copy()\n",
    "outlier_coords['freq'] = outlier_coords.apply(\n",
    "    lambda row: heatmap_data.at[row['word_len'], row['num_morphemes']], axis=1\n",
    ")\n",
    "\n",
    "norm = plt.Normalize(vmin=heatmap_data.values.min(), vmax=heatmap_data.values.max())\n",
    "colors = cm.Purples_r(norm(outlier_coords['freq'].values))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.heatmap(heatmap_data, annot=True, fmt='d', cmap='Reds', cbar_kws={'label': 'Frequency'})\n",
    "plt.title('Heatmap of Word Length vs. Morpheme Count with Outliers')\n",
    "plt.xlabel('Number of Morphemes')\n",
    "plt.ylabel('Word Length (Characters)')\n",
    "\n",
    "for j, (_, row) in enumerate(outlier_coords.iterrows()):\n",
    "    plt.scatter(\n",
    "        x=row['num_morphemes'] + 0.5,\n",
    "        y=row['word_len'] + 0.5,\n",
    "        color=colors[j],\n",
    "        s=100,\n",
    "        marker='X',\n",
    "        linewidths=2,\n",
    "        label='Outlier' if j == 0 else \"\"\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c10ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# BOUNDARY LABEL GENERATION\n",
    "# =========================\n",
    "# Convert morpheme splits into character-level boundary labels\n",
    "# This prepares the data for the BiLSTM+CRF model training\n",
    "\n",
    "def get_boundary_labels(word, split):\n",
    "    \"\"\"\n",
    "    Generate boundary labels for a word given its morpheme split.\n",
    "    \n",
    "    Args:\n",
    "        word: Full word string\n",
    "        split: List of morpheme strings\n",
    "    \n",
    "    Returns:\n",
    "        List of binary labels (0=no boundary, 1=boundary) for each character position\n",
    "    \"\"\"\n",
    "    labels = [0] * len(word)\n",
    "    idx = 0\n",
    "    for morpheme in split[:-1]:  # All but last morpheme end in a boundary\n",
    "        idx += len(morpheme)\n",
    "        if idx < len(word):\n",
    "            labels[idx - 1] = 1  # Boundary at the end of this morpheme\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbe6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PREPARE FULL DATASET FOR TRAINING\n",
    "# =========================\n",
    "# Convert words to character sequences and generate boundary labels\n",
    "# This is for Model 1 (trained on FULL dataset with outliers)\n",
    "\n",
    "gold_df['char_seq'] = gold_df['Word'].apply(list)  # Convert word to list of characters\n",
    "gold_df['boundary_labels'] = gold_df.apply(\n",
    "    lambda row: get_boundary_labels(row['Word'], row['Morph_split']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b2d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PREPARE TRAINING DATA (FULL DATASET)\n",
    "# =========================\n",
    "# Convert gold standard data to JSONL format for model training\n",
    "# This is the FULL dataset (with outliers) - Model 1 will be trained on this\n",
    "\n",
    "output_path = os.path.join(DATA_FOLDER, \"stats_segmentation_data_full.jsonl\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in gold_df.iterrows():\n",
    "        record = {\n",
    "            \"chars\": row['char_seq'],\n",
    "            \"labels\": row['boundary_labels']\n",
    "        }\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Full dataset saved to {output_path}\")\n",
    "print(f\"  Total examples: {len(gold_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9bc414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# DATASET AND MODEL ARCHITECTURE\n",
    "# =========================\n",
    "# PyTorch Dataset and BiLSTM+CRF model for morphological segmentation\n",
    "\n",
    "class MorphemeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for morphological segmentation training.\n",
    "    Each sample contains a character sequence and boundary labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, path, char2idx=None):\n",
    "        self.data = []\n",
    "        with open(path, encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                item = json.loads(line)\n",
    "                if len(item[\"chars\"]) == 0:  # Skip samples with no characters\n",
    "                    continue\n",
    "                self.data.append(item)\n",
    "\n",
    "        # Build vocabulary if not provided\n",
    "        if char2idx is None:\n",
    "            chars = set(c for item in self.data for c in item[\"chars\"])\n",
    "            self.char2idx = {c: i + 1 for i, c in enumerate(sorted(chars))}\n",
    "            self.char2idx[\"<PAD>\"] = 0\n",
    "        else:\n",
    "            self.char2idx = char2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        x = torch.tensor([self.char2idx[c] for c in item[\"chars\"]], dtype=torch.long)\n",
    "        y = torch.tensor(item[\"labels\"], dtype=torch.float)\n",
    "        return x, y\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate function for DataLoader: pads sequences to the same length.\n",
    "    \"\"\"\n",
    "    xs, ys = zip(*batch)\n",
    "    lengths = [len(x) for x in xs]\n",
    "    max_len = max(lengths)\n",
    "    padded_x = torch.zeros(len(xs), max_len, dtype=torch.long)\n",
    "    padded_y = torch.zeros(len(ys), max_len, dtype=torch.long)\n",
    "    for i, (x, y) in enumerate(zip(xs, ys)):\n",
    "        padded_x[i, :len(x)] = x\n",
    "        padded_y[i, :len(y)] = y.long()\n",
    "    mask = (padded_x != 0)  # True for non-padding positions\n",
    "    return padded_x, padded_y, torch.tensor(lengths), mask\n",
    "\n",
    "class Segmenter(nn.Module):\n",
    "    \"\"\"\n",
    "    BiLSTM+CRF model for morphological segmentation.\n",
    "    \n",
    "    Architecture:\n",
    "    1. Character embeddings\n",
    "    2. Bidirectional LSTM\n",
    "    3. Dropout + Linear layers\n",
    "    4. CRF layer for sequence labeling (predicts boundary positions)\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, emb_dim=64, hidden_dim=128, num_labels=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_labels)  # 2 output classes per token (0=no boundary, 1=boundary)\n",
    "        self.crf = CRF(num_labels, batch_first=True)\n",
    "\n",
    "    def forward(self, x, lengths, labels=None, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "        \n",
    "        Args:\n",
    "            x: Input character sequences (batch, seq_len)\n",
    "            lengths: Actual length of each sequence (batch,)\n",
    "            labels: Ground truth boundary labels (batch, seq_len) - for training\n",
    "            mask: Boolean mask indicating valid positions (batch, seq_len)\n",
    "        \n",
    "        Returns:\n",
    "            If labels provided: loss value (for training)\n",
    "            Otherwise: best path predictions (for inference)\n",
    "        \"\"\"\n",
    "        emb = self.embedding(x)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.lstm(packed)\n",
    "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "        h = self.relu(self.fc1(self.dropout(lstm_out)))\n",
    "        emissions = self.fc2(h)  # [batch, seq, 2] - emission scores for CRF\n",
    "\n",
    "        if labels is not None:\n",
    "            # Training: compute negative log-likelihood loss\n",
    "            loss = -self.crf(emissions, labels.long(), mask=mask.bool(), reduction='mean')\n",
    "            return loss\n",
    "        else:\n",
    "            # Inference: predict the best path using Viterbi decoding\n",
    "            best_paths = self.crf.decode(emissions, mask=mask.bool())\n",
    "            return best_paths\n",
    "\n",
    "def train(model, dataloader, epochs=10, lr=1e-3, device=None):\n",
    "    \"\"\"\n",
    "    Training function for the Segmenter model.\n",
    "    \n",
    "    Args:\n",
    "        model: Segmenter model to train\n",
    "        dataloader: DataLoader with training data\n",
    "        epochs: Number of training epochs\n",
    "        lr: Learning rate\n",
    "        device: Device to move tensors to (default: uses model's device)\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = next(model.parameters()).device\n",
    "    \n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for x, y, lengths, mask in dataloader:\n",
    "            # Move all tensors to the same device as the model\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            mask = mask.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = model(x, lengths, labels=y, mask=mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# MODEL CHECKPOINTING FUNCTIONS\n",
    "# =========================\n",
    "# Functions to save and load trained models to avoid retraining\n",
    "\n",
    "def generate_model_id(emb_dim, hidden_dim, epochs, batch_size, lr, vocab_size, model_type=\"full\"):\n",
    "    \"\"\"\n",
    "    Generate a unique identifier for a model based on its training parameters.\n",
    "    \n",
    "    Args:\n",
    "        emb_dim: Embedding dimension\n",
    "        hidden_dim: LSTM hidden dimension\n",
    "        epochs: Number of training epochs\n",
    "        batch_size: Batch size\n",
    "        lr: Learning rate\n",
    "        vocab_size: Vocabulary size\n",
    "        model_type: \"full\" or \"filtered\" to distinguish the two models\n",
    "    \n",
    "    Returns:\n",
    "        A string identifier (hash) for the model\n",
    "    \"\"\"\n",
    "    params_dict = {\n",
    "        'emb_dim': emb_dim,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'lr': lr,\n",
    "        'vocab_size': vocab_size,\n",
    "        'model_type': model_type\n",
    "    }\n",
    "    params_str = json.dumps(params_dict, sort_keys=True)\n",
    "    model_id = hashlib.md5(params_str.encode()).hexdigest()[:16]\n",
    "    return model_id\n",
    "\n",
    "def save_model_checkpoint(model, char2idx, model_id, models_folder=MODELS_FOLDER):\n",
    "    \"\"\"\n",
    "    Save model checkpoint to the models folder.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Segmenter model\n",
    "        char2idx: Character-to-index vocabulary mapping\n",
    "        model_id: Unique identifier for this model\n",
    "        models_folder: Folder to save models in\n",
    "    \"\"\"\n",
    "    model_dir = os.path.join(models_folder, model_id)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    checkpoint_path = os.path.join(model_dir, \"segmenter_model.pt\")\n",
    "    torch.save({\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"char2idx\": char2idx\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata_path = os.path.join(model_dir, \"metadata.json\")\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            'model_id': model_id,\n",
    "            'vocab_size': len(char2idx),\n",
    "            'model_name': MODEL_NAME\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"Model checkpoint saved to {model_dir}\")\n",
    "    return model_dir\n",
    "\n",
    "def load_model_checkpoint(model_id, models_folder=MODELS_FOLDER):\n",
    "    \"\"\"\n",
    "    Load model checkpoint from the models folder.\n",
    "    \n",
    "    Args:\n",
    "        model_id: Unique identifier for the model\n",
    "        models_folder: Folder where models are saved\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with 'model_state', 'char2idx', 'checkpoint_path', 'model_dir' or None if not found\n",
    "    \"\"\"\n",
    "    model_dir = os.path.join(models_folder, model_id)\n",
    "    checkpoint_path = os.path.join(model_dir, \"segmenter_model.pt\")\n",
    "    \n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        return None\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    print(f\"Model checkpoint loaded from {model_dir}\")\n",
    "    return {\n",
    "        'model_state': checkpoint['model_state'],\n",
    "        'char2idx': checkpoint['char2idx'],\n",
    "        'checkpoint_path': checkpoint_path,\n",
    "        'model_dir': model_dir\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# LOAD FULL DATASET AND INITIALIZE MODEL 1\n",
    "# =========================\n",
    "# Model hyperparameters\n",
    "EMB_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 16\n",
    "LR = 3e-3\n",
    "\n",
    "# Model 1: Trained on FULL dataset (with outliers)\n",
    "\n",
    "data_path = os.path.join(DATA_FOLDER, \"stats_segmentation_data_full.jsonl\")\n",
    "dataset = MorphemeDataset(data_path)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "vocab_size = len(dataset.char2idx)\n",
    "\n",
    "# Generate model identifier for Model 1 (full dataset)\n",
    "model_id_full = generate_model_id(EMB_DIM, HIDDEN_DIM, EPOCHS, BATCH_SIZE, LR, vocab_size, model_type=\"full\")\n",
    "\n",
    "# Try to load existing model\n",
    "print(f\"\\n=== MODEL 1: FULL DATASET (with outliers) ===\")\n",
    "print(f\"Checking for existing model with ID: {model_id_full}\")\n",
    "loaded_full = load_model_checkpoint(model_id_full, models_folder=MODELS_FOLDER)\n",
    "\n",
    "if loaded_full is not None:\n",
    "    print(f\"Found existing model! Loading from {loaded_full['model_dir']}\")\n",
    "    char2idx_full = loaded_full['char2idx']\n",
    "    model_full = Segmenter(vocab_size=len(char2idx_full), emb_dim=EMB_DIM, hidden_dim=HIDDEN_DIM).to(device)\n",
    "    model_full.load_state_dict(loaded_full['model_state'])\n",
    "    model_full.eval()\n",
    "    print(\"Model 1 loaded successfully. Skipping training.\")\n",
    "else:\n",
    "    print(f\"No existing model found. Training new model...\")\n",
    "    model_full = Segmenter(vocab_size, emb_dim=EMB_DIM, hidden_dim=HIDDEN_DIM).to(device)\n",
    "    train(model_full, dataloader, epochs=EPOCHS, lr=LR)\n",
    "    # Save model after training\n",
    "    save_model_checkpoint(model_full, dataset.char2idx, model_id_full, models_folder=MODELS_FOLDER)\n",
    "    char2idx_full = dataset.char2idx\n",
    "    print(f\"\\nModel 1 training complete! Model saved with ID: {model_id_full}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a982f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# INFERENCE FUNCTION\n",
    "# =========================\n",
    "# Function to segment a word using the trained model\n",
    "\n",
    "def predict_segments(word, model, char2idx):\n",
    "    \"\"\"\n",
    "    Predict morphological segmentation for a word.\n",
    "    \n",
    "    Args:\n",
    "        word: Input word string to segment\n",
    "        model: Trained Segmenter model\n",
    "        char2idx: Character-to-index vocabulary mapping\n",
    "    \n",
    "    Returns:\n",
    "        List of morpheme strings\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x = torch.tensor([[char2idx.get(c, 0) for c in word]], dtype=torch.long).to(device)\n",
    "    lengths = torch.tensor([len(word)]).to(device)\n",
    "    mask = (x != 0).to(device)\n",
    "    with torch.no_grad():\n",
    "        # Returns a list of paths, each a list of ints (0=no boundary, 1=boundary)\n",
    "        label_seq = model(x, lengths, labels=None, mask=mask)[0]  # [0] because batch size = 1\n",
    "    \n",
    "    # Convert boundary labels to morpheme segments\n",
    "    segments = []\n",
    "    start = 0\n",
    "    for i, label in enumerate(label_seq):\n",
    "        if label == 1:  # Boundary detected at position i\n",
    "            segments.append(word[start:i+1])\n",
    "            start = i + 1\n",
    "    if start < len(word):  # Add remaining characters as final morpheme\n",
    "        segments.append(word[start:])\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model 1 on example word\n",
    "print(\"Model 1 (Full dataset) example:\")\n",
    "print(f\"  pikunas -> {predict_segments('pikunas', model_full, char2idx_full)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f05c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# OUTLIER DETECTION AND REMOVAL\n",
    "# =========================\n",
    "# Identify and remove statistical outliers for Model 2 training\n",
    "# Outliers are words where morpheme count deviates significantly from the expected\n",
    "# relationship with word length (based on linear regression residuals)\n",
    "\n",
    "gold_df3 = gold_df.copy()\n",
    "print(\"Original Size: \", gold_df3.shape)\n",
    "\n",
    "# Fit linear regression to identify outliers\n",
    "X = gold_df3[['word_len']]\n",
    "y = gold_df3['num_morphemes']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "gold_df3['predicted'] = model.predict(X)\n",
    "gold_df3['residual'] = gold_df3['num_morphemes'] - gold_df3['predicted']\n",
    "\n",
    "# Remove outliers: keep only words within 1 standard deviation of the regression line\n",
    "std_residual = gold_df3['residual'].std()\n",
    "filtered_df = gold_df3[np.abs(gold_df3['residual']) <= std_residual].copy()\n",
    "print(\"Cleaned Size (outliers removed): \", filtered_df.shape)\n",
    "print(f\"Outliers removed: {len(gold_df3) - len(filtered_df):,} examples ({100*(len(gold_df3) - len(filtered_df))/len(gold_df3):.1f}% of data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PREPARE FILTERED DATASET FOR TRAINING\n",
    "# =========================\n",
    "# Convert filtered (outlier-free) data to boundary labels format\n",
    "\n",
    "def get_boundary_labels(word, split):\n",
    "    \"\"\"\n",
    "    Generate boundary labels for a word given its morpheme split.\n",
    "    \n",
    "    Args:\n",
    "        word: Full word string\n",
    "        split: List of morpheme strings\n",
    "    \n",
    "    Returns:\n",
    "        List of binary labels (0=no boundary, 1=boundary) for each character position\n",
    "    \"\"\"\n",
    "    labels = [0] * len(word)\n",
    "    idx = 0\n",
    "    for morpheme in split[:-1]:  # All but last morpheme end in a boundary\n",
    "        idx += len(morpheme)\n",
    "        if idx < len(word):\n",
    "            labels[idx - 1] = 1  # Boundary at the end of this morpheme\n",
    "    return labels\n",
    "\n",
    "# Create character sequences and boundary labels for filtered dataset\n",
    "filtered_df = filtered_df.copy()  # Avoid SettingWithCopyWarning\n",
    "filtered_df['char_seq'] = filtered_df['Word'].apply(list)\n",
    "filtered_df['boundary_labels'] = filtered_df.apply(\n",
    "    lambda row: get_boundary_labels(row['Word'], row['Morph_split']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5120a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# SAVE FILTERED DATASET\n",
    "# =========================\n",
    "# Save filtered (outlier-free) dataset to JSONL format for Model 2 training\n",
    "\n",
    "output_path_filtered = os.path.join(DATA_FOLDER, \"stats_segmentation_data_filtered.jsonl\")\n",
    "with open(output_path_filtered, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        json.dump({\n",
    "            \"chars\": row[\"char_seq\"],\n",
    "            \"labels\": row[\"boundary_labels\"]\n",
    "        }, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Filtered dataset saved to {output_path_filtered}\")\n",
    "print(f\"  Total examples: {len(filtered_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13171ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# LOAD FILTERED DATASET AND INITIALIZE MODEL 2\n",
    "# =========================\n",
    "# Model 2: Trained on FILTERED dataset (outliers removed)\n",
    "\n",
    "data_path_filtered = os.path.join(DATA_FOLDER, \"stats_segmentation_data_filtered.jsonl\")\n",
    "dataset2 = MorphemeDataset(data_path_filtered)\n",
    "dataloader2 = DataLoader(dataset2, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "vocab_size_filtered = len(dataset2.char2idx)\n",
    "\n",
    "# Generate model identifier for Model 2 (filtered dataset)\n",
    "model_id_filtered = generate_model_id(EMB_DIM, HIDDEN_DIM, EPOCHS, BATCH_SIZE, LR, vocab_size_filtered, model_type=\"filtered\")\n",
    "\n",
    "# Try to load existing model\n",
    "print(f\"\\n=== MODEL 2: FILTERED DATASET (outliers removed) ===\")\n",
    "print(f\"Checking for existing model with ID: {model_id_filtered}\")\n",
    "loaded_filtered = load_model_checkpoint(model_id_filtered, models_folder=MODELS_FOLDER)\n",
    "\n",
    "if loaded_filtered is not None:\n",
    "    print(f\"Found existing model! Loading from {loaded_filtered['model_dir']}\")\n",
    "    char2idx_filtered = loaded_filtered['char2idx']\n",
    "    model_filtered = Segmenter(vocab_size=len(char2idx_filtered), emb_dim=EMB_DIM, hidden_dim=HIDDEN_DIM).to(device)\n",
    "    model_filtered.load_state_dict(loaded_filtered['model_state'])\n",
    "    model_filtered.eval()\n",
    "    print(\"Model 2 loaded successfully. Skipping training.\")\n",
    "else:\n",
    "    print(f\"No existing model found. Training new model...\")\n",
    "    model_filtered = Segmenter(vocab_size_filtered, emb_dim=EMB_DIM, hidden_dim=HIDDEN_DIM).to(device)\n",
    "    train(model_filtered, dataloader2, epochs=EPOCHS, lr=LR)\n",
    "    # Save model after training\n",
    "    save_model_checkpoint(model_filtered, dataset2.char2idx, model_id_filtered, models_folder=MODELS_FOLDER)\n",
    "    char2idx_filtered = dataset2.char2idx\n",
    "    print(f\"\\nModel 2 training complete! Model saved with ID: {model_id_filtered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b18cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model 2 on example word\n",
    "print(\"Model 2 (Filtered dataset) example:\")\n",
    "print(f\"  pikunas -> {predict_segments('pikunas', model_filtered, char2idx_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b3f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# COMPREHENSIVE EVALUATION: COMPARING BOTH MODELS\n",
    "# =========================\n",
    "# Evaluate both models on test data to see if outlier removal helps\n",
    "# This is the main purpose of this notebook: to test if removing outliers improves performance\n",
    "\n",
    "print(\"Loading test data...\")\n",
    "test_df = pd.read_parquet(os.path.join(DATA_FOLDER, \"cleaned_data_df.parquet\"))\n",
    "print(f\"Loaded {len(test_df):,} test examples\")\n",
    "\n",
    "# =========================\n",
    "# EVALUATION HELPER FUNCTIONS\n",
    "# =========================\n",
    "# Functions for evaluating segmentation accuracy (similar to segmenter.ipynb)\n",
    "\n",
    "def is_correct_prediction(predicted, gold_variants):\n",
    "    \"\"\"\n",
    "    Check if predicted segmentation exactly matches any gold variant.\n",
    "    \n",
    "    Args:\n",
    "        predicted: List of predicted morphemes\n",
    "        gold_variants: List of gold segmentation variants (each is a list of morphemes)\n",
    "    \n",
    "    Returns:\n",
    "        True if prediction matches any gold variant, False otherwise\n",
    "    \"\"\"\n",
    "    # Normalize gold_variants (handle numpy arrays, nested structures)\n",
    "    if gold_variants is None:\n",
    "        return False\n",
    "    \n",
    "    if isinstance(gold_variants, np.ndarray):\n",
    "        gold_variants = gold_variants.tolist()\n",
    "    \n",
    "    if isinstance(gold_variants, list):\n",
    "        normalized = []\n",
    "        for variant in gold_variants:\n",
    "            if isinstance(variant, np.ndarray):\n",
    "                normalized.append(variant.tolist())\n",
    "            elif isinstance(variant, list):\n",
    "                normalized.append([item.tolist() if isinstance(item, np.ndarray) else item for item in variant])\n",
    "            else:\n",
    "                normalized.append(variant)\n",
    "        gold_variants = normalized\n",
    "    \n",
    "    return any(predicted == variant for variant in gold_variants)\n",
    "\n",
    "def split_count_metrics(predicted_segments, gold_variants):\n",
    "    \"\"\"\n",
    "    Compute split-count accuracy variants:\n",
    "    - Exact: same number of morphemes as any gold variant\n",
    "    - +1: one more split than any gold variant\n",
    "    - -1: one fewer split than any gold variant\n",
    "    - ±1: difference ≤ 1 with any gold variant\n",
    "    \"\"\"\n",
    "    pred_count = len(predicted_segments)\n",
    "    \n",
    "    # Normalize gold_variants\n",
    "    if gold_variants is None:\n",
    "        return {\"Exact\": False, \"+1\": False, \"-1\": False, \"±1\": False}\n",
    "    \n",
    "    if isinstance(gold_variants, np.ndarray):\n",
    "        gold_variants = gold_variants.tolist()\n",
    "    \n",
    "    if isinstance(gold_variants, list):\n",
    "        normalized = []\n",
    "        for variant in gold_variants:\n",
    "            if isinstance(variant, np.ndarray):\n",
    "                normalized.append(variant.tolist())\n",
    "            elif isinstance(variant, list):\n",
    "                normalized.append([item.tolist() if isinstance(item, np.ndarray) else item for item in variant])\n",
    "            else:\n",
    "                normalized.append(variant)\n",
    "        gold_variants = normalized\n",
    "    \n",
    "    gold_counts = [len(gold) for gold in gold_variants]\n",
    "\n",
    "    exact = any(pred_count == g for g in gold_counts)\n",
    "    plus1 = any(pred_count == g + 1 for g in gold_counts)\n",
    "    minus1 = any(pred_count == g - 1 for g in gold_counts)\n",
    "    pm1 = any(abs(pred_count - g) <= 1 for g in gold_counts)\n",
    "\n",
    "    return {\"Exact\": exact, \"+1\": plus1, \"-1\": minus1, \"±1\": pm1}\n",
    "\n",
    "# =========================\n",
    "# EVALUATION LOOP: BOTH MODELS\n",
    "# =========================\n",
    "# Predict segmentations for all test words using both models and compute metrics\n",
    "\n",
    "records_full = []\n",
    "records_filtered = []\n",
    "all_words = test_df[\"Word\"].tolist()\n",
    "\n",
    "print(\"\\nEvaluating Model 1 (FULL dataset with outliers)...\")\n",
    "for word in all_words:\n",
    "    # Predict with Model 1 (full dataset)\n",
    "    predicted_full = predict_segments(word, model_full, char2idx_full)\n",
    "    \n",
    "    # Get gold variants\n",
    "    gold_variants = test_df[test_df[\"Word\"] == word][\"Gold\"].iloc[0] if len(test_df[test_df[\"Word\"] == word]) > 0 else []\n",
    "    \n",
    "    # Exact match accuracy\n",
    "    correct_exact_full = is_correct_prediction(predicted_full, gold_variants)\n",
    "    \n",
    "    # Split-count metrics\n",
    "    split_metrics_full = split_count_metrics(predicted_full, gold_variants)\n",
    "    \n",
    "    records_full.append({\n",
    "        \"Word\": word,\n",
    "        \"Prediction\": predicted_full,\n",
    "        \"Gold\": gold_variants,\n",
    "        \"CorrectExactSeg\": correct_exact_full,\n",
    "        \"CorrectSplitCount\": split_metrics_full[\"Exact\"],\n",
    "        \"SplitCount+1\": split_metrics_full[\"+1\"],\n",
    "        \"SplitCount-1\": split_metrics_full[\"-1\"],\n",
    "        \"SplitCount±1\": split_metrics_full[\"±1\"],\n",
    "        \"OverlapExactAndSplit\": correct_exact_full and split_metrics_full[\"Exact\"]\n",
    "    })\n",
    "\n",
    "print(\"Evaluating Model 2 (FILTERED dataset without outliers)...\")\n",
    "for word in all_words:\n",
    "    # Predict with Model 2 (filtered dataset)\n",
    "    predicted_filtered = predict_segments(word, model_filtered, char2idx_filtered)\n",
    "    \n",
    "    # Get gold variants\n",
    "    gold_variants = test_df[test_df[\"Word\"] == word][\"Gold\"].iloc[0] if len(test_df[test_df[\"Word\"] == word]) > 0 else []\n",
    "    \n",
    "    # Exact match accuracy\n",
    "    correct_exact_filtered = is_correct_prediction(predicted_filtered, gold_variants)\n",
    "    \n",
    "    # Split-count metrics\n",
    "    split_metrics_filtered = split_count_metrics(predicted_filtered, gold_variants)\n",
    "    \n",
    "    records_filtered.append({\n",
    "        \"Word\": word,\n",
    "        \"Prediction\": predicted_filtered,\n",
    "        \"Gold\": gold_variants,\n",
    "        \"CorrectExactSeg\": correct_exact_filtered,\n",
    "        \"CorrectSplitCount\": split_metrics_filtered[\"Exact\"],\n",
    "        \"SplitCount+1\": split_metrics_filtered[\"+1\"],\n",
    "        \"SplitCount-1\": split_metrics_filtered[\"-1\"],\n",
    "        \"SplitCount±1\": split_metrics_filtered[\"±1\"],\n",
    "        \"OverlapExactAndSplit\": correct_exact_filtered and split_metrics_filtered[\"Exact\"]\n",
    "    })\n",
    "\n",
    "results_full_df = pd.DataFrame(records_full)\n",
    "results_filtered_df = pd.DataFrame(records_filtered)\n",
    "\n",
    "# =========================\n",
    "# COMPUTE AGGREGATE METRICS FOR BOTH MODELS\n",
    "# =========================\n",
    "# Calculate overall accuracy and split-count metrics for comparison\n",
    "\n",
    "# Model 1 (Full) metrics\n",
    "accuracy_full = results_full_df[\"CorrectExactSeg\"].mean()\n",
    "split_exact_full = results_full_df[\"CorrectSplitCount\"].mean()\n",
    "split_plus1_full = results_full_df[\"SplitCount+1\"].mean()\n",
    "split_minus1_full = results_full_df[\"SplitCount-1\"].mean()\n",
    "split_pm1_full = results_full_df[\"SplitCount±1\"].mean()\n",
    "overlap_full = results_full_df[\"OverlapExactAndSplit\"].mean()\n",
    "\n",
    "# Model 2 (Filtered) metrics\n",
    "accuracy_filtered = results_filtered_df[\"CorrectExactSeg\"].mean()\n",
    "split_exact_filtered = results_filtered_df[\"CorrectSplitCount\"].mean()\n",
    "split_plus1_filtered = results_filtered_df[\"SplitCount+1\"].mean()\n",
    "split_minus1_filtered = results_filtered_df[\"SplitCount-1\"].mean()\n",
    "split_pm1_filtered = results_filtered_df[\"SplitCount±1\"].mean()\n",
    "overlap_filtered = results_filtered_df[\"OverlapExactAndSplit\"].mean()\n",
    "\n",
    "# =========================\n",
    "# COMPARISON RESULTS\n",
    "# =========================\n",
    "# Print side-by-side comparison of both models\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON: FULL DATASET vs FILTERED DATASET (OUTLIERS REMOVED)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThis experiment tests whether removing statistical outliers improves model performance.\")\n",
    "print(f\"Outliers removed: {len(gold_df) - len(filtered_df):,} examples ({100*(len(gold_df) - len(filtered_df))/len(gold_df):.1f}% of data)\")\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(f\"{'Metric':<30} {'Model 1 (Full)':<20} {'Model 2 (Filtered)':<20} {'Difference':<15}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'Exact Segmentation Accuracy':<30} {accuracy_full:<20.4f} {accuracy_filtered:<20.4f} {accuracy_filtered-accuracy_full:+.4f}\")\n",
    "print(f\"{'Split-count (Exact)':<30} {split_exact_full:<20.4f} {split_exact_filtered:<20.4f} {split_exact_filtered-split_exact_full:+.4f}\")\n",
    "print(f\"{'Split-count (+1)':<30} {split_plus1_full:<20.4f} {split_plus1_filtered:<20.4f} {split_plus1_filtered-split_plus1_full:+.4f}\")\n",
    "print(f\"{'Split-count (−1)':<30} {split_minus1_full:<20.4f} {split_minus1_filtered:<20.4f} {split_minus1_filtered-split_minus1_full:+.4f}\")\n",
    "print(f\"{'Split-count (±1)':<30} {split_pm1_full:<20.4f} {split_pm1_filtered:<20.4f} {split_pm1_filtered-split_pm1_full:+.4f}\")\n",
    "print(f\"{'Overlap (Exact ∩ Split)':<30} {overlap_full:<20.4f} {overlap_filtered:<20.4f} {overlap_filtered-overlap_full:+.4f}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Determine which model performs better\n",
    "if accuracy_filtered > accuracy_full:\n",
    "    print(f\"\\n✓ Model 2 (FILTERED) performs BETTER than Model 1 (FULL)\")\n",
    "    print(f\"  Improvement: {100*(accuracy_filtered-accuracy_full):.2f} percentage points\")\n",
    "    print(\"  Conclusion: Removing outliers HELPS model performance\")\n",
    "elif accuracy_filtered < accuracy_full:\n",
    "    print(f\"\\n✗ Model 2 (FILTERED) performs WORSE than Model 1 (FULL)\")\n",
    "    print(f\"  Decrease: {100*(accuracy_full-accuracy_filtered):.2f} percentage points\")\n",
    "    print(\"  Conclusion: Removing outliers HURTS model performance\")\n",
    "else:\n",
    "    print(f\"\\n= Model 2 (FILTERED) performs the SAME as Model 1 (FULL)\")\n",
    "    print(\"  Conclusion: Removing outliers has NO EFFECT on model performance\")\n",
    "\n",
    "# =========================\n",
    "# SAVE EVALUATION RESULTS\n",
    "# =========================\n",
    "# Save evaluation results for both models to the data folder\n",
    "\n",
    "results_full_path = os.path.join(DATA_FOLDER, \"stats_model_full_eval_results.csv\")\n",
    "results_filtered_path = os.path.join(DATA_FOLDER, \"stats_model_filtered_eval_results.csv\")\n",
    "\n",
    "results_full_df.to_csv(results_full_path, index=False)\n",
    "results_filtered_df.to_csv(results_filtered_path, index=False)\n",
    "\n",
    "print(f\"\\nEvaluation results saved:\")\n",
    "print(f\"  Model 1 (Full): {results_full_path}\")\n",
    "print(f\"  Model 2 (Filtered): {results_filtered_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b19e335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
