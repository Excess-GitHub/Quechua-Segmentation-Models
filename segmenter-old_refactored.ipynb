{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "640ad99e",
   "metadata": {},
   "source": [
    "# Segmenter-Old: Character-Level BiLSTM Morphology Parser\n",
    "\n",
    "Character-level BiLSTM for Quechua morphological segmentation. Predicts boundary positions at the character level, marking where morpheme boundaries occur within words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1cb418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import ast\n",
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ML & DL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d622b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_FOLDER = \"data\"\n",
    "MODEL_NAME = \"segmenter-old\"\n",
    "MODELS_FOLDER = f\"models_{MODEL_NAME}\"\n",
    "os.makedirs(DATA_FOLDER, exist_ok=True)\n",
    "os.makedirs(MODELS_FOLDER, exist_ok=True)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "# Special tokens\n",
    "PAD, UNK = \"<PAD>\", \"<UNK>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eb86f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gold standard data\n",
    "print(\"loading gold data...\")\n",
    "gold_df = pd.read_parquet(os.path.join(DATA_FOLDER, \"Sue_kalt.parquet\"))\n",
    "gold_df['Word'] = gold_df['word']\n",
    "gold_df['morph'] = gold_df['morph'].str.replace('-', ' ')\n",
    "gold_df['Morph_split_str'] = gold_df['morph']\n",
    "gold_df['Morph_split'] = gold_df['morph'].str.split(' ')\n",
    "gold_df = gold_df[['Word', 'Morph_split', 'Morph_split_str']]\n",
    "gold_df.drop_duplicates(subset='Word', keep='first', inplace=True)\n",
    "gold_df.dropna(subset=['Word'], inplace=True)\n",
    "print(f\"got {len(gold_df):,} gold examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c941574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract basic features\n",
    "gold_df['num_morphemes'] = gold_df['Morph_split'].apply(len)\n",
    "gold_df['word_len'] = gold_df['Word'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d40ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_labels(word, split):\n",
    "    \"\"\"Generate binary boundary labels for a word given its morpheme split.\"\"\"\n",
    "    labels = [0] * len(word)\n",
    "    idx = 0\n",
    "    for morpheme in split[:-1]:\n",
    "        idx += len(morpheme)\n",
    "        if idx < len(word):\n",
    "            labels[idx - 1] = 1\n",
    "    return labels\n",
    "\n",
    "# Prepare training data\n",
    "gold_df['char_seq'] = gold_df['Word'].apply(list)\n",
    "gold_df['boundary_labels'] = gold_df.apply(\n",
    "    lambda row: get_boundary_labels(row['Word'], row['Morph_split']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda9813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(seqs: List[List[str]]):\n",
    "    \"\"\"Build vocabulary from character sequences.\"\"\"\n",
    "    chars = {c for seq in seqs for c in seq}\n",
    "    itos = [PAD, UNK] + sorted(chars)\n",
    "    stoi = {ch: i for i, ch in enumerate(itos)}\n",
    "    return stoi, itos\n",
    "\n",
    "stoi, itos = build_vocab(gold_df[\"char_seq\"].tolist())\n",
    "print(f\"vocab size: {len(itos)} characters\")\n",
    "\n",
    "def encode(seq: List[str]) -> List[int]:\n",
    "    \"\"\"Convert character sequence to integer IDs.\"\"\"\n",
    "    return [stoi.get(c, stoi[UNK]) for c in seq]\n",
    "\n",
    "def encode_labels(labels: List[int]) -> List[int]:\n",
    "    \"\"\"Labels are already 0/1.\"\"\"\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb3c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharBoundaryDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for character-level boundary prediction.\"\"\"\n",
    "    def __init__(self, df):\n",
    "        self.x = df[\"char_seq\"].tolist()\n",
    "        self.y = df[\"boundary_labels\"].tolist()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "def pad_batch(batch, pad_id=0):\n",
    "    \"\"\"Collate function: pads sequences to the same length.\"\"\"\n",
    "    seqs, labels = zip(*batch)\n",
    "    x_ids = [encode(s) for s in seqs]\n",
    "    y_ids = [encode_labels(y) for y in labels]\n",
    "    lengths = [len(x) for x in x_ids]\n",
    "    maxlen = max(lengths)\n",
    "    \n",
    "    x_pad = [xi + [pad_id] * (maxlen - len(xi)) for xi in x_ids]\n",
    "    y_pad = [yi + [0] * (maxlen - len(yi)) for yi in y_ids]\n",
    "    mask = [[1] * len(xi) + [0] * (maxlen - len(xi)) for xi in x_ids]\n",
    "    \n",
    "    return (\n",
    "        torch.LongTensor(x_pad),\n",
    "        torch.FloatTensor(y_pad),\n",
    "        torch.BoolTensor(mask),\n",
    "        torch.LongTensor(lengths),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a7acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation split\n",
    "rng = np.random.default_rng(42)\n",
    "indices = np.arange(len(gold_df))\n",
    "rng.shuffle(indices)\n",
    "split = int(0.9 * len(indices))\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "\n",
    "train_df = gold_df.iloc[train_idx].reset_index(drop=True)\n",
    "val_df = gold_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "print(f\"training: {len(train_df):,} samples\")\n",
    "print(f\"validation: {len(val_df):,} samples\")\n",
    "\n",
    "train_ds = CharBoundaryDataset(train_df)\n",
    "val_ds = CharBoundaryDataset(val_df)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=pad_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731b106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMBoundary(nn.Module):\n",
    "    \"\"\"Bidirectional LSTM for character-level boundary prediction.\"\"\"\n",
    "    def __init__(self, vocab_size: int, emb_dim: int = 16, hidden_size: int = 16,\n",
    "                 num_layers: int = 1, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(hidden_size * 2, 1)\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"Forward pass through the model.\"\"\"\n",
    "        emb = self.emb(x)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.lstm(packed)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "        out = self.dropout(out)\n",
    "        logits = self.out(out).squeeze(-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fbadc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_bce_loss(logits, targets, mask):\n",
    "    \"\"\"Compute masked binary cross-entropy loss.\"\"\"\n",
    "    loss_fn = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    loss_per_token = loss_fn(logits, targets)\n",
    "    loss_per_token = loss_per_token * mask.float()\n",
    "    denom = mask.float().sum().clamp_min(1.0)\n",
    "    return loss_per_token.sum() / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_f1(logits, targets, mask, threshold=0.5):\n",
    "    \"\"\"Compute precision, recall, and F1 for boundary prediction.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= threshold).long()\n",
    "        t = targets.long()\n",
    "        m = mask.long()\n",
    "\n",
    "        tp = ((preds == 1) & (t == 1) & (m == 1)).sum().item()\n",
    "        fp = ((preds == 1) & (t == 0) & (m == 1)).sum().item()\n",
    "        fn = ((preds == 0) & (t == 1) & (m == 1)).sum().item()\n",
    "\n",
    "        prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        rec = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0.0\n",
    "        return prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e72ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_boundaries(words: List[str], model, stoi, threshold=0.5) -> List[List[int]]:\n",
    "    \"\"\"Predict boundary labels for a list of words.\"\"\"\n",
    "    model.eval()\n",
    "    char_lists = [list(w) for w in words]\n",
    "    x_ids = [[stoi.get(c, stoi[UNK]) for c in chars] for chars in char_lists]\n",
    "    lengths = [len(x) for x in x_ids]\n",
    "    maxlen = max(lengths)\n",
    "    pad_id = stoi[PAD]\n",
    "\n",
    "    x_pad = [xi + [pad_id] * (maxlen - len(xi)) for xi in x_ids]\n",
    "    mask = [[1] * len(xi) + [0] * (maxlen - len(xi)) for xi in x_ids]\n",
    "\n",
    "    x = torch.LongTensor(x_pad).to(device)\n",
    "    lengths_t = torch.LongTensor(lengths).to(device)\n",
    "    mask_t = torch.BoolTensor(mask).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x, lengths_t)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= threshold) & mask_t\n",
    "\n",
    "    out = []\n",
    "    for i, L in enumerate(lengths):\n",
    "        out.append(preds[i, :L].int().tolist())\n",
    "    return out\n",
    "\n",
    "def apply_boundaries(word: str, boundary_labels: List[int]) -> List[str]:\n",
    "    \"\"\"Reconstruct morphemes from word and boundary labels.\"\"\"\n",
    "    segs = []\n",
    "    start = 0\n",
    "    for i, b in enumerate(boundary_labels):\n",
    "        if b == 1:\n",
    "            segs.append(word[start:i+1])\n",
    "            start = i + 1\n",
    "    if start < len(word):\n",
    "        segs.append(word[start:])\n",
    "    return segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cedbe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_id(emb_dim, hidden_size, num_layers, dropout, epochs, batch_size, lr, weight_decay):\n",
    "    \"\"\"Hash training params to get unique model ID.\"\"\"\n",
    "    params_dict = {\n",
    "        'emb_dim': emb_dim,\n",
    "        'hidden_size': hidden_size,\n",
    "        'num_layers': num_layers,\n",
    "        'dropout': dropout,\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'lr': lr,\n",
    "        'weight_decay': weight_decay,\n",
    "        'vocab_size': len(itos)\n",
    "    }\n",
    "    params_str = json.dumps(params_dict, sort_keys=True)\n",
    "    return hashlib.md5(params_str.encode()).hexdigest()[:16]\n",
    "\n",
    "def save_model_checkpoint(model, stoi, itos, model_id, models_folder=MODELS_FOLDER):\n",
    "    \"\"\"Save model checkpoint.\"\"\"\n",
    "    model_dir = os.path.join(models_folder, model_id)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    checkpoint_path = os.path.join(model_dir, \"bilstm_char_boundary.pt\")\n",
    "    torch.save({\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"stoi\": stoi,\n",
    "        \"itos\": itos\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    metadata_path = os.path.join(model_dir, \"metadata.json\")\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            'model_id': model_id,\n",
    "            'vocab_size': len(itos),\n",
    "            'model_name': MODEL_NAME\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"saved checkpoint to {model_dir}\")\n",
    "    return model_dir\n",
    "\n",
    "def load_model_checkpoint(model_id, models_folder=MODELS_FOLDER):\n",
    "    \"\"\"Load model checkpoint.\"\"\"\n",
    "    model_dir = os.path.join(models_folder, model_id)\n",
    "    checkpoint_path = os.path.join(model_dir, \"bilstm_char_boundary.pt\")\n",
    "    \n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        return None\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    print(f\"loaded checkpoint from {model_dir}\")\n",
    "    return {\n",
    "        'model_state': checkpoint['model_state'],\n",
    "        'stoi': checkpoint['stoi'],\n",
    "        'itos': checkpoint['itos'],\n",
    "        'checkpoint_path': checkpoint_path,\n",
    "        'model_dir': model_dir\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07526873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "EMB_DIM = 16\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "EPOCHS = 35\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Generate model identifier\n",
    "model_id = generate_model_id(EMB_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT, EPOCHS, BATCH_SIZE, LR, WEIGHT_DECAY)\n",
    "\n",
    "# Try to load existing model\n",
    "print(f\"looking for model {model_id}...\")\n",
    "loaded = load_model_checkpoint(model_id, models_folder=MODELS_FOLDER)\n",
    "\n",
    "if loaded is not None:\n",
    "    print(f\"found it! loading from {loaded['model_dir']}\")\n",
    "    stoi = loaded['stoi']\n",
    "    itos = loaded['itos']\n",
    "    model = BiLSTMBoundary(vocab_size=len(itos), emb_dim=EMB_DIM, hidden_size=HIDDEN_SIZE,\n",
    "                           num_layers=NUM_LAYERS, dropout=DROPOUT).to(device)\n",
    "    model.load_state_dict(loaded['model_state'])\n",
    "    model.eval()\n",
    "    print(\"skipping training, model ready\")\n",
    "else:\n",
    "    print(f\"not found, training from scratch...\")\n",
    "    \n",
    "    model = BiLSTMBoundary(vocab_size=len(itos), emb_dim=EMB_DIM, hidden_size=HIDDEN_SIZE,\n",
    "                          num_layers=NUM_LAYERS, dropout=DROPOUT).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    best_val_f1 = 0.0\n",
    "    \n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_tokens = 0\n",
    "        for x, y, mask, lengths in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            mask = mask.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            logits = model(x, lengths)\n",
    "            loss = masked_bce_loss(logits, y, mask)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * mask.sum().item()\n",
    "            total_tokens += mask.sum().item()\n",
    "\n",
    "        train_loss = total_loss / max(total_tokens, 1)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_tokens = 0.0, 0\n",
    "        all_prec, all_rec, all_f1 = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y, mask, lengths in val_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                mask = mask.to(device)\n",
    "                lengths = lengths.to(device)\n",
    "\n",
    "                logits = model(x, lengths)\n",
    "                loss = masked_bce_loss(logits, y, mask)\n",
    "                val_loss += loss.item() * mask.sum().item()\n",
    "                val_tokens += mask.sum().item()\n",
    "\n",
    "                p, r, f = boundary_f1(logits, y, mask, threshold=0.5)\n",
    "                all_prec.append(p)\n",
    "                all_rec.append(r)\n",
    "                all_f1.append(f)\n",
    "\n",
    "        val_loss = val_loss / max(val_tokens, 1)\n",
    "        prec = np.mean(all_prec) if all_prec else 0.0\n",
    "        rec = np.mean(all_rec) if all_rec else 0.0\n",
    "        f1 = np.mean(all_f1) if all_f1 else 0.0\n",
    "\n",
    "        print(f\"epoch {epoch:02d} | train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  P={prec:.3f} R={rec:.3f} F1={f1:.3f}\")\n",
    "\n",
    "        if f1 > best_val_f1:\n",
    "            best_val_f1 = f1\n",
    "            save_model_checkpoint(model, stoi, itos, model_id, models_folder=MODELS_FOLDER)\n",
    "            print(\"  ↳ saved checkpoint (best F1 so far)\")\n",
    "    \n",
    "    print(f\"\\ntraining done! best validation F1: {best_val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731b7b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_cross_validation(\n",
    "    df,\n",
    "    n_folds=5,\n",
    "    emb_dim=16,\n",
    "    hidden_size=32,\n",
    "    num_layers=2,\n",
    "    dropout=0.3,\n",
    "    epochs=35,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    random_state=42,\n",
    "    device=device\n",
    "):\n",
    "    \"\"\"K-fold cross-validation for more robust evaluation.\"\"\"\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"K-FOLD CV (k={n_folds})\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    indices = np.arange(len(df))\n",
    "    \n",
    "    fold_results = []\n",
    "    all_metrics = {\n",
    "        'boundary_precision': [],\n",
    "        'boundary_recall': [],\n",
    "        'boundary_f1': [],\n",
    "        'val_loss': []\n",
    "    }\n",
    "    \n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(kfold.split(indices), 1):\n",
    "        print(f\"\\n--- fold {fold_idx}/{n_folds} ---\")\n",
    "        print(f\"train: {len(train_indices)}, val: {len(val_indices)}\")\n",
    "        \n",
    "        train_df_fold = df.iloc[train_indices].reset_index(drop=True)\n",
    "        val_df_fold = df.iloc[val_indices].reset_index(drop=True)\n",
    "        \n",
    "        stoi_fold, itos_fold = build_vocab(train_df_fold[\"char_seq\"].tolist())\n",
    "        vocab_size = len(itos_fold)\n",
    "        \n",
    "        train_ds_fold = CharBoundaryDataset(train_df_fold)\n",
    "        val_ds_fold = CharBoundaryDataset(val_df_fold)\n",
    "        train_loader_fold = DataLoader(train_ds_fold, batch_size=batch_size, shuffle=True, collate_fn=pad_batch)\n",
    "        val_loader_fold = DataLoader(val_ds_fold, batch_size=batch_size, shuffle=False, collate_fn=pad_batch)\n",
    "        \n",
    "        model_fold = BiLSTMBoundary(\n",
    "            vocab_size=vocab_size,\n",
    "            emb_dim=emb_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer_fold = torch.optim.AdamW(model_fold.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        \n",
    "        best_val_f1 = 0.0\n",
    "        best_val_prec = 0.0\n",
    "        best_val_rec = 0.0\n",
    "        best_val_loss = float('inf')\n",
    "        best_epoch = 0\n",
    "        \n",
    "        for epoch in range(1, epochs + 1):\n",
    "            model_fold.train()\n",
    "            total_loss = 0.0\n",
    "            total_tokens = 0\n",
    "            for x, y, mask, lengths in train_loader_fold:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                mask = mask.to(device)\n",
    "                lengths = lengths.to(device)\n",
    "                \n",
    "                logits = model_fold(x, lengths)\n",
    "                loss = masked_bce_loss(logits, y, mask)\n",
    "                \n",
    "                optimizer_fold.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model_fold.parameters(), 1.0)\n",
    "                optimizer_fold.step()\n",
    "                \n",
    "                total_loss += loss.item() * mask.sum().item()\n",
    "                total_tokens += mask.sum().item()\n",
    "            \n",
    "            train_loss = total_loss / max(total_tokens, 1)\n",
    "            \n",
    "            model_fold.eval()\n",
    "            val_loss, val_tokens = 0.0, 0\n",
    "            all_prec, all_rec, all_f1 = [], [], []\n",
    "            with torch.no_grad():\n",
    "                for x, y, mask, lengths in val_loader_fold:\n",
    "                    x = x.to(device)\n",
    "                    y = y.to(device)\n",
    "                    mask = mask.to(device)\n",
    "                    lengths = lengths.to(device)\n",
    "                    \n",
    "                    logits = model_fold(x, lengths)\n",
    "                    loss = masked_bce_loss(logits, y, mask)\n",
    "                    val_loss += loss.item() * mask.sum().item()\n",
    "                    val_tokens += mask.sum().item()\n",
    "                    \n",
    "                    p, r, f = boundary_f1(logits, y, mask, threshold=0.5)\n",
    "                    all_prec.append(p)\n",
    "                    all_rec.append(r)\n",
    "                    all_f1.append(f)\n",
    "            \n",
    "            val_loss = val_loss / max(val_tokens, 1)\n",
    "            prec = np.mean(all_prec) if all_prec else 0.0\n",
    "            rec = np.mean(all_rec) if all_rec else 0.0\n",
    "            f1 = np.mean(all_f1) if all_f1 else 0.0\n",
    "            \n",
    "            print(f\"  ep {epoch:02d} | train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  P={prec:.3f} R={rec:.3f} F1={f1:.3f}\")\n",
    "            \n",
    "            if f1 > best_val_f1 or (np.isclose(f1, best_val_f1) and val_loss < best_val_loss):\n",
    "                best_val_f1 = f1\n",
    "                best_val_prec = prec\n",
    "                best_val_rec = rec\n",
    "                best_val_loss = val_loss\n",
    "                best_epoch = epoch\n",
    "        \n",
    "        print(f\"\\n  best epoch: {best_epoch}\")\n",
    "        print(f\"  best validation: P={best_val_prec:.3f} R={best_val_rec:.3f} F1={best_val_f1:.3f} Loss={best_val_loss:.4f}\")\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold_idx,\n",
    "            'boundary_precision': best_val_prec,\n",
    "            'boundary_recall': best_val_rec,\n",
    "            'boundary_f1': best_val_f1,\n",
    "            'val_loss': best_val_loss,\n",
    "            'best_epoch': best_epoch\n",
    "        })\n",
    "        \n",
    "        all_metrics['boundary_precision'].append(best_val_prec)\n",
    "        all_metrics['boundary_recall'].append(best_val_rec)\n",
    "        all_metrics['boundary_f1'].append(best_val_f1)\n",
    "        all_metrics['val_loss'].append(best_val_loss)\n",
    "    \n",
    "    mean_metrics = {k: np.mean(v) for k, v in all_metrics.items()}\n",
    "    std_metrics = {k: np.std(v) for k, v in all_metrics.items()}\n",
    "    best_fold_idx = max(range(len(fold_results)), key=lambda i: fold_results[i]['boundary_f1'])\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"CV SUMMARY\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    for r in fold_results:\n",
    "        print(f\"  fold {r['fold']}: P={r['boundary_precision']:.3f}, R={r['boundary_recall']:.3f}, \"\n",
    "              f\"F1={r['boundary_f1']:.3f}, Loss={r['val_loss']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nmean +/- std over {n_folds} folds:\")\n",
    "    print(f\"  precision: {mean_metrics['boundary_precision']:.3f} +/- {std_metrics['boundary_precision']:.3f}\")\n",
    "    print(f\"  recall:    {mean_metrics['boundary_recall']:.3f} +/- {std_metrics['boundary_recall']:.3f}\")\n",
    "    print(f\"  F1:        {mean_metrics['boundary_f1']:.3f} +/- {std_metrics['boundary_f1']:.3f}\")\n",
    "    print(f\"  loss:      {mean_metrics['val_loss']:.4f} +/- {std_metrics['val_loss']:.4f}\")\n",
    "    print(f\"\\nbest fold: {fold_results[best_fold_idx]['fold']} (F1={fold_results[best_fold_idx]['boundary_f1']:.3f})\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'fold_results': fold_results,\n",
    "        'mean_metrics': mean_metrics,\n",
    "        'std_metrics': std_metrics,\n",
    "        'best_fold_idx': best_fold_idx,\n",
    "        'all_metrics': all_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c33202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run k-fold cross-validation\n",
    "kfold_results = run_kfold_cross_validation(\n",
    "    df=gold_df,\n",
    "    n_folds=5,\n",
    "    emb_dim=EMB_DIM,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    random_state=42,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"\\navg boundary F1: {kfold_results['mean_metrics']['boundary_f1']:.3f} +/- {kfold_results['std_metrics']['boundary_f1']:.3f}\")\n",
    "print(f\"avg precision: {kfold_results['mean_metrics']['boundary_precision']:.3f} +/- {kfold_results['std_metrics']['boundary_precision']:.3f}\")\n",
    "print(f\"avg recall: {kfold_results['mean_metrics']['boundary_recall']:.3f} +/- {kfold_results['std_metrics']['boundary_recall']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655abfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_positions_from_labels(labels):\n",
    "    \"\"\"Convert per-char boundary labels to boundary positions.\"\"\"\n",
    "    if not labels:\n",
    "        return set()\n",
    "    L = len(labels)\n",
    "    return {i for i in range(min(L-1, len(labels))) if labels[i] == 1}\n",
    "\n",
    "def boundary_positions_from_segments(segments):\n",
    "    \"\"\"Convert a list of segments into boundary positions.\"\"\"\n",
    "    pos = set()\n",
    "    acc = 0\n",
    "    for k, seg in enumerate(segments):\n",
    "        acc += len(seg)\n",
    "        if k < len(segments) - 1:\n",
    "            pos.add(acc - 1)\n",
    "    return pos\n",
    "\n",
    "def prf_from_sets(pred_set, gold_set):\n",
    "    \"\"\"Compute precision, recall, F1 from boundary sets.\"\"\"\n",
    "    tp = len(pred_set & gold_set)\n",
    "    fp = len(pred_set - gold_set)\n",
    "    fn = len(gold_set - pred_set)\n",
    "    \n",
    "    if tp + fp == 0:\n",
    "        precision = 1.0 if tp + fp + fn == 0 else 0.0\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "    \n",
    "    if tp + fn == 0:\n",
    "        recall = 1.0 if tp + fp + fn == 0 else 0.0\n",
    "    else:\n",
    "        recall = tp / (tp + fn)\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        f1 = 1.0 if tp + fp + fn == 0 else 0.0\n",
    "    else:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return tp, fp, fn, precision, recall, f1\n",
    "\n",
    "def best_variant_metrics(pred_boundaries, gold_variants):\n",
    "    \"\"\"Among multiple gold segmentations, pick the one that maximizes F1.\"\"\"\n",
    "    best = None\n",
    "    for variant in gold_variants:\n",
    "        gold_b = boundary_positions_from_segments(variant)\n",
    "        tp, fp, fn, P, R, F1 = prf_from_sets(pred_boundaries, gold_b)\n",
    "        key = (F1, tp, -fn, -fp)\n",
    "        if (best is None) or (key > best[0]):\n",
    "            best = (key, gold_b, tp, fp, fn, P, R, F1)\n",
    "    \n",
    "    if best is None:\n",
    "        gold_b = set()\n",
    "        tp, fp, fn, P, R, F1 = prf_from_sets(pred_boundaries, gold_b)\n",
    "        return gold_b, tp, fp, fn, P, R, F1\n",
    "    \n",
    "    _, gold_b, tp, fp, fn, P, R, F1 = best\n",
    "    return gold_b, tp, fp, fn, P, R, F1\n",
    "\n",
    "def is_correct_prediction(predicted, gold_variants):\n",
    "    \"\"\"Check if predicted segmentation matches any gold variant.\"\"\"\n",
    "    return any(predicted == variant for variant in gold_variants)\n",
    "\n",
    "def normalize_gold_variants(gold_variants):\n",
    "    \"\"\"Convert gold_variants to proper list format.\"\"\"\n",
    "    if gold_variants is None:\n",
    "        return []\n",
    "    if isinstance(gold_variants, np.ndarray):\n",
    "        gold_variants = gold_variants.tolist()\n",
    "    if isinstance(gold_variants, list):\n",
    "        normalized = []\n",
    "        for variant in gold_variants:\n",
    "            if isinstance(variant, np.ndarray):\n",
    "                normalized.append(variant.tolist())\n",
    "            elif isinstance(variant, list):\n",
    "                normalized.append([item.tolist() if isinstance(item, np.ndarray) else item for item in variant])\n",
    "            else:\n",
    "                normalized.append(variant)\n",
    "        return normalized\n",
    "    return []\n",
    "\n",
    "def split_count_metrics(predicted_segments, gold_variants):\n",
    "    \"\"\"Compute split-count accuracy variants.\"\"\"\n",
    "    pred_count = len(predicted_segments)\n",
    "    gold_counts = [len(gold) for gold in gold_variants]\n",
    "\n",
    "    exact = any(pred_count == g for g in gold_counts)\n",
    "    plus1 = any(pred_count == g + 1 for g in gold_counts)\n",
    "    minus1 = any(pred_count == g - 1 for g in gold_counts)\n",
    "    pm1 = any(abs(pred_count - g) <= 1 for g in gold_counts)\n",
    "\n",
    "    return {\"Exact\": exact, \"+1\": plus1, \"-1\": minus1, \"±1\": pm1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed52014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "print(\"loading test data...\")\n",
    "df = pd.read_parquet(os.path.join(DATA_FOLDER, \"cleaned_data_df.parquet\"))\n",
    "print(f\"loaded {len(df):,} test examples\")\n",
    "\n",
    "# Load trained model\n",
    "EMB_DIM = 16\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "EPOCHS = 35\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "model_id = generate_model_id(EMB_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT, EPOCHS, BATCH_SIZE, LR, WEIGHT_DECAY)\n",
    "\n",
    "loaded = load_model_checkpoint(model_id, models_folder=MODELS_FOLDER)\n",
    "if loaded is None:\n",
    "    raise FileNotFoundError(f\"model checkpoint not found (model_id: {model_id})\")\n",
    "\n",
    "stoi, itos = loaded[\"stoi\"], loaded[\"itos\"]\n",
    "model = BiLSTMBoundary(vocab_size=len(itos), emb_dim=EMB_DIM, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS)\n",
    "model.load_state_dict(loaded[\"model_state\"])\n",
    "model.eval()\n",
    "print(\"model loaded for evaluation\")\n",
    "\n",
    "# Evaluate on test set\n",
    "all_words = df[\"Word\"].tolist()\n",
    "all_boundaries = predict_boundaries(all_words, model, stoi, threshold=0.5)\n",
    "\n",
    "results = []\n",
    "micro_tp = micro_fp = micro_fn = 0\n",
    "macro_Ps, macro_Rs, macro_F1s = [], [], []\n",
    "\n",
    "for word, gold_variants, boundary_labels in zip(all_words, df[\"Gold\"], all_boundaries):\n",
    "    gold_variants = normalize_gold_variants(gold_variants)\n",
    "\n",
    "    pred_b = boundary_positions_from_labels(boundary_labels)\n",
    "    gold_b, tp, fp, fn, P, R, F1 = best_variant_metrics(pred_b, gold_variants)\n",
    "\n",
    "    predicted_segments = apply_boundaries(word, boundary_labels)\n",
    "    correct = is_correct_prediction(predicted_segments, gold_variants)\n",
    "\n",
    "    results.append({\n",
    "        \"Word\": word,\n",
    "        \"Prediction\": predicted_segments,\n",
    "        \"Gold\": gold_variants,\n",
    "        \"PredBoundaries\": sorted(pred_b),\n",
    "        \"GoldBoundaries(Chosen)\": sorted(gold_b),\n",
    "        \"TP\": tp, \"FP\": fp, \"FN\": fn,\n",
    "        \"P_word\": P, \"R_word\": R, \"F1_word\": F1,\n",
    "        \"CorrectExactSeg\": correct\n",
    "    })\n",
    "\n",
    "    micro_tp += tp\n",
    "    micro_fp += fp\n",
    "    micro_fn += fn\n",
    "    macro_Ps.append(P)\n",
    "    macro_Rs.append(R)\n",
    "    macro_F1s.append(F1)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "accuracy = results_df[\"CorrectExactSeg\"].mean()\n",
    "\n",
    "if micro_tp + micro_fp == 0:\n",
    "    P_micro = 1.0 if micro_tp + micro_fn == 0 else 0.0\n",
    "else:\n",
    "    P_micro = micro_tp / (micro_tp + micro_fp)\n",
    "\n",
    "if micro_tp + micro_fn == 0:\n",
    "    R_micro = 1.0 if micro_tp + micro_fp == 0 else 0.0\n",
    "else:\n",
    "    R_micro = micro_tp / (micro_tp + micro_fn)\n",
    "\n",
    "if P_micro + R_micro == 0:\n",
    "    F1_micro = 1.0 if (micro_tp + micro_fp + micro_fn) == 0 else 0.0\n",
    "else:\n",
    "    F1_micro = 2 * P_micro * R_micro / (P_micro + R_micro)\n",
    "\n",
    "P_macro = float(pd.Series(macro_Ps).mean()) if macro_Ps else 0.0\n",
    "R_macro = float(pd.Series(macro_Rs).mean()) if macro_Rs else 0.0\n",
    "F1_macro = float(pd.Series(macro_F1s).mean()) if macro_F1s else 0.0\n",
    "\n",
    "print(f\"exact segmentation accuracy: {accuracy:.4f}\")\n",
    "print(\"boundary metrics:\")\n",
    "print(f\"  micro  - P: {P_micro:.4f}  R: {R_micro:.4f}  F1: {F1_micro:.4f}\")\n",
    "print(f\"  macro  - P: {P_macro:.4f}  R: {R_macro:.4f}  F1: {F1_macro:.4f}\")\n",
    "\n",
    "# Split-count metrics\n",
    "split_exact_flags = []\n",
    "split_plus1_flags = []\n",
    "split_minus1_flags = []\n",
    "split_pm1_flags = []\n",
    "overlap_flags = []\n",
    "\n",
    "for rec in results:\n",
    "    predicted_segments = rec[\"Prediction\"]\n",
    "    gold_variants = rec[\"Gold\"]\n",
    "    gold_variants = normalize_gold_variants(gold_variants)\n",
    "\n",
    "    split_metrics = split_count_metrics(predicted_segments, gold_variants)\n",
    "    rec[\"CorrectSplitCount\"] = split_metrics[\"Exact\"]\n",
    "    rec[\"SplitCount+1\"] = split_metrics[\"+1\"]\n",
    "    rec[\"SplitCount-1\"] = split_metrics[\"-1\"]\n",
    "    rec[\"SplitCount±1\"] = split_metrics[\"±1\"]\n",
    "\n",
    "    overlap = rec[\"CorrectExactSeg\"] and split_metrics[\"Exact\"]\n",
    "    rec[\"OverlapExactAndSplit\"] = overlap\n",
    "\n",
    "    split_exact_flags.append(split_metrics[\"Exact\"])\n",
    "    split_plus1_flags.append(split_metrics[\"+1\"])\n",
    "    split_minus1_flags.append(split_metrics[\"-1\"])\n",
    "    split_pm1_flags.append(split_metrics[\"±1\"])\n",
    "    overlap_flags.append(overlap)\n",
    "\n",
    "split_exact_acc = np.mean(split_exact_flags)\n",
    "split_plus1_acc = np.mean(split_plus1_flags)\n",
    "split_minus1_acc = np.mean(split_minus1_flags)\n",
    "split_pm1_acc = np.mean(split_pm1_flags)\n",
    "overlap_accuracy = np.mean(overlap_flags)\n",
    "\n",
    "print(\"\\n=== split-count metrics ===\")\n",
    "print(f\"split-count (exact):          {split_exact_acc:.4f}\")\n",
    "print(f\"split-count (+1):             {split_plus1_acc:.4f}\")\n",
    "print(f\"split-count (−1):             {split_minus1_acc:.4f}\")\n",
    "print(f\"split-count (±1):             {split_pm1_acc:.4f}\")\n",
    "print(f\"overlap (exact ∩ split):      {overlap_accuracy:.4f}\")\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_output_path = os.path.join(DATA_FOLDER, \"bilstm_eval_results.csv\")\n",
    "results_df.to_csv(results_output_path, index=False)\n",
    "print(f\"\\nevaluation results saved to {results_output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
