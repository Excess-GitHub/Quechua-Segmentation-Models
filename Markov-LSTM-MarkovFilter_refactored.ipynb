{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68a1a87a",
   "metadata": {},
   "source": [
    "# Markov-LSTM-Markov Filter: Quechua Morphology Parser\n",
    "\n",
    "Morphological segmentation for Quechua using:\n",
    "- BiLSTM for boundary prediction\n",
    "- HMM priors from suffix patterns\n",
    "- K-teacher regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7119aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "import math\n",
    "import hashlib\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Set, Tuple\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ML & DL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold, GroupShuffleSplit\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fbcc4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_FOLDER = \"data\"\n",
    "MODEL_NAME = \"Markov-LSTM-MarkovFilter\"\n",
    "MODELS_FOLDER = f\"models_{MODEL_NAME}\"\n",
    "os.makedirs(MODELS_FOLDER, exist_ok=True)\n",
    "\n",
    "# Synthetic data options: \"none\", \"gpt4o\", \"gpt5mini\"\n",
    "SYNTHETIC_DATA_CHOICE = \"none\"\n",
    "\n",
    "# Word selection for augmentation: \"all\", \"first\", \"random\"\n",
    "AUGMENTATION_WORD_SELECTION = \"random\"\n",
    "AUGMENTATION_N_WORDS = 100\n",
    "\n",
    "# Random seed\n",
    "RNG = 42\n",
    "torch.manual_seed(RNG)\n",
    "np.random.seed(RNG)\n",
    "\n",
    "# Feature columns used for privileged knowledge\n",
    "NEW_NUM_FEATS = [\n",
    "    \"Word_len\", \"Vowel_no\", \"Cons_no\",\n",
    "    \"Tail_cons_no\", \"Tail_vowel_no\",\n",
    "    \"No_splits\", \"YW_count\", \"Tail_YW_count\"\n",
    "]\n",
    "\n",
    "# Quechua graphemes for tokenization\n",
    "graphemes = [\n",
    "    \"ch\", \"ll\", \"rr\", \"tr\", \"kw\", \"ph\",\n",
    "    \"a\", \"b\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"k\", \"l\", \"m\", \"n\", \"ñ\", \"o\", \"p\", \"q\",\n",
    "    \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a04aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading gold data...\n",
      "got 6,896 gold examples\n"
     ]
    }
   ],
   "source": [
    "# Load the gold standard segmentations\n",
    "print(\"loading gold data...\")\n",
    "gold_df = pd.read_parquet(os.path.join(DATA_FOLDER, \"Sue_kalt.parquet\"))\n",
    "gold_df['Word'] = gold_df['word']\n",
    "gold_df['morph'] = gold_df['morph'].str.replace('-', ' ')\n",
    "gold_df['Morph_split_str'] = gold_df['morph']\n",
    "gold_df['Morph_split'] = gold_df['morph'].str.split(' ')\n",
    "gold_df = gold_df[['Word', 'Morph_split', 'Morph_split_str']]\n",
    "gold_df.drop_duplicates(subset='Word', keep='first', inplace=True)\n",
    "gold_df.dropna(subset=['Word'], inplace=True)\n",
    "print(f\"got {len(gold_df):,} gold examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36cc7f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no synthetic augmentation\n"
     ]
    }
   ],
   "source": [
    "def load_synthetic_data(choice):\n",
    "    \"\"\"Load GPT-generated segmentations if augmentation is enabled.\"\"\"\n",
    "    if choice == \"none\":\n",
    "        print(\"no synthetic augmentation\")\n",
    "        return None\n",
    "    \n",
    "    file_map = {\n",
    "        \"gpt4o\": \"gpt4o_synthetic_segmentations.csv\",\n",
    "        \"gpt5mini\": \"gpt5mini_synthetic_segmentations.csv\"\n",
    "    }\n",
    "    \n",
    "    if choice not in file_map:\n",
    "        print(f\"unknown choice '{choice}', skipping augmentation\")\n",
    "        return None\n",
    "    \n",
    "    file_path = os.path.join(DATA_FOLDER, file_map[choice])\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"file not found: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"loading synthetic data from {file_path}...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.drop_duplicates(subset=['Original_Word']).reset_index(drop=True)\n",
    "    \n",
    "    # Filter out garbage responses\n",
    "    bad_strings = ['can\\'t', 'quechua', 'sorry', 'could']\n",
    "    df = df[~df['Segmented_Morphemes'].str.contains('|'.join(bad_strings), case=False, na=False)]\n",
    "    \n",
    "    df = df.rename(columns={'Original_Word': 'Word'})\n",
    "    df['Morph_split_str'] = df['Segmented_Morphemes']\n",
    "    df['Morph_split'] = df['Segmented_Morphemes'].str.split(' ')\n",
    "    df = df[['Word', 'Morph_split', 'Morph_split_str']]\n",
    "    \n",
    "    print(f\"loaded {len(df):,} synthetic examples\")\n",
    "    return df\n",
    "\n",
    "synthetic_df = load_synthetic_data(SYNTHETIC_DATA_CHOICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fec71d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words in both GPT sets: 469\n"
     ]
    }
   ],
   "source": [
    "# Load GPT data separately for finding common words\n",
    "gpt_5_mini_df = pd.read_csv(os.path.join(DATA_FOLDER, \"gpt5mini_synthetic_segmentations.csv\"))\n",
    "gpt_5_mini_df = gpt_5_mini_df.drop_duplicates(subset=['Original_Word']).reset_index(drop=True)\n",
    "bad_strings = ['can\\'t', 'quechua', 'sorry', 'could']\n",
    "gpt_5_mini_df = gpt_5_mini_df[~gpt_5_mini_df['Segmented_Morphemes'].str.contains('|'.join(bad_strings), case=False, na=False)]\n",
    "gpt_5_mini_df = gpt_5_mini_df.rename(columns={'Original_Word': 'Word'})\n",
    "gpt_5_mini_df['Morph_split_str'] = gpt_5_mini_df['Segmented_Morphemes']\n",
    "gpt_5_mini_df['Morph_split'] = gpt_5_mini_df['Segmented_Morphemes'].str.split(' ')\n",
    "gpt_5_mini_df = gpt_5_mini_df[['Word', 'Morph_split', 'Morph_split_str']]\n",
    "\n",
    "gpt_4o_df = pd.read_csv(os.path.join(DATA_FOLDER, \"gpt4o_synthetic_segmentations.csv\"))\n",
    "gpt_4o_df = gpt_4o_df.drop_duplicates(subset=['Original_Word']).reset_index(drop=True)\n",
    "gpt_4o_df = gpt_4o_df[~gpt_4o_df['Segmented_Morphemes'].str.contains('|'.join(bad_strings), case=False, na=False)]\n",
    "gpt_4o_df = gpt_4o_df.rename(columns={'Original_Word': 'Word'})\n",
    "gpt_4o_df['Morph_split_str'] = gpt_4o_df['Segmented_Morphemes']\n",
    "gpt_4o_df['Morph_split'] = gpt_4o_df['Segmented_Morphemes'].str.split(' ')\n",
    "gpt_4o_df = gpt_4o_df[['Word', 'Morph_split', 'Morph_split_str']]\n",
    "\n",
    "gpt_5_mini_words = set(gpt_5_mini_df['Word'])\n",
    "gpt_4o_words = set(gpt_4o_df['Word'])\n",
    "common_words = gpt_4o_words.intersection(gpt_5_mini_words)\n",
    "print(f\"words in both GPT sets: {len(common_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fd29f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold data only (no augmentation)\n"
     ]
    }
   ],
   "source": [
    "# Merge synthetic with gold if augmentation is on\n",
    "if synthetic_df is not None:\n",
    "    gpt_5_mini_words = set(gpt_5_mini_df['Word'])\n",
    "    gpt_4o_words = set(gpt_4o_df['Word'])\n",
    "    common_words = gpt_4o_words.intersection(gpt_5_mini_words)\n",
    "    print(f\"common words between GPT models: {len(common_words):,}\")\n",
    "    \n",
    "    if AUGMENTATION_WORD_SELECTION == \"all\":\n",
    "        selected_words = common_words\n",
    "        print(f\"using all {len(selected_words):,} common words\")\n",
    "    elif AUGMENTATION_WORD_SELECTION == \"first\":\n",
    "        sorted_words = sorted(common_words)\n",
    "        n = min(AUGMENTATION_N_WORDS, len(sorted_words))\n",
    "        selected_words = set(sorted_words[:n])\n",
    "        print(f\"using first {n:,} words alphabetically\")\n",
    "    elif AUGMENTATION_WORD_SELECTION == \"random\":\n",
    "        import random\n",
    "        seed = RNG if 'RNG' in globals() else 42\n",
    "        random.seed(seed)\n",
    "        n = min(AUGMENTATION_N_WORDS, len(common_words))\n",
    "        selected_words = set(random.sample(list(common_words), n))\n",
    "        print(f\"using {n:,} random words\")\n",
    "    else:\n",
    "        print(f\"unknown selection '{AUGMENTATION_WORD_SELECTION}', using all\")\n",
    "        selected_words = common_words\n",
    "    \n",
    "    if SYNTHETIC_DATA_CHOICE in [\"gpt5mini\", \"gpt4o\"]:\n",
    "        df_sampled = synthetic_df[synthetic_df['Word'].isin(selected_words)]\n",
    "    else:\n",
    "        df_sampled = None\n",
    "    \n",
    "    if df_sampled is not None and len(df_sampled) > 0:\n",
    "        gold_df = pd.concat([df_sampled, gold_df], ignore_index=True)\n",
    "        print(f\"combined: {len(gold_df):,} total examples\")\n",
    "    else:\n",
    "        print(\"no synthetic data added\")\n",
    "else:\n",
    "    print(\"gold data only (no augmentation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30f8643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sampled words for reference\n",
    "if synthetic_df is not None and 'df_sampled' in locals() and df_sampled is not None:\n",
    "    df_sampled = df_sampled.sort_values(by=\"Word\")\n",
    "    output_file = os.path.join(DATA_FOLDER, f\"{SYNTHETIC_DATA_CHOICE}_common.parquet\")\n",
    "    df_sampled.to_parquet(output_file, index=False)\n",
    "    print(f\"saved common words to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6d09317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET SUMMARY\n",
      "============================================================\n",
      "training: (6896, 3)\n",
      "test: (913, 5)\n",
      "augmentation: none\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load test set\n",
    "acc_df = pd.read_parquet(os.path.join(DATA_FOLDER, \"cleaned_data_df.parquet\"))\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"training: {gold_df.shape}\")\n",
    "print(f\"test: {acc_df.shape}\")\n",
    "print(f\"augmentation: {SYNTHETIC_DATA_CHOICE}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f999fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"|\".join(sorted(graphemes, key=len, reverse=True)))\n",
    "\n",
    "def tokenize_morphemes(morphs):\n",
    "    \"\"\"Break morphemes into grapheme tokens.\"\"\"\n",
    "    return [pattern.findall(m.lower()) for m in morphs]\n",
    "\n",
    "gold_df[\"Char_split\"] = gold_df[\"Morph_split\"].apply(tokenize_morphemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcaed10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = {\"a\", \"i\", \"e\", \"o\", \"u\"}\n",
    "\n",
    "def grapheme_to_cv(grapheme):\n",
    "    return \"V\" if grapheme in vowels else \"C\"\n",
    "\n",
    "def morphs_to_cv(morphs):\n",
    "    \"\"\"Convert grapheme lists to CV (consonant/vowel) patterns.\"\"\"\n",
    "    return [[grapheme_to_cv(g) for g in morph] for morph in morphs]\n",
    "\n",
    "gold_df[\"CV_split\"] = gold_df[\"Char_split\"].apply(morphs_to_cv)\n",
    "\n",
    "def cv_to_string(cv_split):\n",
    "    \"\"\"Turn nested CV list into dash-separated string.\"\"\"\n",
    "    return \"-\".join(\"\".join(m) for m in cv_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2bbff92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full_chain</th>\n",
       "      <th>Trimmed_chain</th>\n",
       "      <th>Word</th>\n",
       "      <th>Char_split</th>\n",
       "      <th>Morph_split</th>\n",
       "      <th>Word_len</th>\n",
       "      <th>Vowel_no</th>\n",
       "      <th>Cons_no</th>\n",
       "      <th>Tail_cons_no</th>\n",
       "      <th>Tail_vowel_no</th>\n",
       "      <th>No_splits</th>\n",
       "      <th>YW_count</th>\n",
       "      <th>Tail_YW_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VCVCCVCVV-CVC</td>\n",
       "      <td>CVC</td>\n",
       "      <td>cementerioman</td>\n",
       "      <td>[[e, m, e, n, t, e, r, i, o], [m, a, n]]</td>\n",
       "      <td>[cementerio, man]</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVCCV-CCV-CV-C-CV</td>\n",
       "      <td>CCV-CV-C-CV</td>\n",
       "      <td>kawsachkananta</td>\n",
       "      <td>[[k, a, w, s, a], [ch, k, a], [n, a], [n], [t,...</td>\n",
       "      <td>[kawsa, chka, na, n, ta]</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVCV-CV-C-CVC</td>\n",
       "      <td>CV-C-CVC</td>\n",
       "      <td>mañakunpis</td>\n",
       "      <td>[[m, a, ñ, a], [k, u], [n], [p, i, s]]</td>\n",
       "      <td>[maña, ku, n, pis]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VCVCCV-CV-CVC</td>\n",
       "      <td>CV-CVC</td>\n",
       "      <td>imaynapichus</td>\n",
       "      <td>[[i, m, a, y, n, a], [p, i], [ch, u, s]]</td>\n",
       "      <td>[imayna, pi, chus]</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CVCV-CVC</td>\n",
       "      <td>CVC</td>\n",
       "      <td>qipiyuq</td>\n",
       "      <td>[[q, i, p, i], [y, u, q]]</td>\n",
       "      <td>[qipi, yuq]</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Full_chain Trimmed_chain            Word  \\\n",
       "0      VCVCCVCVV-CVC           CVC   cementerioman   \n",
       "1  CVCCV-CCV-CV-C-CV   CCV-CV-C-CV  kawsachkananta   \n",
       "2      CVCV-CV-C-CVC      CV-C-CVC      mañakunpis   \n",
       "3      VCVCCV-CV-CVC        CV-CVC    imaynapichus   \n",
       "4           CVCV-CVC           CVC         qipiyuq   \n",
       "\n",
       "                                          Char_split  \\\n",
       "0           [[e, m, e, n, t, e, r, i, o], [m, a, n]]   \n",
       "1  [[k, a, w, s, a], [ch, k, a], [n, a], [n], [t,...   \n",
       "2             [[m, a, ñ, a], [k, u], [n], [p, i, s]]   \n",
       "3           [[i, m, a, y, n, a], [p, i], [ch, u, s]]   \n",
       "4                          [[q, i, p, i], [y, u, q]]   \n",
       "\n",
       "                Morph_split  Word_len  Vowel_no  Cons_no  Tail_cons_no  \\\n",
       "0         [cementerio, man]        13         6        6             2   \n",
       "1  [kawsa, chka, na, n, ta]        14         5        8             5   \n",
       "2        [maña, ku, n, pis]        10         4        6             4   \n",
       "3        [imayna, pi, chus]        12         5        6             3   \n",
       "4               [qipi, yuq]         7         3        4             2   \n",
       "\n",
       "   Tail_vowel_no  No_splits  YW_count  Tail_YW_count  \n",
       "0              1          2         0              0  \n",
       "1              3          5         1              0  \n",
       "2              2          4         0              0  \n",
       "3              2          3         1              0  \n",
       "4              1          2         1              1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the feature dataframe\n",
    "str_df = pd.DataFrame()\n",
    "str_df[\"Full_chain\"] = gold_df[\"CV_split\"].apply(cv_to_string)\n",
    "str_df[\"Trimmed_chain\"] = str_df[\"Full_chain\"].apply(\n",
    "    lambda x: x.split(\"-\", 1)[1] if \"-\" in x else np.nan\n",
    ")\n",
    "str_df[\"Word\"] = gold_df[\"Word\"]\n",
    "str_df[\"Char_split\"] = gold_df[\"Char_split\"]\n",
    "str_df[\"Morph_split\"] = gold_df[\"Morph_split\"]\n",
    "str_df = str_df.dropna(subset=[\"Trimmed_chain\"]).reset_index(drop=True)\n",
    "\n",
    "# Numeric features\n",
    "str_df[\"Word_len\"] = str_df[\"Word\"].str.len()\n",
    "str_df[\"Vowel_no\"] = str_df[\"Full_chain\"].str.count(\"V\")\n",
    "str_df[\"Cons_no\"] = str_df[\"Full_chain\"].str.count(\"C\")\n",
    "str_df[\"Tail_cons_no\"] = str_df[\"Trimmed_chain\"].str.count(\"C\")\n",
    "str_df[\"Tail_vowel_no\"] = str_df[\"Trimmed_chain\"].str.count(\"V\")\n",
    "str_df[\"No_splits\"] = str_df[\"Morph_split\"].str.len()\n",
    "str_df[\"YW_count\"] = str_df[\"Word\"].str.count(\"[yw]\")\n",
    "str_df[\"Tail_YW_count\"] = str_df[\"Morph_split\"].apply(\n",
    "    lambda ms: sum(m.count(\"y\") + m.count(\"w\") for m in ms[1:])\n",
    ")\n",
    "\n",
    "str_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3688902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_list(x):\n",
    "    \"\"\"Handle various list-like formats from dataframes.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    s = str(x)\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except Exception:\n",
    "        s2 = s.replace(\"[[\", \"[['\").replace(\"]]\", \"']]\").replace(\"], [\", \"'],['\").replace(\", \", \"','\")\n",
    "        return ast.literal_eval(s2)\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    \"\"\"Flatten nested list into single list of strings.\"\"\"\n",
    "    out = []\n",
    "    for seg in list_of_lists:\n",
    "        out.extend(seg)\n",
    "    return [str(t) for t in out]\n",
    "\n",
    "def extract_priv_features_from_row(row, feat_names):\n",
    "    \"\"\"Pull numeric features from a row into a vector.\"\"\"\n",
    "    vec = []\n",
    "    for k in feat_names:\n",
    "        val = row[k] if (k in row and pd.notna(row[k])) else 0.0\n",
    "        try:\n",
    "            vec.append(float(val))\n",
    "        except Exception:\n",
    "            vec.append(0.0)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8e92113",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuffixHMMPrior:\n",
    "    \"\"\"\n",
    "    Forward-backward algorithm over a suffix vocabulary.\n",
    "    Gives boundary probabilities based on how well positions\n",
    "    align with known suffix patterns.\n",
    "    \"\"\"\n",
    "    def __init__(self, suffix_log_probs, max_suffix_len, unk_penalty=-15.0):\n",
    "        self.log_probs = suffix_log_probs\n",
    "        self.max_len = max_suffix_len\n",
    "        self.unk_penalty = unk_penalty\n",
    "        self.LOG_ZERO = -1e9\n",
    "\n",
    "    def _get_log_prob(self, segment):\n",
    "        return self.log_probs.get(segment, self.unk_penalty)\n",
    "\n",
    "    def _forward_pass(self, word):\n",
    "        n = len(word)\n",
    "        alpha = [self.LOG_ZERO] * (n + 1)\n",
    "        alpha[0] = 0.0\n",
    "\n",
    "        for i in range(1, n + 1):\n",
    "            log_sums = []\n",
    "            for j in range(max(0, i - self.max_len), i):\n",
    "                segment = word[j:i]\n",
    "                log_p_segment = self._get_log_prob(segment)\n",
    "                log_sums.append(alpha[j] + log_p_segment)\n",
    "            if log_sums:\n",
    "                alpha[i] = torch.logsumexp(torch.tensor(log_sums), dim=0).item()\n",
    "        return alpha\n",
    "\n",
    "    def _backward_pass(self, word):\n",
    "        n = len(word)\n",
    "        beta = [self.LOG_ZERO] * (n + 1)\n",
    "        beta[n] = 0.0\n",
    "\n",
    "        for i in range(n - 1, -1, -1):\n",
    "            log_sums = []\n",
    "            for j in range(i + 1, min(n + 1, i + self.max_len + 1)):\n",
    "                segment = word[i:j]\n",
    "                log_p_segment = self._get_log_prob(segment)\n",
    "                log_sums.append(beta[j] + log_p_segment)\n",
    "            if log_sums:\n",
    "                beta[i] = torch.logsumexp(torch.tensor(log_sums), dim=0).item()\n",
    "        return beta\n",
    "\n",
    "    def get_boundary_priors(self, word):\n",
    "        \"\"\"Compute P(boundary at position i | word) for each position.\"\"\"\n",
    "        n = len(word)\n",
    "        if n <= 1:\n",
    "            return []\n",
    "\n",
    "        alpha = self._forward_pass(word)\n",
    "        beta = self._backward_pass(word)\n",
    "        \n",
    "        log_total_prob = alpha[n]\n",
    "        if log_total_prob == self.LOG_ZERO:\n",
    "            return [0.0] * (n - 1)\n",
    "\n",
    "        log_priors = []\n",
    "        for i in range(1, n):\n",
    "            log_p_boundary = alpha[i] + beta[i]\n",
    "            log_priors.append(log_p_boundary)\n",
    "        \n",
    "        log_priors_tensor = torch.tensor(log_priors)\n",
    "        normalized_log_priors = log_priors_tensor - log_total_prob\n",
    "        return torch.exp(normalized_log_priors).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94dd80d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hmm_prior(samples):\n",
    "    \"\"\"Learn suffix probabilities from training segmentations.\"\"\"\n",
    "    suffix_counts = Counter()\n",
    "    max_suffix_len = 0\n",
    "    \n",
    "    for s in samples:\n",
    "        cs = s[\"tokens\"]\n",
    "        morph_lens = [len(seg) for seg in safe_list(s['y_morphs'])]\n",
    "        \n",
    "        current_idx = len(cs)\n",
    "        for morph_len in reversed(morph_lens[1:]):\n",
    "            start_idx = current_idx - morph_len\n",
    "            suffix_tokens = cs[start_idx:current_idx]\n",
    "            suffix_str = \"\".join(suffix_tokens)\n",
    "            suffix_counts[suffix_str] += 1\n",
    "            max_suffix_len = max(max_suffix_len, len(suffix_str))\n",
    "            current_idx = start_idx\n",
    "\n",
    "    total_suffix_obs = sum(suffix_counts.values())\n",
    "    \n",
    "    log_probs = {\n",
    "        suffix: math.log((count + 1) / (total_suffix_obs + len(suffix_counts)))\n",
    "        for suffix, count in suffix_counts.items()\n",
    "    }\n",
    "\n",
    "    avg_log_prob = sum(log_probs.values()) / len(log_probs) if log_probs else 0\n",
    "    unk_penalty = avg_log_prob * 1.5\n",
    "\n",
    "    print(f\"HMM: {len(log_probs)} suffixes, max len {max_suffix_len}, unk penalty {unk_penalty:.2f}\")\n",
    "    return SuffixHMMPrior(log_probs, max_suffix_len, unk_penalty=unk_penalty)\n",
    "\n",
    "def create_hmm_prior_from_list(allowed_suffixes: list, unk_penalty: float = -15.0):\n",
    "    \"\"\"Build HMM prior from a predefined suffix list instead of learning.\"\"\"\n",
    "    if not allowed_suffixes:\n",
    "        raise ValueError(\"suffix list can't be empty\")\n",
    "\n",
    "    suffix_log_probs = {suffix: 0.0 for suffix in allowed_suffixes}\n",
    "    max_suffix_len = len(max(allowed_suffixes, key=len))\n",
    "\n",
    "    print(f\"HMM: initialized with {len(allowed_suffixes)} suffixes, max len {max_suffix_len}\")\n",
    "    return SuffixHMMPrior(suffix_log_probs, max_suffix_len, unk_penalty=unk_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90ece557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_samples_with_priv(df, feat_names=NEW_NUM_FEATS):\n",
    "    \"\"\"Convert dataframe rows to sample dicts for training.\"\"\"\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        cs = safe_list(r[\"Char_split\"])\n",
    "        toks = flatten(cs)\n",
    "        lens = [len(seg) for seg in cs]\n",
    "        cut_idxs = set(np.cumsum(lens)[:-1].tolist())\n",
    "        y = [1 if (i + 1) in cut_idxs else 0 for i in range(len(toks) - 1)]\n",
    "        priv = extract_priv_features_from_row(r, feat_names)\n",
    "        gold_morphs = [\"\".join(seg) for seg in cs]\n",
    "        rows.append({\"tokens\": toks, \"y\": y, \"priv\": priv, \"y_morphs\": gold_morphs})\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f01cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_window(tokens, i, k_left=2, k_right=2):\n",
    "    \"\"\"Extract local context features around position i.\"\"\"\n",
    "    feats = {}\n",
    "    for k in range(1, k_left + 1):\n",
    "        idx = i - (k - 1)\n",
    "        feats[f\"L{k}\"] = tokens[idx] if idx >= 0 else \"<BOS>\"\n",
    "    for k in range(1, k_right + 1):\n",
    "        idx = i + k\n",
    "        feats[f\"R{k}\"] = tokens[idx] if idx < len(tokens) else \"<EOS>\"\n",
    "    \n",
    "    def is_vowel(ch):\n",
    "        return ch.lower() in \"aeiouáéíóú\"\n",
    "    \n",
    "    L1 = feats[\"L1\"]\n",
    "    R1 = feats[\"R1\"]\n",
    "    feats[\"L1_cv\"] = 'V' if is_vowel(L1[-1]) else 'C'\n",
    "    feats[\"R1_cv\"] = 'V' if (R1 != \"<EOS>\" and is_vowel(R1[0])) else 'C'\n",
    "    feats[\"L1_last\"] = L1[-1]\n",
    "    feats[\"R1_first\"] = R1[0] if R1 != \"<EOS>\" else \"<EOS>\"\n",
    "    return feats\n",
    "\n",
    "def prior_probs_for_sample(hmm_prior, tokens):\n",
    "    \"\"\"Get HMM boundary priors mapped to token positions.\"\"\"\n",
    "    if hmm_prior is None or len(tokens) <= 1:\n",
    "        return [0.5] * (max(len(tokens) - 1, 0))\n",
    "\n",
    "    word = \"\".join(tokens)\n",
    "    char_priors = hmm_prior.get_boundary_priors(word)\n",
    "\n",
    "    # Map character-level to token-level\n",
    "    token_boundary_indices = np.cumsum([len(t) for t in tokens[:-1]]) - 1\n",
    "    \n",
    "    token_priors = []\n",
    "    for idx in token_boundary_indices:\n",
    "        if 0 <= idx < len(char_priors):\n",
    "            token_priors.append(char_priors[idx])\n",
    "        else:\n",
    "            token_priors.append(0.5)\n",
    "\n",
    "    return token_priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "decddf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_k_teacher_priv(samples, feat_dim):\n",
    "    \"\"\"Train a regressor to predict number of cuts from features.\"\"\"\n",
    "    X = np.array([s[\"priv\"] for s in samples], dtype=float)\n",
    "    y = np.array([int(np.sum(s[\"y\"])) for s in samples], dtype=float)\n",
    "    reg = DecisionTreeRegressor(max_depth=6, min_samples_leaf=10, random_state=RNG)\n",
    "    reg.fit(X, y)\n",
    "    return reg\n",
    "\n",
    "def predict_k_hat_priv(reg, priv_batch):\n",
    "    \"\"\"Predict expected number of cuts for a batch.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        k = reg.predict(priv_batch.cpu().numpy())\n",
    "    return torch.tensor(k, dtype=torch.float32, device=priv_batch.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ac190d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(samples, min_freq=1):\n",
    "    \"\"\"Build token vocabulary from samples.\"\"\"\n",
    "    ctr = Counter()\n",
    "    for s in samples:\n",
    "        ctr.update(s[\"tokens\"])\n",
    "    vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "    for t, c in sorted(ctr.items(), key=lambda x: (-x[1], x[0])):\n",
    "        if c >= min_freq and t not in vocab:\n",
    "            vocab[t] = len(vocab)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "621fb70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegDataset(Dataset):\n",
    "    \"\"\"Dataset for boundary prediction training.\"\"\"\n",
    "    def __init__(self, samples, vocab, hmm_prior=None, feat_dim=0):\n",
    "        self.samples = samples\n",
    "        self.vocab = vocab\n",
    "        self.hmm_prior = hmm_prior\n",
    "        self.feat_dim = feat_dim\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        s = self.samples[idx]\n",
    "        tokens = s[\"tokens\"]\n",
    "        ids = [self.vocab.get(t, self.vocab[\"<UNK>\"]) for t in tokens]\n",
    "        y = s[\"y\"]\n",
    "        prior = prior_probs_for_sample(self.hmm_prior, tokens)\n",
    "        priv = s[\"priv\"] if self.feat_dim > 0 else []\n",
    "        return {\"ids\": ids, \"y\": y, \"prior\": prior, \"priv\": priv, \"tokens\": tokens}\n",
    "\n",
    "def collate(batch):\n",
    "    \"\"\"Collate samples into batched tensors.\"\"\"\n",
    "    maxT = max(len(b[\"ids\"]) for b in batch)\n",
    "    maxB = maxT - 1\n",
    "    B = len(batch)\n",
    "\n",
    "    ids = torch.full((B, maxT), 0, dtype=torch.long)\n",
    "    mask_tok = torch.zeros((B, maxT), dtype=torch.bool)\n",
    "    y = torch.full((B, maxB), -100, dtype=torch.long)\n",
    "    prior = torch.zeros((B, maxB), dtype=torch.float32)\n",
    "    mask_b = torch.zeros((B, maxB), dtype=torch.bool)\n",
    "\n",
    "    feat_dim = len(batch[0][\"priv\"]) if isinstance(batch[0][\"priv\"], list) else 0\n",
    "    priv = torch.zeros((B, feat_dim), dtype=torch.float32) if feat_dim > 0 else None\n",
    "\n",
    "    for i, b in enumerate(batch):\n",
    "        T = len(b[\"ids\"])\n",
    "        ids[i, :T] = torch.tensor(b[\"ids\"], dtype=torch.long)\n",
    "        mask_tok[i, :T] = True\n",
    "        if T > 1:\n",
    "            L = T - 1\n",
    "            y[i, :L] = torch.tensor(b[\"y\"], dtype=torch.long)\n",
    "            p = b[\"prior\"] if len(b[\"prior\"]) == L else [0.5] * L\n",
    "            prior[i, :L] = torch.tensor(p, dtype=torch.float32)\n",
    "            mask_b[i, :L] = True\n",
    "        if feat_dim > 0:\n",
    "            priv[i] = torch.tensor(b[\"priv\"], dtype=torch.float32)\n",
    "\n",
    "    return {\n",
    "        \"ids\": ids, \"mask_tok\": mask_tok,\n",
    "        \"y\": y, \"prior\": prior, \"mask_b\": mask_b,\n",
    "        \"priv\": priv\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b6a8ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMTagger(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional LSTM for boundary prediction.\n",
    "    Can fuse HMM prior via concatenation or logit addition.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, emb_dim=16, hidden_size=64, num_layers=2,\n",
    "                 use_prior=True, dropout=0.1, freeze_emb=False, fuse_mode=\"logit_add\"):\n",
    "        super().__init__()\n",
    "        self.use_prior = use_prior\n",
    "        self.fuse_mode = fuse_mode\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        if freeze_emb:\n",
    "            for p in self.emb.parameters():\n",
    "                p.requires_grad = False\n",
    "        lstm_dropout = dropout if num_layers > 1 else 0.0\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_dim, hidden_size=hidden_size // 2,\n",
    "            num_layers=num_layers, dropout=lstm_dropout,\n",
    "            bidirectional=True, batch_first=True\n",
    "        )\n",
    "        in_mlp = hidden_size + (1 if (use_prior and fuse_mode == \"concat\") else 0)\n",
    "        self.boundary_mlp = nn.Sequential(\n",
    "            nn.Linear(in_mlp, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size // 2, 2)\n",
    "        )\n",
    "        if use_prior and fuse_mode == \"logit_add\":\n",
    "            self.alpha = nn.Parameter(torch.tensor(1.0))\n",
    "\n",
    "    def forward(self, ids, prior, mask_tok):\n",
    "        emb = self.emb(ids)\n",
    "        h, _ = self.lstm(emb)\n",
    "        left = h[:, :-1, :]\n",
    "        if self.use_prior and self.fuse_mode == \"concat\":\n",
    "            feat = torch.cat([left, prior.unsqueeze(-1)], dim=-1)\n",
    "            return self.boundary_mlp(feat)\n",
    "        logits = self.boundary_mlp(left)\n",
    "        if self.use_prior and self.fuse_mode == \"logit_add\":\n",
    "            eps = 1e-6\n",
    "            p = prior.clamp(eps, 1 - eps)\n",
    "            prior_logit = torch.log(p) - torch.log(1 - p)\n",
    "            logits[..., 1] = logits[..., 1] + self.alpha * prior_logit\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "067a6af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_metrics_from_lists(probs_list, gold_list, thr=0.5):\n",
    "    \"\"\"Compute precision/recall/F1 for boundary prediction.\"\"\"\n",
    "    if not probs_list:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    p = torch.cat([t for t in probs_list if t.numel() > 0], dim=0).numpy()\n",
    "    g = torch.cat([t for t in gold_list if t.numel() > 0], dim=0).numpy()\n",
    "    pred = (p >= thr).astype(int)\n",
    "    P, R, F1, _ = precision_recall_fscore_support(g, pred, average='binary', zero_division=0)\n",
    "    return P, R, F1\n",
    "\n",
    "def exact_match_rate_from_lists(probs_list, gold_list, thr=0.5):\n",
    "    \"\"\"Fraction of words with perfectly predicted boundaries.\"\"\"\n",
    "    if not probs_list:\n",
    "        return 0.0\n",
    "    em = []\n",
    "    for p, g in zip(probs_list, gold_list):\n",
    "        if g.numel() == 0:\n",
    "            em.append(1.0)\n",
    "        else:\n",
    "            pred = (p.numpy() >= thr).astype(int)\n",
    "            em.append(float(np.array_equal(pred, g.numpy())))\n",
    "    return float(np.mean(em))\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, loader):\n",
    "    \"\"\"Run model on loader, return probability and gold lists.\"\"\"\n",
    "    model.eval()\n",
    "    probs_list, gold_list = [], []\n",
    "    for batch in loader:\n",
    "        logits = model(batch[\"ids\"], batch[\"prior\"], batch[\"mask_tok\"])\n",
    "        probs = torch.softmax(logits, dim=-1)[..., 1]\n",
    "        y = batch[\"y\"]\n",
    "        mask = batch[\"mask_b\"]\n",
    "        B = probs.shape[0]\n",
    "        for b in range(B):\n",
    "            L = int(mask[b].sum().item())\n",
    "            if L == 0:\n",
    "                probs_list.append(torch.empty(0))\n",
    "                gold_list.append(torch.empty(0, dtype=torch.long))\n",
    "            else:\n",
    "                probs_list.append(probs[b, :L].cpu())\n",
    "                gold_list.append(y[b, :L].cpu())\n",
    "    return probs_list, gold_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b2ad949",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "criterion_bce = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "mse = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "def train_epoch(model, loader, opt, lambda_prior=0.1, lambda_k=0.1, k_reg=None):\n",
    "    \"\"\"One training epoch with optional prior distillation and K regularization.\"\"\"\n",
    "    model.train()\n",
    "    tot = 0\n",
    "    n = 0\n",
    "    for batch in loader:\n",
    "        ids, prior, y, mask_b = batch[\"ids\"], batch[\"prior\"], batch[\"y\"], batch[\"mask_b\"]\n",
    "        priv = batch[\"priv\"]\n",
    "\n",
    "        logits = model(ids, prior, batch[\"mask_tok\"])\n",
    "        logits_flat = logits[mask_b]\n",
    "        y_true = y[mask_b]\n",
    "\n",
    "        # Main CE loss\n",
    "        loss = criterion_ce(logits_flat, y_true)\n",
    "\n",
    "        # Prior distillation\n",
    "        if lambda_prior > 0:\n",
    "            cut_logit = logits[..., 1]\n",
    "            prior_flat = prior[mask_b]\n",
    "            loss_pr = criterion_bce(cut_logit[mask_b], prior_flat)\n",
    "            loss = loss + lambda_prior * loss_pr\n",
    "\n",
    "        # K regularization\n",
    "        if (lambda_k > 0) and (k_reg is not None) and (priv is not None):\n",
    "            with torch.no_grad():\n",
    "                k_hat = predict_k_hat_priv(k_reg, priv)\n",
    "            cut_logit = logits[..., 1]\n",
    "            p_cut = torch.sigmoid(cut_logit)\n",
    "            exp_K = p_cut.sum(dim=1)\n",
    "            loss_k = mse(exp_K, k_hat)\n",
    "            loss = loss + lambda_k * loss_k\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        tot += loss.item()\n",
    "        n += 1\n",
    "    return tot / max(n, 1)\n",
    "\n",
    "def split_train_test(samples, test_ratio=0.2):\n",
    "    \"\"\"Random train/test split.\"\"\"\n",
    "    n = len(samples)\n",
    "    idx = np.arange(n)\n",
    "    np.random.shuffle(idx)\n",
    "    cut = int(n * (1 - test_ratio))\n",
    "    tr = [samples[i] for i in idx[:cut]]\n",
    "    te = [samples[i] for i in idx[cut:]]\n",
    "    return tr, te\n",
    "\n",
    "def best_threshold_for_exact(probs_list, gold_list, grid=None):\n",
    "    \"\"\"Find threshold that maximizes exact match rate.\"\"\"\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.3, 0.9, 61)\n",
    "    best_thr, best_em, best_f1 = 0.5, -1.0, 0.0\n",
    "    p_all = np.concatenate([t.numpy() for t in probs_list if t.numel() > 0], axis=0)\n",
    "    g_all = np.concatenate([t.numpy() for t in gold_list if t.numel() > 0], axis=0)\n",
    "    for thr in grid:\n",
    "        ems = []\n",
    "        for p, g in zip(probs_list, gold_list):\n",
    "            if g.numel() == 0:\n",
    "                ems.append(1.0)\n",
    "                continue\n",
    "            ems.append(float(np.array_equal((p.numpy() >= thr).astype(int), g.numpy())))\n",
    "        em = float(np.mean(ems))\n",
    "        pred_all = (p_all >= thr).astype(int)\n",
    "        P, R, F1, _ = precision_recall_fscore_support(g_all, pred_all, average='binary', zero_division=0)\n",
    "        if em > best_em or (np.isclose(em, best_em) and F1 > best_f1):\n",
    "            best_thr, best_em, best_f1 = thr, em, F1\n",
    "    print(f\"best threshold: {best_thr:.3f} | exact={best_em:.3f} | F1={best_f1:.3f}\")\n",
    "    return best_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7727ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_id(df, provided_suffix_list, use_suffix_list, unk_penalty, epochs,\n",
    "                      use_prior, fuse_mode, lambda_prior, lambda_k, batch_size, hparams, synthetic_choice,\n",
    "                      augmentation_word_selection=None, augmentation_n_words=None):\n",
    "    \"\"\"Hash training params to get unique model ID.\"\"\"\n",
    "    if augmentation_word_selection is None:\n",
    "        augmentation_word_selection = globals().get('AUGMENTATION_WORD_SELECTION', 'all')\n",
    "    if augmentation_n_words is None:\n",
    "        augmentation_n_words = globals().get('AUGMENTATION_N_WORDS', None)\n",
    "    \n",
    "    params_dict = {\n",
    "        'synthetic_choice': synthetic_choice,\n",
    "        'use_suffix_list': use_suffix_list,\n",
    "        'unk_penalty': unk_penalty,\n",
    "        'epochs': epochs,\n",
    "        'use_prior': use_prior,\n",
    "        'fuse_mode': fuse_mode,\n",
    "        'lambda_prior': lambda_prior,\n",
    "        'lambda_k': lambda_k,\n",
    "        'batch_size': batch_size,\n",
    "        'hparams': hparams,\n",
    "        'suffix_list_len': len(provided_suffix_list) if provided_suffix_list else 0,\n",
    "        'df_shape': df.shape if df is not None else (0, 0),\n",
    "        'augmentation_word_selection': augmentation_word_selection,\n",
    "        'augmentation_n_words': augmentation_n_words\n",
    "    }\n",
    "    params_str = json.dumps(params_dict, sort_keys=True)\n",
    "    model_id = hashlib.md5(params_str.encode()).hexdigest()[:16]\n",
    "    return model_id\n",
    "\n",
    "def save_model(model, vocab, out, model_id, models_folder=MODELS_FOLDER,\n",
    "               synthetic_choice=None, augmentation_word_selection=None, augmentation_n_words=None):\n",
    "    \"\"\"Save model weights and artifacts.\"\"\"\n",
    "    model_dir = os.path.join(models_folder, model_id)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join(model_dir, \"model.pt\"))\n",
    "    \n",
    "    with open(os.path.join(model_dir, \"vocab.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(vocab, f)\n",
    "    \n",
    "    with open(os.path.join(model_dir, \"artifacts.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(out, f)\n",
    "    \n",
    "    if synthetic_choice is None:\n",
    "        synthetic_choice = globals().get('SYNTHETIC_DATA_CHOICE', 'none')\n",
    "    if augmentation_word_selection is None:\n",
    "        augmentation_word_selection = globals().get('AUGMENTATION_WORD_SELECTION', 'all')\n",
    "    if augmentation_n_words is None:\n",
    "        augmentation_n_words = globals().get('AUGMENTATION_N_WORDS', None)\n",
    "    \n",
    "    metadata = {\n",
    "        'model_id': model_id,\n",
    "        'vocab_size': len(vocab),\n",
    "        'synthetic_choice': synthetic_choice,\n",
    "        'augmentation_word_selection': augmentation_word_selection,\n",
    "    }\n",
    "    if augmentation_n_words is not None:\n",
    "        metadata['augmentation_n_words'] = augmentation_n_words\n",
    "    with open(os.path.join(model_dir, \"metadata.json\"), \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"saved model to {model_dir}\")\n",
    "    return model_dir\n",
    "\n",
    "def load_model(model_id, models_folder=MODELS_FOLDER, vocab_size=None):\n",
    "    \"\"\"Load saved model artifacts.\"\"\"\n",
    "    model_dir = os.path.join(models_folder, model_id)\n",
    "    if not os.path.exists(model_dir):\n",
    "        return None\n",
    "    \n",
    "    vocab_path = os.path.join(model_dir, \"vocab.pkl\")\n",
    "    if not os.path.exists(vocab_path):\n",
    "        return None\n",
    "    with open(vocab_path, \"rb\") as f:\n",
    "        vocab = pickle.load(f)\n",
    "    \n",
    "    artifacts_path = os.path.join(model_dir, \"artifacts.pkl\")\n",
    "    if not os.path.exists(artifacts_path):\n",
    "        return None\n",
    "    with open(artifacts_path, \"rb\") as f:\n",
    "        out = pickle.load(f)\n",
    "    \n",
    "    model_path = os.path.join(model_dir, \"model.pt\")\n",
    "    if not os.path.exists(model_path):\n",
    "        return None\n",
    "    \n",
    "    print(f\"loaded artifacts from {model_dir}\")\n",
    "    return {\n",
    "        'vocab': vocab,\n",
    "        'out': out,\n",
    "        'model_state_path': model_path,\n",
    "        'model_dir': model_dir\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "102987b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_segmentation_with_privK(\n",
    "    df,\n",
    "    provided_suffix_list,\n",
    "    use_suffix_list=True,\n",
    "    unk_penalty=-15.0,\n",
    "    epochs=15,\n",
    "    use_prior=True,\n",
    "    fuse_mode=\"logit_add\",\n",
    "    lambda_prior=0.1,\n",
    "    lambda_k=0.2,\n",
    "    batch_size=64,\n",
    "    hparams=None,\n",
    "    synthetic_choice=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Train or load a segmentation model. Checks for existing checkpoints first.\n",
    "    \"\"\"\n",
    "    if hparams is None:\n",
    "        hparams = dict(emb_dim=16, hidden_size=64, num_layers=2,\n",
    "                       dropout=0.25, lr=1e-3, weight_decay=1e-4, freeze_emb=False)\n",
    "    \n",
    "    if synthetic_choice is None:\n",
    "        synthetic_choice = SYNTHETIC_DATA_CHOICE if 'SYNTHETIC_DATA_CHOICE' in globals() else \"none\"\n",
    "    \n",
    "    augmentation_word_selection = globals().get('AUGMENTATION_WORD_SELECTION', 'all')\n",
    "    augmentation_n_words = globals().get('AUGMENTATION_N_WORDS', None)\n",
    "    \n",
    "    model_id = generate_model_id(\n",
    "        df, provided_suffix_list, use_suffix_list, unk_penalty, epochs,\n",
    "        use_prior, fuse_mode, lambda_prior, lambda_k, batch_size, hparams, synthetic_choice,\n",
    "        augmentation_word_selection=augmentation_word_selection,\n",
    "        augmentation_n_words=augmentation_n_words\n",
    "    )\n",
    "    \n",
    "    print(f\"looking for model {model_id}...\")\n",
    "    loaded = load_model(model_id, models_folder=MODELS_FOLDER)\n",
    "    \n",
    "    if loaded is not None:\n",
    "        print(f\"found it! loading from {loaded['model_dir']}\")\n",
    "        vocab = loaded['vocab']\n",
    "        out = loaded['out']\n",
    "        model_state_path = loaded['model_state_path']\n",
    "        \n",
    "        model = BiLSTMTagger(\n",
    "            vocab_size=len(vocab),\n",
    "            emb_dim=hparams.get(\"emb_dim\", 16),\n",
    "            hidden_size=hparams.get(\"hidden_size\", 64),\n",
    "            num_layers=hparams.get(\"num_layers\", 2),\n",
    "            use_prior=(use_prior and fuse_mode != \"none\"),\n",
    "            dropout=hparams.get(\"dropout\", 0.25),\n",
    "            freeze_emb=hparams.get(\"freeze_emb\", False),\n",
    "            fuse_mode=fuse_mode\n",
    "        )\n",
    "        model.load_state_dict(torch.load(model_state_path))\n",
    "        model.eval()\n",
    "        print(\"skipping training, model ready\")\n",
    "        return model, vocab, out\n",
    "    \n",
    "    print(f\"no checkpoint found, training from scratch...\")\n",
    "    \n",
    "    samples = build_samples_with_priv(df, feat_names=NEW_NUM_FEATS)\n",
    "    train_s, test_s = split_train_test(samples, 0.2)\n",
    "\n",
    "    hmm_prior = None\n",
    "    if use_prior and use_suffix_list:\n",
    "        hmm_prior = create_hmm_prior_from_list(provided_suffix_list, unk_penalty)\n",
    "    if use_prior and not use_suffix_list:\n",
    "        hmm_prior = train_hmm_prior(train_s)\n",
    "\n",
    "    feat_dim = len(NEW_NUM_FEATS)\n",
    "    k_reg = train_k_teacher_priv(train_s, feat_dim=feat_dim)\n",
    "\n",
    "    vocab = build_vocab(train_s, min_freq=1)\n",
    "\n",
    "    train_ds = SegDataset(train_s, vocab, hmm_prior=hmm_prior, feat_dim=feat_dim)\n",
    "    test_ds = SegDataset(test_s, vocab, hmm_prior=hmm_prior, feat_dim=feat_dim)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, collate_fn=collate)\n",
    "\n",
    "    model = BiLSTMTagger(\n",
    "        vocab_size=len(vocab),\n",
    "        emb_dim=hparams.get(\"emb_dim\", 16),\n",
    "        hidden_size=hparams.get(\"hidden_size\", 64),\n",
    "        num_layers=hparams.get(\"num_layers\", 2),\n",
    "        use_prior=(use_prior and fuse_mode != \"none\"),\n",
    "        dropout=hparams.get(\"dropout\", 0.25),\n",
    "        freeze_emb=hparams.get(\"freeze_emb\", False),\n",
    "        fuse_mode=fuse_mode\n",
    "    )\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=hparams.get(\"lr\", 1e-3), \n",
    "                            weight_decay=hparams.get(\"weight_decay\", 1e-4))\n",
    "\n",
    "    final_probs_list, final_gold_list = None, None\n",
    "    for ep in range(1, epochs + 1):\n",
    "        loss = train_epoch(model, train_loader, opt, lambda_prior=lambda_prior, lambda_k=lambda_k, k_reg=k_reg)\n",
    "        probs_list, gold_list = predict(model, test_loader)\n",
    "        P, R, F1 = boundary_metrics_from_lists(probs_list, gold_list, thr=0.5)\n",
    "        EM = exact_match_rate_from_lists(probs_list, gold_list, thr=0.5)\n",
    "        print(f\"epoch {ep:02d} | loss={loss:.4f} | P/R/F1={P:.3f}/{R:.3f}/{F1:.3f} | exact={EM:.3f}\")\n",
    "        final_probs_list, final_gold_list = probs_list, gold_list\n",
    "\n",
    "    best_thr = best_threshold_for_exact(final_probs_list, final_gold_list)\n",
    "\n",
    "    out = {\n",
    "        \"probs_list\": final_probs_list,\n",
    "        \"gold_list\": final_gold_list,\n",
    "        \"hmm_prior\": hmm_prior,\n",
    "        \"k_teacher\": k_reg,\n",
    "        \"best_thr\": best_thr\n",
    "    }\n",
    "    \n",
    "    print(f\"saving model {model_id}...\")\n",
    "    save_model(model, vocab, out, model_id, models_folder=MODELS_FOLDER,\n",
    "               synthetic_choice=synthetic_choice,\n",
    "               augmentation_word_selection=augmentation_word_selection,\n",
    "               augmentation_n_words=augmentation_n_words)\n",
    "\n",
    "    return model, vocab, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df219c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_cross_validation(\n",
    "    df,\n",
    "    provided_suffix_list,\n",
    "    n_folds=5,\n",
    "    use_suffix_list=True,\n",
    "    unk_penalty=-15.0,\n",
    "    epochs=15,\n",
    "    use_prior=True,\n",
    "    fuse_mode=\"logit_add\",\n",
    "    lambda_prior=0.1,\n",
    "    lambda_k=0.2,\n",
    "    batch_size=64,\n",
    "    hparams=None,\n",
    "    synthetic_choice=None,\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"K-fold cross-validation for more robust evaluation.\"\"\"\n",
    "    if hparams is None:\n",
    "        hparams = dict(emb_dim=16, hidden_size=64, num_layers=2,\n",
    "                       dropout=0.25, lr=1e-3, weight_decay=1e-4, freeze_emb=False)\n",
    "    \n",
    "    if synthetic_choice is None:\n",
    "        synthetic_choice = SYNTHETIC_DATA_CHOICE if 'SYNTHETIC_DATA_CHOICE' in globals() else \"none\"\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"K-FOLD CV (k={n_folds})\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "    samples = build_samples_with_priv(df, feat_names=NEW_NUM_FEATS)\n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    fold_results = []\n",
    "    all_metrics = {\n",
    "        'boundary_precision': [],\n",
    "        'boundary_recall': [],\n",
    "        'boundary_f1': [],\n",
    "        'exact_match': [],\n",
    "        'best_threshold': []\n",
    "    }\n",
    "    \n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(kfold.split(samples), 1):\n",
    "        print(f\"\\n--- fold {fold_idx}/{n_folds} ---\")\n",
    "        print(f\"train: {len(train_indices)}, val: {len(val_indices)}\")\n",
    "        \n",
    "        train_samples = [samples[i] for i in train_indices]\n",
    "        val_samples = [samples[i] for i in val_indices]\n",
    "        \n",
    "        hmm_prior = None\n",
    "        if use_prior and use_suffix_list:\n",
    "            hmm_prior = create_hmm_prior_from_list(provided_suffix_list, unk_penalty)\n",
    "        elif use_prior and not use_suffix_list:\n",
    "            hmm_prior = train_hmm_prior(train_samples)\n",
    "        \n",
    "        feat_dim = len(NEW_NUM_FEATS)\n",
    "        k_reg = train_k_teacher_priv(train_samples, feat_dim=feat_dim)\n",
    "        vocab = build_vocab(train_samples, min_freq=1)\n",
    "        \n",
    "        train_ds = SegDataset(train_samples, vocab, hmm_prior=hmm_prior, feat_dim=feat_dim)\n",
    "        val_ds = SegDataset(val_samples, vocab, hmm_prior=hmm_prior, feat_dim=feat_dim)\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, collate_fn=collate)\n",
    "        \n",
    "        model = BiLSTMTagger(\n",
    "            vocab_size=len(vocab),\n",
    "            emb_dim=hparams.get(\"emb_dim\", 16),\n",
    "            hidden_size=hparams.get(\"hidden_size\", 64),\n",
    "            num_layers=hparams.get(\"num_layers\", 2),\n",
    "            use_prior=(use_prior and fuse_mode != \"none\"),\n",
    "            dropout=hparams.get(\"dropout\", 0.25),\n",
    "            freeze_emb=hparams.get(\"freeze_emb\", False),\n",
    "            fuse_mode=fuse_mode\n",
    "        )\n",
    "        \n",
    "        opt = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=hparams.get(\"lr\", 1e-3),\n",
    "            weight_decay=hparams.get(\"weight_decay\", 1e-4)\n",
    "        )\n",
    "        \n",
    "        best_val_em = -1.0\n",
    "        best_val_f1 = -1.0\n",
    "        best_epoch = 0\n",
    "        \n",
    "        for ep in range(1, epochs + 1):\n",
    "            loss = train_epoch(model, train_loader, opt, lambda_prior=lambda_prior, lambda_k=lambda_k, k_reg=k_reg)\n",
    "            probs_list, gold_list = predict(model, val_loader)\n",
    "            P, R, F1 = boundary_metrics_from_lists(probs_list, gold_list, thr=0.5)\n",
    "            EM = exact_match_rate_from_lists(probs_list, gold_list, thr=0.5)\n",
    "            \n",
    "            print(f\"  ep {ep:02d} | loss={loss:.4f} | P/R/F1={P:.3f}/{R:.3f}/{F1:.3f} | exact={EM:.3f}\")\n",
    "            \n",
    "            if EM > best_val_em or (np.isclose(EM, best_val_em) and F1 > best_val_f1):\n",
    "                best_val_em = EM\n",
    "                best_val_f1 = F1\n",
    "                best_epoch = ep\n",
    "                best_probs_list = probs_list\n",
    "                best_gold_list = gold_list\n",
    "        \n",
    "        best_thr = best_threshold_for_exact(best_probs_list, best_gold_list)\n",
    "        P_final, R_final, F1_final = boundary_metrics_from_lists(best_probs_list, best_gold_list, thr=best_thr)\n",
    "        EM_final = exact_match_rate_from_lists(best_probs_list, best_gold_list, thr=best_thr)\n",
    "        \n",
    "        print(f\"  best epoch: {best_epoch}\")\n",
    "        print(f\"  final (thr={best_thr:.3f}): P/R/F1={P_final:.3f}/{R_final:.3f}/{F1_final:.3f} | exact={EM_final:.3f}\")\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold_idx,\n",
    "            'boundary_precision': P_final,\n",
    "            'boundary_recall': R_final,\n",
    "            'boundary_f1': F1_final,\n",
    "            'exact_match': EM_final,\n",
    "            'best_threshold': best_thr,\n",
    "            'best_epoch': best_epoch\n",
    "        })\n",
    "        \n",
    "        all_metrics['boundary_precision'].append(P_final)\n",
    "        all_metrics['boundary_recall'].append(R_final)\n",
    "        all_metrics['boundary_f1'].append(F1_final)\n",
    "        all_metrics['exact_match'].append(EM_final)\n",
    "        all_metrics['best_threshold'].append(best_thr)\n",
    "    \n",
    "    mean_metrics = {k: np.mean(v) for k, v in all_metrics.items()}\n",
    "    std_metrics = {k: np.std(v) for k, v in all_metrics.items()}\n",
    "    best_fold_idx = max(range(len(fold_results)), key=lambda i: fold_results[i]['exact_match'])\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"CV SUMMARY\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    for r in fold_results:\n",
    "        print(f\"  fold {r['fold']}: P={r['boundary_precision']:.3f}, R={r['boundary_recall']:.3f}, \"\n",
    "              f\"F1={r['boundary_f1']:.3f}, EM={r['exact_match']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nmean +/- std over {n_folds} folds:\")\n",
    "    print(f\"  precision: {mean_metrics['boundary_precision']:.3f} +/- {std_metrics['boundary_precision']:.3f}\")\n",
    "    print(f\"  recall:    {mean_metrics['boundary_recall']:.3f} +/- {std_metrics['boundary_recall']:.3f}\")\n",
    "    print(f\"  F1:        {mean_metrics['boundary_f1']:.3f} +/- {std_metrics['boundary_f1']:.3f}\")\n",
    "    print(f\"  exact:     {mean_metrics['exact_match']:.3f} +/- {std_metrics['exact_match']:.3f}\")\n",
    "    print(f\"  threshold: {mean_metrics['best_threshold']:.3f} +/- {std_metrics['best_threshold']:.3f}\")\n",
    "    print(f\"\\nbest fold: {fold_results[best_fold_idx]['fold']} (exact={fold_results[best_fold_idx]['exact_match']:.3f})\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'fold_results': fold_results,\n",
    "        'mean_metrics': mean_metrics,\n",
    "        'std_metrics': std_metrics,\n",
    "        'best_fold_idx': best_fold_idx,\n",
    "        'all_metrics': all_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "553cf3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_vocab(word: str, vocab: dict, max_token_len: int = 4):\n",
    "    \"\"\"Greedy left-to-right tokenization using vocab.\"\"\"\n",
    "    i, toks = 0, []\n",
    "    while i < len(word):\n",
    "        matched = None\n",
    "        Lmax = min(max_token_len, len(word) - i)\n",
    "        for L in range(Lmax, 0, -1):\n",
    "            seg = word[i:i + L]\n",
    "            if seg in vocab:\n",
    "                matched = seg\n",
    "                break\n",
    "        toks.append(matched if matched else word[i])\n",
    "        i += len(toks[-1])\n",
    "    return toks\n",
    "\n",
    "@torch.no_grad()\n",
    "def segment_tokens(model, vocab, tokens, hmm_prior=None, thr=0.5):\n",
    "    \"\"\"Segment a tokenized word and return the segmented string + probabilities.\"\"\"\n",
    "    ids = torch.tensor([[vocab.get(t, vocab[\"<UNK>\"]) for t in tokens]], dtype=torch.long)\n",
    "    mask_tok = torch.ones_like(ids, dtype=torch.bool)\n",
    "    T = len(tokens)\n",
    "    if T <= 1:\n",
    "        return \"\".join(tokens), np.array([])\n",
    "    \n",
    "    prior_list = prior_probs_for_sample(hmm_prior, tokens)\n",
    "    prior = torch.tensor([prior_list], dtype=torch.float32)\n",
    "    logits = model(ids, prior, mask_tok)\n",
    "    probs = torch.softmax(logits, dim=-1)[0, :, 1].cpu().numpy()\n",
    "    cuts = (probs >= thr).astype(int)\n",
    "    \n",
    "    out = []\n",
    "    for i, tok in enumerate(tokens):\n",
    "        out.append(tok)\n",
    "        if i < T - 1 and cuts[i] == 1:\n",
    "            out.append(\"-\")\n",
    "    return \"\".join(out), probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65e6f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offsets_from_morphemes(morphs: List[str]) -> Set[int]:\n",
    "    \"\"\"Character offsets of boundaries between morphemes.\"\"\"\n",
    "    offs = []\n",
    "    s = 0\n",
    "    for i, m in enumerate(morphs):\n",
    "        s += len(m)\n",
    "        if i < len(morphs) - 1:\n",
    "            offs.append(s)\n",
    "    return set(offs)\n",
    "\n",
    "def offsets_from_tokens_and_mask(tokens: List[str], mask01: np.ndarray) -> Set[int]:\n",
    "    \"\"\"Character offsets where model predicted boundaries.\"\"\"\n",
    "    offs = set()\n",
    "    cum = 0\n",
    "    for i, t in enumerate(tokens):\n",
    "        cum += len(t)\n",
    "        if i < len(tokens) - 1 and mask01[i] == 1:\n",
    "            offs.add(cum)\n",
    "    return offs\n",
    "\n",
    "def f1_from_sets(pred: Set[int], gold: Set[int]) -> Tuple[float, float, float, int, int, int]:\n",
    "    \"\"\"P/R/F1 from predicted and gold boundary sets.\"\"\"\n",
    "    tp = len(pred & gold)\n",
    "    fp = len(pred - gold)\n",
    "    fn = len(gold - pred)\n",
    "    P = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    R = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    F1 = 2 * P * R / (P + R) if (P + R) > 0 else 0.0\n",
    "    return P, R, F1, tp, fp, fn\n",
    "\n",
    "def normalize_gold_variants(gold_variants):\n",
    "    \"\"\"Convert gold variants to proper list format.\"\"\"\n",
    "    if gold_variants is None:\n",
    "        return []\n",
    "    if isinstance(gold_variants, np.ndarray):\n",
    "        gold_variants = gold_variants.tolist()\n",
    "    if isinstance(gold_variants, list):\n",
    "        normalized = []\n",
    "        for variant in gold_variants:\n",
    "            if isinstance(variant, np.ndarray):\n",
    "                normalized.append(variant.tolist())\n",
    "            elif isinstance(variant, list):\n",
    "                normalized.append([item.tolist() if isinstance(item, np.ndarray) else item for item in variant])\n",
    "            else:\n",
    "                normalized.append(variant)\n",
    "        return normalized\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b6e5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_gold_df(df, model, vocab, out, max_token_len=4, use_tuned_thr=True, show_sample=5):\n",
    "    \"\"\"Evaluate model on test set with multiple gold variants per word.\"\"\"\n",
    "    hmm_prior = out[\"hmm_prior\"]\n",
    "    thr = float(out.get(\"best_thr\", 0.5)) if use_tuned_thr else 0.5\n",
    "\n",
    "    total_tp = total_fp = total_fn = 0\n",
    "    exact_hits = 0\n",
    "    n_eval = 0\n",
    "    examples = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        word = str(row[\"Word\"])\n",
    "        gold_variants = normalize_gold_variants(row[\"Gold\"])\n",
    "\n",
    "        if not isinstance(gold_variants, list) or len(gold_variants) == 0:\n",
    "            continue\n",
    "\n",
    "        toks = tokenize_with_vocab(word, vocab, max_token_len=max_token_len)\n",
    "        seg_string, probs = segment_tokens(model, vocab, toks, hmm_prior=hmm_prior, thr=thr)\n",
    "        mask01 = (probs >= thr).astype(int)\n",
    "        pred_set = offsets_from_tokens_and_mask(toks, mask01)\n",
    "\n",
    "        gold_sets = [offsets_from_morphemes(gv) for gv in gold_variants]\n",
    "\n",
    "        if any(pred_set == gs for gs in gold_sets):\n",
    "            exact_hits += 1\n",
    "\n",
    "        best = max((f1_from_sets(pred_set, gs) + (gs,) for gs in gold_sets), key=lambda z: z[2])\n",
    "        P, R, F1, tp, fp, fn, best_gs = best\n",
    "\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "        n_eval += 1\n",
    "\n",
    "        if len(examples) < show_sample:\n",
    "            best_morphs = None\n",
    "            for gv in gold_variants:\n",
    "                if offsets_from_morphemes(gv) == best_gs:\n",
    "                    best_morphs = gv\n",
    "                    break\n",
    "            gold_str = \"-\".join(best_morphs) if best_morphs else \"(ambig)\"\n",
    "            examples.append({\n",
    "                \"word\": word, \"tokens\": toks, \"pred_seg\": seg_string,\n",
    "                \"gold_best\": gold_str, \"P\": round(P, 3), \"R\": round(R, 3), \"F1\": round(F1, 3)\n",
    "            })\n",
    "\n",
    "    micro_P = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
    "    micro_R = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
    "    micro_F1 = 2 * micro_P * micro_R / (micro_P + micro_R) if (micro_P + micro_R) > 0 else 0.0\n",
    "    exact_rate = exact_hits / n_eval if n_eval > 0 else 0.0\n",
    "\n",
    "    print(f\"evaluated {n_eval} words\")\n",
    "    print(f\"boundary (micro) P/R/F1 = {micro_P:.3f}/{micro_R:.3f}/{micro_F1:.3f}\")\n",
    "    print(f\"exact match = {exact_rate:.3f}\")\n",
    "    if examples:\n",
    "        print(\"\\nsamples:\")\n",
    "        for ex in examples:\n",
    "            print(f\"- {ex['word']}\")\n",
    "            print(f\"  tokens: {ex['tokens']}\")\n",
    "            print(f\"  pred:   {ex['pred_seg']}\")\n",
    "            print(f\"  gold:   {ex['gold_best']}\")\n",
    "            print(f\"  P/R/F1: {ex['P']}/{ex['R']}/{ex['F1']}\\n\")\n",
    "\n",
    "    return {\n",
    "        \"n_eval\": n_eval, \"micro_precision\": micro_P, \"micro_recall\": micro_R,\n",
    "        \"micro_f1\": micro_F1, \"exact_match_rate\": exact_rate, \"examples\": examples\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6717e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_segmentation_valid(segmentation: list, allowed_suffixes: set) -> bool:\n",
    "    \"\"\"Check if all suffixes (non-root morphemes) are in the allowed set.\"\"\"\n",
    "    if len(segmentation) <= 1:\n",
    "        return True\n",
    "    for morpheme in segmentation[1:]:\n",
    "        if morpheme not in allowed_suffixes:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def evaluate_and_ignore_rejected(\n",
    "    df, model, vocab, out,\n",
    "    allowed_suffixes: list,\n",
    "    max_token_len=4,\n",
    "    use_tuned_thr=True,\n",
    "    show_sample=5\n",
    "):\n",
    "    \"\"\"Evaluate but skip predictions with invalid suffixes.\"\"\"\n",
    "    hmm_prior = out[\"hmm_prior\"]\n",
    "    thr = float(out.get(\"best_thr\", 0.5)) if use_tuned_thr else 0.5\n",
    "    allowed_suffixes_set = set(allowed_suffixes)\n",
    "\n",
    "    total_tp = total_fp = total_fn = 0\n",
    "    exact_hits = 0\n",
    "    n_total_words = 0\n",
    "    n_evaluated_words = 0\n",
    "    rejection_count = 0\n",
    "    false_rejection_count = 0\n",
    "    correct_kept_count = 0\n",
    "    examples = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        word = str(row[\"Word\"])\n",
    "        gold_variants = normalize_gold_variants(row[\"Gold\"])\n",
    "\n",
    "        if not isinstance(gold_variants, list) or len(gold_variants) == 0:\n",
    "            continue\n",
    "        \n",
    "        n_total_words += 1\n",
    "\n",
    "        toks = tokenize_with_vocab(word, vocab, max_token_len=max_token_len)\n",
    "        seg_string, probs = segment_tokens(model, vocab, toks, hmm_prior=hmm_prior, thr=thr)\n",
    "        predicted_morphs = seg_string.split('-')\n",
    "        \n",
    "        mask01 = (probs >= thr).astype(int)\n",
    "        pred_set = offsets_from_tokens_and_mask(toks, mask01)\n",
    "        gold_sets = [offsets_from_morphemes(gv) for gv in gold_variants]\n",
    "        is_correct = any(pred_set == gs for gs in gold_sets)\n",
    "\n",
    "        if not is_segmentation_valid(predicted_morphs, allowed_suffixes_set):\n",
    "            rejection_count += 1\n",
    "            if is_correct:\n",
    "                false_rejection_count += 1\n",
    "            continue\n",
    "\n",
    "        n_evaluated_words += 1\n",
    "        \n",
    "        if is_correct:\n",
    "            correct_kept_count += 1\n",
    "            exact_hits += 1\n",
    "\n",
    "        best = max((f1_from_sets(pred_set, gs) + (gs,) for gs in gold_sets), key=lambda z: z[2])\n",
    "        P, R, F1, tp, fp, fn, best_gs = best\n",
    "\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "\n",
    "        if len(examples) < show_sample:\n",
    "            best_morphs = None\n",
    "            for gv in gold_variants:\n",
    "                if offsets_from_morphemes(gv) == best_gs:\n",
    "                    best_morphs = gv\n",
    "                    break\n",
    "            gold_str = \"-\".join(best_morphs) if best_morphs else \"(ambig)\"\n",
    "            examples.append({\n",
    "                \"word\": word, \"tokens\": toks, \"pred_seg\": seg_string,\n",
    "                \"gold_best\": gold_str, \"P\": round(P, 3), \"R\": round(R, 3), \"F1\": round(F1, 3)\n",
    "            })\n",
    "\n",
    "    micro_P = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
    "    micro_R = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
    "    micro_F1 = 2 * micro_P * micro_R / (micro_P + micro_R) if (micro_P + micro_R) > 0 else 0.0\n",
    "    exact_rate = exact_hits / n_evaluated_words if n_evaluated_words > 0 else 0.0\n",
    "    \n",
    "    filter_precision = correct_kept_count / n_evaluated_words if n_evaluated_words > 0 else 0.0\n",
    "    total_correct = correct_kept_count + false_rejection_count\n",
    "    false_rejection_rate = false_rejection_count / total_correct if total_correct > 0 else 0.0\n",
    "\n",
    "    print(f\"tried {n_total_words} words\")\n",
    "    print(f\"rejected {rejection_count} ({rejection_count/n_total_words:.1%}) with invalid suffixes\")\n",
    "    print(f\"scoring {n_evaluated_words} valid predictions\")\n",
    "    print(f\"\\n--- filter analysis ---\")\n",
    "    print(f\"filter precision: {filter_precision:.1%}\")\n",
    "    print(f\"false rejection rate: {false_rejection_rate:.1%}\")\n",
    "    print(f\"  correct kept: {correct_kept_count}\")\n",
    "    print(f\"  correct rejected: {false_rejection_count}\")\n",
    "    print(f\"  total correct: {total_correct}\")\n",
    "    print(f\"\\n--- final scores (valid predictions only) ---\")\n",
    "    print(f\"boundary (micro) P/R/F1 = {micro_P:.3f}/{micro_R:.3f}/{micro_F1:.3f}\")\n",
    "    print(f\"exact match = {exact_rate:.3f}\")\n",
    "\n",
    "    if examples:\n",
    "        print(\"\\nsamples:\")\n",
    "        for ex in examples:\n",
    "            print(f\"- {ex['word']}\")\n",
    "            print(f\"  tokens: {ex['tokens']}\")\n",
    "            print(f\"  pred:   {ex['pred_seg']}\")\n",
    "            print(f\"  gold:   {ex['gold_best']}\")\n",
    "            print(f\"  P/R/F1: {ex['P']}/{ex['R']}/{ex['F1']}\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"micro_f1\": micro_F1, \"exact_match_rate\": exact_rate,\n",
    "        \"rejection_count\": rejection_count, \"false_rejection_count\": false_rejection_count,\n",
    "        \"filter_precision\": filter_precision, \"false_rejection_rate\": false_rejection_rate\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9625a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 88 suffixes from data\\suffixesCQ-Anettte-Rios_LS.txt\n"
     ]
    }
   ],
   "source": [
    "def read_suffixes(filename):\n",
    "    \"\"\"Read suffix list from file (format: 'number -suffix').\"\"\"\n",
    "    suffixes = []\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = line.split(maxsplit=1)\n",
    "            if len(parts) == 2:\n",
    "                _, suffix = parts\n",
    "                suffixes.append(suffix[1:])  # drop leading dash\n",
    "    return suffixes\n",
    "\n",
    "suffix_filename = os.path.join(DATA_FOLDER, \"suffixesCQ-Anettte-Rios_LS.txt\")\n",
    "if not os.path.exists(suffix_filename):\n",
    "    suffix_filename = \"suffixesCQ-Anettte-Rios_LS.txt\"\n",
    "    if not os.path.exists(suffix_filename):\n",
    "        print(f\"warning: suffix file not found\")\n",
    "        suffix_list = []\n",
    "    else:\n",
    "        suffix_list = read_suffixes(suffix_filename)\n",
    "        print(f\"loaded {len(suffix_list)} suffixes from {suffix_filename}\")\n",
    "else:\n",
    "    suffix_list = read_suffixes(suffix_filename)\n",
    "    print(f\"loaded {len(suffix_list)} suffixes from {suffix_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97efca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    \"\"\"Optuna objective for hyperparameter search.\"\"\"\n",
    "    hparams = {\n",
    "        \"emb_dim\": trial.suggest_categorical(\"emb_dim\", [16, 32, 64]),\n",
    "        \"hidden_size\": trial.suggest_categorical(\"hidden_size\", [32, 64, 128]),\n",
    "        \"num_layers\": trial.suggest_int(\"num_layers\", 1, 3),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5, step=0.05),\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True),\n",
    "        \"freeze_emb\": False,\n",
    "    }\n",
    "    lambda_prior_val = trial.suggest_float(\"lambda_prior\", 0.0, 0.5)\n",
    "\n",
    "    print(f\"\\n--- trial {trial.number} ---\")\n",
    "    model, vocab, out = run_segmentation_with_privK(\n",
    "        df=str_df,\n",
    "        provided_suffix_list=suffix_list,\n",
    "        use_suffix_list=True,\n",
    "        unk_penalty=-15,\n",
    "        epochs=15,\n",
    "        use_prior=True,\n",
    "        lambda_prior=lambda_prior_val,\n",
    "        lambda_k=0.2,\n",
    "        hparams=hparams,\n",
    "        synthetic_choice=SYNTHETIC_DATA_CHOICE\n",
    "    )\n",
    "\n",
    "    test_set_results = evaluate_on_gold_df(\n",
    "        df=acc_df, model=model, vocab=vocab, out=out,\n",
    "        max_token_len=4, use_tuned_thr=True, show_sample=0\n",
    "    )\n",
    "    test_exact_match = test_set_results[\"exact_match_rate\"]\n",
    "    \n",
    "    print(f\"trial {trial.number} done | exact match: {test_exact_match:.4f}\")\n",
    "    return test_exact_match\n",
    "\n",
    "# Uncomment to run hyperparameter search:\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=50)\n",
    "# print(f\"best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa97c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters from optuna search\n",
    "best = {\n",
    "    \"emb_dim\": 32,\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.4,\n",
    "    \"lr\": 0.009213045798657327,\n",
    "    \"weight_decay\": 0.0001132283214088801,\n",
    "    \"freeze_emb\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c65c838e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "K-FOLD CV (k=5)\n",
      "================================================================================\n",
      "\n",
      "--- fold 1/5 ---\n",
      "train: 5064, val: 1266\n",
      "HMM: 510 suffixes, max len 8, unk penalty -11.33\n",
      "  ep 01 | loss=0.7222 | P/R/F1=0.859/0.922/0.889 | exact=0.593\n",
      "  ep 02 | loss=0.2640 | P/R/F1=0.945/0.956/0.950 | exact=0.802\n",
      "  ep 03 | loss=0.1909 | P/R/F1=0.962/0.966/0.964 | exact=0.858\n",
      "  ep 04 | loss=0.1591 | P/R/F1=0.958/0.982/0.970 | exact=0.878\n",
      "  ep 05 | loss=0.1444 | P/R/F1=0.975/0.972/0.973 | exact=0.892\n",
      "  ep 06 | loss=0.1192 | P/R/F1=0.973/0.974/0.974 | exact=0.898\n",
      "  ep 07 | loss=0.1151 | P/R/F1=0.968/0.985/0.976 | exact=0.904\n",
      "  ep 08 | loss=0.1054 | P/R/F1=0.978/0.978/0.978 | exact=0.913\n",
      "  ep 09 | loss=0.1019 | P/R/F1=0.967/0.987/0.977 | exact=0.909\n",
      "  ep 10 | loss=0.1014 | P/R/F1=0.973/0.986/0.980 | exact=0.920\n",
      "  ep 11 | loss=0.0975 | P/R/F1=0.971/0.986/0.979 | exact=0.914\n",
      "  ep 12 | loss=0.0957 | P/R/F1=0.975/0.983/0.979 | exact=0.916\n",
      "  ep 13 | loss=0.0972 | P/R/F1=0.973/0.982/0.977 | exact=0.911\n",
      "  ep 14 | loss=0.0979 | P/R/F1=0.977/0.980/0.979 | exact=0.919\n",
      "  ep 15 | loss=0.0940 | P/R/F1=0.983/0.979/0.981 | exact=0.925\n",
      "best threshold: 0.590 | exact=0.929 | F1=0.982\n",
      "  best epoch: 15\n",
      "  final (thr=0.590): P/R/F1=0.985/0.979/0.982 | exact=0.929\n",
      "\n",
      "--- fold 2/5 ---\n",
      "train: 5064, val: 1266\n",
      "HMM: 517 suffixes, max len 8, unk penalty -11.35\n",
      "  ep 01 | loss=0.7274 | P/R/F1=0.881/0.853/0.867 | exact=0.573\n",
      "  ep 02 | loss=0.2708 | P/R/F1=0.914/0.971/0.941 | exact=0.769\n",
      "  ep 03 | loss=0.1914 | P/R/F1=0.941/0.979/0.959 | exact=0.841\n",
      "  ep 04 | loss=0.1666 | P/R/F1=0.959/0.976/0.968 | exact=0.870\n",
      "  ep 05 | loss=0.1443 | P/R/F1=0.971/0.982/0.977 | exact=0.908\n",
      "  ep 06 | loss=0.1286 | P/R/F1=0.978/0.980/0.979 | exact=0.912\n",
      "  ep 07 | loss=0.1203 | P/R/F1=0.966/0.988/0.977 | exact=0.908\n",
      "  ep 08 | loss=0.1210 | P/R/F1=0.973/0.986/0.979 | exact=0.921\n",
      "  ep 09 | loss=0.1085 | P/R/F1=0.972/0.987/0.979 | exact=0.915\n",
      "  ep 10 | loss=0.1024 | P/R/F1=0.978/0.983/0.981 | exact=0.923\n",
      "  ep 11 | loss=0.0998 | P/R/F1=0.977/0.989/0.983 | exact=0.931\n",
      "  ep 12 | loss=0.0951 | P/R/F1=0.982/0.986/0.984 | exact=0.934\n",
      "  ep 13 | loss=0.0950 | P/R/F1=0.976/0.986/0.981 | exact=0.924\n",
      "  ep 14 | loss=0.0939 | P/R/F1=0.976/0.990/0.983 | exact=0.930\n",
      "  ep 15 | loss=0.0893 | P/R/F1=0.979/0.988/0.983 | exact=0.935\n",
      "best threshold: 0.560 | exact=0.940 | F1=0.985\n",
      "  best epoch: 15\n",
      "  final (thr=0.560): P/R/F1=0.981/0.988/0.985 | exact=0.940\n",
      "\n",
      "--- fold 3/5 ---\n",
      "train: 5064, val: 1266\n",
      "HMM: 514 suffixes, max len 8, unk penalty -11.34\n",
      "  ep 01 | loss=0.7760 | P/R/F1=0.868/0.858/0.863 | exact=0.544\n",
      "  ep 02 | loss=0.2841 | P/R/F1=0.933/0.960/0.946 | exact=0.796\n",
      "  ep 03 | loss=0.2060 | P/R/F1=0.967/0.946/0.956 | exact=0.829\n",
      "  ep 04 | loss=0.1703 | P/R/F1=0.954/0.976/0.964 | exact=0.856\n",
      "  ep 05 | loss=0.1506 | P/R/F1=0.958/0.978/0.968 | exact=0.875\n",
      "  ep 06 | loss=0.1303 | P/R/F1=0.962/0.977/0.970 | exact=0.884\n",
      "  ep 07 | loss=0.1206 | P/R/F1=0.972/0.976/0.974 | exact=0.902\n",
      "  ep 08 | loss=0.1119 | P/R/F1=0.974/0.972/0.973 | exact=0.897\n",
      "  ep 09 | loss=0.1099 | P/R/F1=0.972/0.982/0.977 | exact=0.909\n",
      "  ep 10 | loss=0.1008 | P/R/F1=0.983/0.976/0.979 | exact=0.919\n",
      "  ep 11 | loss=0.0960 | P/R/F1=0.978/0.976/0.977 | exact=0.912\n",
      "  ep 12 | loss=0.0937 | P/R/F1=0.977/0.983/0.980 | exact=0.922\n",
      "  ep 13 | loss=0.0952 | P/R/F1=0.978/0.985/0.981 | exact=0.930\n",
      "  ep 14 | loss=0.0882 | P/R/F1=0.978/0.982/0.980 | exact=0.922\n",
      "  ep 15 | loss=0.0876 | P/R/F1=0.982/0.982/0.982 | exact=0.933\n",
      "best threshold: 0.540 | exact=0.934 | F1=0.982\n",
      "  best epoch: 15\n",
      "  final (thr=0.540): P/R/F1=0.983/0.981/0.982 | exact=0.934\n",
      "\n",
      "--- fold 4/5 ---\n",
      "train: 5064, val: 1266\n",
      "HMM: 523 suffixes, max len 8, unk penalty -11.35\n",
      "  ep 01 | loss=0.8623 | P/R/F1=0.793/0.830/0.811 | exact=0.420\n",
      "  ep 02 | loss=0.3340 | P/R/F1=0.924/0.943/0.933 | exact=0.740\n",
      "  ep 03 | loss=0.2082 | P/R/F1=0.960/0.963/0.962 | exact=0.855\n",
      "  ep 04 | loss=0.1754 | P/R/F1=0.932/0.987/0.959 | exact=0.836\n",
      "  ep 05 | loss=0.1579 | P/R/F1=0.972/0.971/0.971 | exact=0.885\n",
      "  ep 06 | loss=0.1370 | P/R/F1=0.967/0.976/0.971 | exact=0.885\n",
      "  ep 07 | loss=0.1224 | P/R/F1=0.966/0.984/0.975 | exact=0.897\n",
      "  ep 08 | loss=0.1148 | P/R/F1=0.970/0.982/0.976 | exact=0.905\n",
      "  ep 09 | loss=0.1081 | P/R/F1=0.968/0.982/0.975 | exact=0.904\n",
      "  ep 10 | loss=0.1001 | P/R/F1=0.970/0.982/0.976 | exact=0.907\n",
      "  ep 11 | loss=0.1002 | P/R/F1=0.974/0.979/0.977 | exact=0.908\n",
      "  ep 12 | loss=0.0988 | P/R/F1=0.975/0.982/0.978 | exact=0.913\n",
      "  ep 13 | loss=0.0933 | P/R/F1=0.974/0.978/0.976 | exact=0.909\n",
      "  ep 14 | loss=0.0964 | P/R/F1=0.977/0.981/0.979 | exact=0.919\n",
      "  ep 15 | loss=0.0962 | P/R/F1=0.974/0.982/0.978 | exact=0.915\n",
      "best threshold: 0.550 | exact=0.919 | F1=0.979\n",
      "  best epoch: 14\n",
      "  final (thr=0.550): P/R/F1=0.980/0.979/0.979 | exact=0.919\n",
      "\n",
      "--- fold 5/5 ---\n",
      "train: 5064, val: 1266\n",
      "HMM: 511 suffixes, max len 8, unk penalty -11.34\n",
      "  ep 01 | loss=0.8016 | P/R/F1=0.889/0.638/0.743 | exact=0.323\n",
      "  ep 02 | loss=0.2906 | P/R/F1=0.940/0.934/0.937 | exact=0.764\n",
      "  ep 03 | loss=0.1987 | P/R/F1=0.935/0.979/0.957 | exact=0.828\n",
      "  ep 04 | loss=0.1629 | P/R/F1=0.965/0.972/0.968 | exact=0.869\n",
      "  ep 05 | loss=0.1381 | P/R/F1=0.965/0.977/0.971 | exact=0.883\n",
      "  ep 06 | loss=0.1307 | P/R/F1=0.969/0.976/0.972 | exact=0.893\n",
      "  ep 07 | loss=0.1255 | P/R/F1=0.978/0.969/0.973 | exact=0.896\n",
      "  ep 08 | loss=0.1141 | P/R/F1=0.971/0.982/0.977 | exact=0.906\n",
      "  ep 09 | loss=0.1166 | P/R/F1=0.975/0.979/0.977 | exact=0.909\n",
      "  ep 10 | loss=0.1039 | P/R/F1=0.980/0.980/0.980 | exact=0.915\n",
      "  ep 11 | loss=0.1016 | P/R/F1=0.976/0.982/0.979 | exact=0.912\n",
      "  ep 12 | loss=0.0952 | P/R/F1=0.977/0.981/0.979 | exact=0.919\n",
      "  ep 13 | loss=0.0913 | P/R/F1=0.978/0.989/0.983 | exact=0.931\n",
      "  ep 14 | loss=0.0931 | P/R/F1=0.980/0.981/0.981 | exact=0.924\n",
      "  ep 15 | loss=0.0889 | P/R/F1=0.980/0.983/0.981 | exact=0.928\n",
      "best threshold: 0.520 | exact=0.932 | F1=0.984\n",
      "  best epoch: 13\n",
      "  final (thr=0.520): P/R/F1=0.978/0.989/0.984 | exact=0.932\n",
      "\n",
      "================================================================================\n",
      "CV SUMMARY\n",
      "================================================================================\n",
      "  fold 1: P=0.985, R=0.979, F1=0.982, EM=0.929\n",
      "  fold 2: P=0.981, R=0.988, F1=0.985, EM=0.940\n",
      "  fold 3: P=0.983, R=0.981, F1=0.982, EM=0.934\n",
      "  fold 4: P=0.980, R=0.979, F1=0.979, EM=0.919\n",
      "  fold 5: P=0.978, R=0.989, F1=0.984, EM=0.932\n",
      "\n",
      "mean +/- std over 5 folds:\n",
      "  precision: 0.981 +/- 0.002\n",
      "  recall:    0.983 +/- 0.004\n",
      "  F1:        0.982 +/- 0.002\n",
      "  exact:     0.931 +/- 0.007\n",
      "  threshold: 0.552 +/- 0.023\n",
      "\n",
      "best fold: 2 (exact=0.940)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "avg exact match: 0.931 +/- 0.007\n",
      "avg boundary F1: 0.982 +/- 0.002\n"
     ]
    }
   ],
   "source": [
    "# Run k-fold cross-validation\n",
    "kfold_results = run_kfold_cross_validation(\n",
    "    df=str_df,\n",
    "    provided_suffix_list=suffix_list,\n",
    "    n_folds=5,\n",
    "    use_suffix_list=False,\n",
    "    unk_penalty=-15.0,\n",
    "    epochs=15,\n",
    "    use_prior=True,\n",
    "    lambda_prior=0.15289202508573396,\n",
    "    lambda_k=0.2,\n",
    "    hparams=best,\n",
    "    synthetic_choice=SYNTHETIC_DATA_CHOICE,\n",
    "    random_state=RNG\n",
    ")\n",
    "\n",
    "print(f\"\\navg exact match: {kfold_results['mean_metrics']['exact_match']:.3f} +/- {kfold_results['std_metrics']['exact_match']:.3f}\")\n",
    "print(f\"avg boundary F1: {kfold_results['mean_metrics']['boundary_f1']:.3f} +/- {kfold_results['std_metrics']['boundary_f1']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "637a3623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for model 38f132fa19705d49...\n",
      "loaded artifacts from models_Markov-LSTM-MarkovFilter\\38f132fa19705d49\n",
      "found it! loading from models_Markov-LSTM-MarkovFilter\\38f132fa19705d49\n",
      "skipping training, model ready\n",
      "\n",
      "model ready, threshold: 0.420\n"
     ]
    }
   ],
   "source": [
    "# Train or load the model (this creates model, vocab, out for later use)\n",
    "model, vocab, out = run_segmentation_with_privK(\n",
    "    df=str_df,\n",
    "    provided_suffix_list=suffix_list,\n",
    "    use_suffix_list=False,\n",
    "    unk_penalty=-15.0,\n",
    "    epochs=15,\n",
    "    use_prior=True,\n",
    "    lambda_prior=0.15289202508573396,\n",
    "    lambda_k=0.2,\n",
    "    hparams=best,\n",
    "    synthetic_choice=SYNTHETIC_DATA_CHOICE\n",
    ")\n",
    "\n",
    "thr = out.get(\"best_thr\", 0.5)\n",
    "print(f\"\\nmodel ready, threshold: {thr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a22bfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: pikunas\n",
      "tokens: ['p', 'i', 'k', 'u', 'n', 'a', 's']\n",
      "probs: [0.0, 0.9670000076293945, 0.0, 0.0010000000474974513, 0.0, 0.8569999933242798]\n",
      "segmented (thr=0.420): pi-kuna-s\n"
     ]
    }
   ],
   "source": [
    "# Example segmentation\n",
    "word = \"pikunas\"\n",
    "tokens = tokenize_with_vocab(word, vocab, max_token_len=4)\n",
    "thr = out.get(\"best_thr\", 0.5)\n",
    "\n",
    "seg_string, boundary_probs = segment_tokens(\n",
    "    model, vocab, tokens, hmm_prior=out[\"hmm_prior\"], thr=thr\n",
    ")\n",
    "\n",
    "print(f\"word: {word}\")\n",
    "print(f\"tokens: {tokens}\")\n",
    "print(f\"probs: {np.round(boundary_probs, 3).tolist()}\")\n",
    "print(f\"segmented (thr={thr:.3f}): {seg_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34e3de9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- standard evaluation ---\n",
      "evaluated 913 words\n",
      "boundary (micro) P/R/F1 = 0.794/0.852/0.822\n",
      "exact match = 0.574\n",
      "\n",
      "samples:\n",
      "- unupas\n",
      "  tokens: ['u', 'n', 'u', 'p', 'a', 's']\n",
      "  pred:   unupa-s\n",
      "  gold:   unu-pas\n",
      "  P/R/F1: 0.0/0.0/0.0\n",
      "\n",
      "- umankus\n",
      "  tokens: ['u', 'm', 'a', 'n', 'k', 'u', 's']\n",
      "  pred:   uma-nku-s\n",
      "  gold:   uma-nku-s\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- hikurin\n",
      "  tokens: ['h', 'i', 'k', 'u', 'r', 'i', 'n']\n",
      "  pred:   hiku-ri-n\n",
      "  gold:   hikuri-n\n",
      "  P/R/F1: 0.5/1.0/0.667\n",
      "\n",
      "- sutipi\n",
      "  tokens: ['s', 'u', 't', 'i', 'p', 'i']\n",
      "  pred:   suti-pi\n",
      "  gold:   suti-pi\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- pikunas\n",
      "  tokens: ['p', 'i', 'k', 'u', 'n', 'a', 's']\n",
      "  pred:   pi-kuna-s\n",
      "  gold:   pi-kuna-s\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- atipaq\n",
      "  tokens: ['a', 't', 'i', 'p', 'a', 'q']\n",
      "  pred:   ati-paq\n",
      "  gold:   ati-paq\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- tomani\n",
      "  tokens: ['t', 'o', 'm', 'a', 'n', 'i']\n",
      "  pred:   toma-ni\n",
      "  gold:   toma-ni\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- rantiq\n",
      "  tokens: ['r', 'a', 'n', 't', 'i', 'q']\n",
      "  pred:   rantiq\n",
      "  gold:   ranti-q\n",
      "  P/R/F1: 0.0/0.0/0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "print(\"\\n--- standard evaluation ---\")\n",
    "results = evaluate_on_gold_df(\n",
    "    acc_df, model, vocab, out,\n",
    "    max_token_len=4,\n",
    "    use_tuned_thr=True,\n",
    "    show_sample=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bac2518a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- evaluation with suffix filter ---\n",
      "tried 913 words\n",
      "rejected 245 (26.8%) with invalid suffixes\n",
      "scoring 668 valid predictions\n",
      "\n",
      "--- filter analysis ---\n",
      "filter precision: 66.6%\n",
      "false rejection rate: 15.1%\n",
      "  correct kept: 445\n",
      "  correct rejected: 79\n",
      "  total correct: 524\n",
      "\n",
      "--- final scores (valid predictions only) ---\n",
      "boundary (micro) P/R/F1 = 0.826/0.901/0.862\n",
      "exact match = 0.666\n",
      "\n",
      "samples:\n",
      "- unupas\n",
      "  tokens: ['u', 'n', 'u', 'p', 'a', 's']\n",
      "  pred:   unupa-s\n",
      "  gold:   unu-pas\n",
      "  P/R/F1: 0.0/0.0/0.0\n",
      "\n",
      "- umankus\n",
      "  tokens: ['u', 'm', 'a', 'n', 'k', 'u', 's']\n",
      "  pred:   uma-nku-s\n",
      "  gold:   uma-nku-s\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- hikurin\n",
      "  tokens: ['h', 'i', 'k', 'u', 'r', 'i', 'n']\n",
      "  pred:   hiku-ri-n\n",
      "  gold:   hikuri-n\n",
      "  P/R/F1: 0.5/1.0/0.667\n",
      "\n",
      "- sutipi\n",
      "  tokens: ['s', 'u', 't', 'i', 'p', 'i']\n",
      "  pred:   suti-pi\n",
      "  gold:   suti-pi\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- pikunas\n",
      "  tokens: ['p', 'i', 'k', 'u', 'n', 'a', 's']\n",
      "  pred:   pi-kuna-s\n",
      "  gold:   pi-kuna-s\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- atipaq\n",
      "  tokens: ['a', 't', 'i', 'p', 'a', 'q']\n",
      "  pred:   ati-paq\n",
      "  gold:   ati-paq\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- tomani\n",
      "  tokens: ['t', 'o', 'm', 'a', 'n', 'i']\n",
      "  pred:   toma-ni\n",
      "  gold:   toma-ni\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- rantiq\n",
      "  tokens: ['r', 'a', 'n', 't', 'i', 'q']\n",
      "  pred:   rantiq\n",
      "  gold:   ranti-q\n",
      "  P/R/F1: 0.0/0.0/0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with suffix filter\n",
    "print(\"\\n--- evaluation with suffix filter ---\")\n",
    "results_filtered = evaluate_and_ignore_rejected(\n",
    "    acc_df, model, vocab, out,\n",
    "    allowed_suffixes=suffix_list,\n",
    "    show_sample=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "163a3fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grabbing gold data for comparison...\n",
      "\n",
      "================================================================================\n",
      "trying: none | None | None\n",
      "================================================================================\n",
      "looking for model 38f132fa19705d49...\n",
      "loaded artifacts from models_Markov-LSTM-MarkovFilter\\38f132fa19705d49\n",
      "found it! loading from models_Markov-LSTM-MarkovFilter\\38f132fa19705d49\n",
      "skipping training, model ready\n",
      "evaluated 913 words\n",
      "boundary (micro) P/R/F1 = 0.794/0.852/0.822\n",
      "exact match = 0.574\n",
      "tried 913 words\n",
      "rejected 245 (26.8%) with invalid suffixes\n",
      "scoring 668 valid predictions\n",
      "\n",
      "--- filter analysis ---\n",
      "filter precision: 66.6%\n",
      "false rejection rate: 15.1%\n",
      "  correct kept: 445\n",
      "  correct rejected: 79\n",
      "  total correct: 524\n",
      "\n",
      "--- final scores (valid predictions only) ---\n",
      "boundary (micro) P/R/F1 = 0.826/0.901/0.862\n",
      "exact match = 0.666\n",
      "\n",
      "================================================================================\n",
      "trying: gpt4o | first | 100\n",
      "================================================================================\n",
      "loading synthetic data from data\\gpt4o_synthetic_segmentations.csv...\n",
      "loaded 2,382 synthetic examples\n",
      "looking for model e472bb88ff4f1313...\n",
      "loaded artifacts from models_Markov-LSTM-MarkovFilter\\e472bb88ff4f1313\n",
      "found it! loading from models_Markov-LSTM-MarkovFilter\\e472bb88ff4f1313\n",
      "skipping training, model ready\n",
      "evaluated 913 words\n",
      "boundary (micro) P/R/F1 = 0.813/0.841/0.827\n",
      "exact match = 0.556\n",
      "tried 913 words\n",
      "rejected 242 (26.5%) with invalid suffixes\n",
      "scoring 671 valid predictions\n",
      "\n",
      "--- filter analysis ---\n",
      "filter precision: 64.7%\n",
      "false rejection rate: 14.6%\n",
      "  correct kept: 434\n",
      "  correct rejected: 74\n",
      "  total correct: 508\n",
      "\n",
      "--- final scores (valid predictions only) ---\n",
      "boundary (micro) P/R/F1 = 0.857/0.875/0.866\n",
      "exact match = 0.647\n",
      "\n",
      "================================================================================\n",
      "trying: gpt5mini | first | 100\n",
      "================================================================================\n",
      "loading synthetic data from data\\gpt5mini_synthetic_segmentations.csv...\n",
      "loaded 5,000 synthetic examples\n",
      "looking for model ddcf9a5090b4081e...\n",
      "loaded artifacts from models_Markov-LSTM-MarkovFilter\\ddcf9a5090b4081e\n",
      "found it! loading from models_Markov-LSTM-MarkovFilter\\ddcf9a5090b4081e\n",
      "skipping training, model ready\n",
      "evaluated 913 words\n",
      "boundary (micro) P/R/F1 = 0.797/0.851/0.823\n",
      "exact match = 0.559\n",
      "tried 913 words\n",
      "rejected 241 (26.4%) with invalid suffixes\n",
      "scoring 672 valid predictions\n",
      "\n",
      "--- filter analysis ---\n",
      "filter precision: 65.5%\n",
      "false rejection rate: 13.7%\n",
      "  correct kept: 440\n",
      "  correct rejected: 70\n",
      "  total correct: 510\n",
      "\n",
      "--- final scores (valid predictions only) ---\n",
      "boundary (micro) P/R/F1 = 0.827/0.903/0.863\n",
      "exact match = 0.655\n",
      "\n",
      "================================================================================\n",
      "trying: gpt4o | first | 200\n",
      "================================================================================\n",
      "loading synthetic data from data\\gpt4o_synthetic_segmentations.csv...\n",
      "loaded 2,382 synthetic examples\n",
      "looking for model 0dbdce1bde73fec1...\n",
      "loaded artifacts from models_Markov-LSTM-MarkovFilter\\0dbdce1bde73fec1\n",
      "found it! loading from models_Markov-LSTM-MarkovFilter\\0dbdce1bde73fec1\n",
      "skipping training, model ready\n",
      "evaluated 913 words\n",
      "boundary (micro) P/R/F1 = 0.844/0.864/0.854\n",
      "exact match = 0.639\n",
      "tried 913 words\n",
      "rejected 247 (27.1%) with invalid suffixes\n",
      "scoring 666 valid predictions\n",
      "\n",
      "--- filter analysis ---\n",
      "filter precision: 74.2%\n",
      "false rejection rate: 15.3%\n",
      "  correct kept: 494\n",
      "  correct rejected: 89\n",
      "  total correct: 583\n",
      "\n",
      "--- final scores (valid predictions only) ---\n",
      "boundary (micro) P/R/F1 = 0.888/0.909/0.898\n",
      "exact match = 0.742\n",
      "\n",
      "================================================================================\n",
      "trying: gpt5mini | first | 200\n",
      "================================================================================\n",
      "loading synthetic data from data\\gpt5mini_synthetic_segmentations.csv...\n",
      "loaded 5,000 synthetic examples\n",
      "looking for model 2567ee1a01ab9602...\n",
      "loaded artifacts from models_Markov-LSTM-MarkovFilter\\2567ee1a01ab9602\n",
      "found it! loading from models_Markov-LSTM-MarkovFilter\\2567ee1a01ab9602\n",
      "skipping training, model ready\n",
      "evaluated 913 words\n",
      "boundary (micro) P/R/F1 = 0.816/0.859/0.837\n",
      "exact match = 0.589\n",
      "tried 913 words\n",
      "rejected 248 (27.2%) with invalid suffixes\n",
      "scoring 665 valid predictions\n",
      "\n",
      "--- filter analysis ---\n",
      "filter precision: 68.7%\n",
      "false rejection rate: 15.1%\n",
      "  correct kept: 457\n",
      "  correct rejected: 81\n",
      "  total correct: 538\n",
      "\n",
      "--- final scores (valid predictions only) ---\n",
      "boundary (micro) P/R/F1 = 0.856/0.900/0.877\n",
      "exact match = 0.687\n",
      "\n",
      "================================================================================\n",
      "trying: gpt4o | first | 300\n",
      "================================================================================\n",
      "loading synthetic data from data\\gpt4o_synthetic_segmentations.csv...\n",
      "loaded 2,382 synthetic examples\n",
      "looking for model 298543dc2bdfe697...\n",
      "loaded artifacts from models_Markov-LSTM-MarkovFilter\\298543dc2bdfe697\n",
      "found it! loading from models_Markov-LSTM-MarkovFilter\\298543dc2bdfe697\n",
      "skipping training, model ready\n",
      "evaluated 913 words\n",
      "boundary (micro) P/R/F1 = 0.829/0.877/0.852\n",
      "exact match = 0.618\n",
      "tried 913 words\n",
      "rejected 242 (26.5%) with invalid suffixes\n",
      "scoring 671 valid predictions\n",
      "\n",
      "--- filter analysis ---\n",
      "filter precision: 70.3%\n",
      "false rejection rate: 16.3%\n",
      "  correct kept: 472\n",
      "  correct rejected: 92\n",
      "  total correct: 564\n",
      "\n",
      "--- final scores (valid predictions only) ---\n",
      "boundary (micro) P/R/F1 = 0.867/0.910/0.888\n",
      "exact match = 0.703\n",
      "\n",
      "================================================================================\n",
      "trying: gpt5mini | first | 300\n",
      "================================================================================\n",
      "loading synthetic data from data\\gpt5mini_synthetic_segmentations.csv...\n",
      "loaded 5,000 synthetic examples\n",
      "looking for model d149571817079168...\n",
      "loaded artifacts from models_Markov-LSTM-MarkovFilter\\d149571817079168\n",
      "found it! loading from models_Markov-LSTM-MarkovFilter\\d149571817079168\n",
      "skipping training, model ready\n",
      "evaluated 913 words\n",
      "boundary (micro) P/R/F1 = 0.814/0.867/0.840\n",
      "exact match = 0.589\n",
      "tried 913 words\n",
      "rejected 249 (27.3%) with invalid suffixes\n",
      "scoring 664 valid predictions\n",
      "\n",
      "--- filter analysis ---\n",
      "filter precision: 68.7%\n",
      "false rejection rate: 15.2%\n",
      "  correct kept: 456\n",
      "  correct rejected: 82\n",
      "  total correct: 538\n",
      "\n",
      "--- final scores (valid predictions only) ---\n",
      "boundary (micro) P/R/F1 = 0.845/0.916/0.879\n",
      "exact match = 0.687\n",
      "\n",
      "================================================================================\n",
      "trying: gpt4o | random | 100\n",
      "================================================================================\n",
      "loading synthetic data from data\\gpt4o_synthetic_segmentations.csv...\n",
      "loaded 2,382 synthetic examples\n",
      "looking for model 04a4d5653b493462...\n",
      "loaded artifacts from models_Markov-LSTM-MarkovFilter\\04a4d5653b493462\n",
      "found it! loading from models_Markov-LSTM-MarkovFilter\\04a4d5653b493462\n",
      "skipping training, model ready\n",
      "evaluated 913 words\n",
      "boundary (micro) P/R/F1 = 0.821/0.878/0.849\n",
      "exact match = 0.621\n",
      "tried 913 words\n",
      "rejected 230 (25.2%) with invalid suffixes\n",
      "scoring 683 valid predictions\n",
      "\n",
      "--- filter analysis ---\n",
      "filter precision: 70.1%\n",
      "false rejection rate: 15.5%\n",
      "  correct kept: 479\n",
      "  correct rejected: 88\n",
      "  total correct: 567\n",
      "\n",
      "--- final scores (valid predictions only) ---\n",
      "boundary (micro) P/R/F1 = 0.856/0.915/0.885\n",
      "exact match = 0.701\n",
      "\n",
      "================================================================================\n",
      "trying: gpt5mini | random | 100\n",
      "================================================================================\n",
      "loading synthetic data from data\\gpt5mini_synthetic_segmentations.csv...\n",
      "loaded 5,000 synthetic examples\n",
      "looking for model ac3f637f6d7a1bcc...\n",
      "no checkpoint found, training from scratch...\n",
      "HMM: 574 suffixes, max len 8, unk penalty -11.53\n",
      "epoch 01 | loss=0.6686 | P/R/F1=0.895/0.892/0.893 | exact=0.619\n",
      "epoch 02 | loss=0.2762 | P/R/F1=0.918/0.957/0.937 | exact=0.757\n",
      "epoch 03 | loss=0.2090 | P/R/F1=0.940/0.975/0.957 | exact=0.826\n",
      "epoch 04 | loss=0.1776 | P/R/F1=0.964/0.970/0.967 | exact=0.869\n",
      "epoch 05 | loss=0.1542 | P/R/F1=0.959/0.977/0.968 | exact=0.871\n",
      "epoch 06 | loss=0.1469 | P/R/F1=0.963/0.977/0.970 | exact=0.881\n",
      "epoch 07 | loss=0.1325 | P/R/F1=0.974/0.978/0.976 | exact=0.905\n",
      "epoch 08 | loss=0.1286 | P/R/F1=0.980/0.973/0.977 | exact=0.905\n",
      "epoch 09 | loss=0.1218 | P/R/F1=0.970/0.983/0.977 | exact=0.908\n",
      "epoch 10 | loss=0.1215 | P/R/F1=0.964/0.983/0.973 | exact=0.897\n",
      "epoch 11 | loss=0.1129 | P/R/F1=0.972/0.979/0.976 | exact=0.911\n",
      "epoch 12 | loss=0.1112 | P/R/F1=0.969/0.982/0.975 | exact=0.907\n",
      "epoch 13 | loss=0.1072 | P/R/F1=0.979/0.972/0.975 | exact=0.906\n",
      "epoch 14 | loss=0.1076 | P/R/F1=0.974/0.979/0.976 | exact=0.908\n",
      "epoch 15 | loss=0.1042 | P/R/F1=0.973/0.985/0.979 | exact=0.919\n",
      "best threshold: 0.470 | exact=0.920 | F1=0.979\n",
      "saving model ac3f637f6d7a1bcc...\n",
      "saved model to models_Markov-LSTM-MarkovFilter\\ac3f637f6d7a1bcc\n",
      "evaluated 913 words\n",
      "boundary (micro) P/R/F1 = 0.789/0.872/0.829\n",
      "exact match = 0.544\n",
      "tried 913 words\n",
      "rejected 265 (29.0%) with invalid suffixes\n",
      "scoring 648 valid predictions\n",
      "\n",
      "--- filter analysis ---\n",
      "filter precision: 65.1%\n",
      "false rejection rate: 15.1%\n",
      "  correct kept: 422\n",
      "  correct rejected: 75\n",
      "  total correct: 497\n",
      "\n",
      "--- final scores (valid predictions only) ---\n",
      "boundary (micro) P/R/F1 = 0.832/0.917/0.873\n",
      "exact match = 0.651\n",
      "\n",
      "================================================================================\n",
      "trying: gpt4o | random | 200\n",
      "================================================================================\n",
      "loading synthetic data from data\\gpt4o_synthetic_segmentations.csv...\n",
      "loaded 2,382 synthetic examples\n",
      "looking for model 0dbdce1bde73fec1...\n",
      "loaded artifacts from models_Markov-LSTM-MarkovFilter\\0dbdce1bde73fec1\n",
      "found it! loading from models_Markov-LSTM-MarkovFilter\\0dbdce1bde73fec1\n",
      "skipping training, model ready\n",
      "evaluated 913 words\n",
      "boundary (micro) P/R/F1 = 0.844/0.864/0.854\n",
      "exact match = 0.639\n",
      "tried 913 words\n",
      "rejected 247 (27.1%) with invalid suffixes\n",
      "scoring 666 valid predictions\n",
      "\n",
      "--- filter analysis ---\n",
      "filter precision: 74.2%\n",
      "false rejection rate: 15.3%\n",
      "  correct kept: 494\n",
      "  correct rejected: 89\n",
      "  total correct: 583\n",
      "\n",
      "--- final scores (valid predictions only) ---\n",
      "boundary (micro) P/R/F1 = 0.888/0.909/0.898\n",
      "exact match = 0.742\n",
      "\n",
      "================================================================================\n",
      "trying: gpt5mini | random | 200\n",
      "================================================================================\n",
      "loading synthetic data from data\\gpt5mini_synthetic_segmentations.csv...\n",
      "loaded 5,000 synthetic examples\n",
      "looking for model 68cbf2dd0330de24...\n",
      "no checkpoint found, training from scratch...\n",
      "HMM: 617 suffixes, max len 11, unk penalty -11.63\n",
      "epoch 01 | loss=0.9757 | P/R/F1=0.873/0.739/0.801 | exact=0.434\n",
      "epoch 02 | loss=0.3661 | P/R/F1=0.892/0.965/0.927 | exact=0.722\n",
      "epoch 03 | loss=0.2485 | P/R/F1=0.923/0.968/0.945 | exact=0.796\n",
      "epoch 04 | loss=0.2010 | P/R/F1=0.930/0.978/0.953 | exact=0.825\n",
      "epoch 05 | loss=0.1760 | P/R/F1=0.960/0.956/0.958 | exact=0.856\n",
      "epoch 06 | loss=0.1524 | P/R/F1=0.954/0.972/0.963 | exact=0.874\n",
      "epoch 07 | loss=0.1400 | P/R/F1=0.966/0.957/0.962 | exact=0.868\n",
      "epoch 08 | loss=0.1275 | P/R/F1=0.962/0.972/0.967 | exact=0.883\n",
      "epoch 09 | loss=0.1198 | P/R/F1=0.960/0.972/0.966 | exact=0.878\n",
      "epoch 10 | loss=0.1114 | P/R/F1=0.966/0.969/0.967 | exact=0.887\n",
      "epoch 11 | loss=0.1094 | P/R/F1=0.966/0.970/0.968 | exact=0.893\n",
      "epoch 12 | loss=0.0976 | P/R/F1=0.965/0.968/0.967 | exact=0.894\n",
      "epoch 13 | loss=0.0990 | P/R/F1=0.969/0.966/0.967 | exact=0.897\n",
      "epoch 14 | loss=0.0967 | P/R/F1=0.965/0.971/0.968 | exact=0.898\n",
      "epoch 15 | loss=0.0921 | P/R/F1=0.970/0.967/0.969 | exact=0.891\n",
      "best threshold: 0.430 | exact=0.895 | F1=0.970\n",
      "saving model 68cbf2dd0330de24...\n",
      "saved model to models_Markov-LSTM-MarkovFilter\\68cbf2dd0330de24\n",
      "evaluated 913 words\n",
      "boundary (micro) P/R/F1 = 0.798/0.861/0.828\n",
      "exact match = 0.558\n",
      "tried 913 words\n",
      "rejected 250 (27.4%) with invalid suffixes\n",
      "scoring 663 valid predictions\n",
      "\n",
      "--- filter analysis ---\n",
      "filter precision: 66.2%\n",
      "false rejection rate: 13.8%\n",
      "  correct kept: 439\n",
      "  correct rejected: 70\n",
      "  total correct: 509\n",
      "\n",
      "--- final scores (valid predictions only) ---\n",
      "boundary (micro) P/R/F1 = 0.835/0.909/0.870\n",
      "exact match = 0.662\n",
      "\n",
      "================================================================================\n",
      "trying: gpt4o | random | 300\n",
      "================================================================================\n",
      "loading synthetic data from data\\gpt4o_synthetic_segmentations.csv...\n",
      "loaded 2,382 synthetic examples\n",
      "looking for model 298543dc2bdfe697...\n",
      "loaded artifacts from models_Markov-LSTM-MarkovFilter\\298543dc2bdfe697\n",
      "found it! loading from models_Markov-LSTM-MarkovFilter\\298543dc2bdfe697\n",
      "skipping training, model ready\n",
      "evaluated 913 words\n",
      "boundary (micro) P/R/F1 = 0.829/0.877/0.852\n",
      "exact match = 0.618\n",
      "tried 913 words\n",
      "rejected 242 (26.5%) with invalid suffixes\n",
      "scoring 671 valid predictions\n",
      "\n",
      "--- filter analysis ---\n",
      "filter precision: 70.3%\n",
      "false rejection rate: 16.3%\n",
      "  correct kept: 472\n",
      "  correct rejected: 92\n",
      "  total correct: 564\n",
      "\n",
      "--- final scores (valid predictions only) ---\n",
      "boundary (micro) P/R/F1 = 0.867/0.910/0.888\n",
      "exact match = 0.703\n",
      "\n",
      "================================================================================\n",
      "trying: gpt5mini | random | 300\n",
      "================================================================================\n",
      "loading synthetic data from data\\gpt5mini_synthetic_segmentations.csv...\n",
      "loaded 5,000 synthetic examples\n",
      "looking for model d27c841383c9b0b5...\n",
      "no checkpoint found, training from scratch...\n",
      "HMM: 683 suffixes, max len 11, unk penalty -11.77\n",
      "epoch 01 | loss=0.9709 | P/R/F1=0.832/0.747/0.787 | exact=0.393\n",
      "epoch 02 | loss=0.3744 | P/R/F1=0.890/0.947/0.917 | exact=0.689\n",
      "epoch 03 | loss=0.2660 | P/R/F1=0.927/0.947/0.937 | exact=0.765\n",
      "epoch 04 | loss=0.2218 | P/R/F1=0.942/0.947/0.944 | exact=0.798\n",
      "epoch 05 | loss=0.1992 | P/R/F1=0.944/0.967/0.955 | exact=0.840\n",
      "epoch 06 | loss=0.1787 | P/R/F1=0.959/0.961/0.960 | exact=0.857\n",
      "epoch 07 | loss=0.1630 | P/R/F1=0.954/0.970/0.961 | exact=0.862\n",
      "epoch 08 | loss=0.1506 | P/R/F1=0.961/0.966/0.964 | exact=0.877\n",
      "epoch 09 | loss=0.1413 | P/R/F1=0.963/0.960/0.962 | exact=0.872\n",
      "epoch 10 | loss=0.1308 | P/R/F1=0.962/0.967/0.965 | exact=0.882\n",
      "epoch 11 | loss=0.1249 | P/R/F1=0.959/0.971/0.965 | exact=0.880\n",
      "epoch 12 | loss=0.1159 | P/R/F1=0.968/0.961/0.964 | exact=0.878\n",
      "epoch 13 | loss=0.1173 | P/R/F1=0.965/0.971/0.967 | exact=0.891\n",
      "epoch 14 | loss=0.1092 | P/R/F1=0.967/0.963/0.965 | exact=0.882\n",
      "epoch 15 | loss=0.1090 | P/R/F1=0.966/0.964/0.965 | exact=0.883\n",
      "best threshold: 0.570 | exact=0.886 | F1=0.965\n",
      "saving model d27c841383c9b0b5...\n",
      "saved model to models_Markov-LSTM-MarkovFilter\\d27c841383c9b0b5\n",
      "evaluated 913 words\n",
      "boundary (micro) P/R/F1 = 0.820/0.807/0.814\n",
      "exact match = 0.548\n",
      "tried 913 words\n",
      "rejected 279 (30.6%) with invalid suffixes\n",
      "scoring 634 valid predictions\n",
      "\n",
      "--- filter analysis ---\n",
      "filter precision: 66.4%\n",
      "false rejection rate: 15.8%\n",
      "  correct kept: 421\n",
      "  correct rejected: 79\n",
      "  total correct: 500\n",
      "\n",
      "--- final scores (valid predictions only) ---\n",
      "boundary (micro) P/R/F1 = 0.851/0.870/0.860\n",
      "exact match = 0.664\n",
      "\n",
      "================================================================================\n",
      "augmentation comparison results\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config</th>\n",
       "      <th>base_exact</th>\n",
       "      <th>base_f1</th>\n",
       "      <th>filtered_exact</th>\n",
       "      <th>filtered_f1</th>\n",
       "      <th>filter_prec</th>\n",
       "      <th>false_rej_rate</th>\n",
       "      <th>rejections</th>\n",
       "      <th>false_rej</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no augmentation</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.862</td>\n",
       "      <td>66.6%</td>\n",
       "      <td>15.1%</td>\n",
       "      <td>245</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt4o first 100</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.866</td>\n",
       "      <td>64.7%</td>\n",
       "      <td>14.6%</td>\n",
       "      <td>242</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt5mini first 100</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.863</td>\n",
       "      <td>65.5%</td>\n",
       "      <td>13.7%</td>\n",
       "      <td>241</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt4o first 200</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.898</td>\n",
       "      <td>74.2%</td>\n",
       "      <td>15.3%</td>\n",
       "      <td>247</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt5mini first 200</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.877</td>\n",
       "      <td>68.7%</td>\n",
       "      <td>15.1%</td>\n",
       "      <td>248</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt4o first 300</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.888</td>\n",
       "      <td>70.3%</td>\n",
       "      <td>16.3%</td>\n",
       "      <td>242</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt5mini first 300</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.879</td>\n",
       "      <td>68.7%</td>\n",
       "      <td>15.2%</td>\n",
       "      <td>249</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt4o random 100</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.885</td>\n",
       "      <td>70.1%</td>\n",
       "      <td>15.5%</td>\n",
       "      <td>230</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt5mini random 100</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.873</td>\n",
       "      <td>65.1%</td>\n",
       "      <td>15.1%</td>\n",
       "      <td>265</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt4o random 200</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.898</td>\n",
       "      <td>74.2%</td>\n",
       "      <td>15.3%</td>\n",
       "      <td>247</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt5mini random 200</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.870</td>\n",
       "      <td>66.2%</td>\n",
       "      <td>13.8%</td>\n",
       "      <td>250</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt4o random 300</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.888</td>\n",
       "      <td>70.3%</td>\n",
       "      <td>16.3%</td>\n",
       "      <td>242</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt5mini random 300</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.860</td>\n",
       "      <td>66.4%</td>\n",
       "      <td>15.8%</td>\n",
       "      <td>279</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 config base_exact base_f1 filtered_exact filtered_f1  \\\n",
       "0       no augmentation      0.574   0.822          0.666       0.862   \n",
       "1       gpt4o first 100      0.556   0.827          0.647       0.866   \n",
       "2    gpt5mini first 100      0.559   0.823          0.655       0.863   \n",
       "3       gpt4o first 200      0.639   0.854          0.742       0.898   \n",
       "4    gpt5mini first 200      0.589   0.837          0.687       0.877   \n",
       "5       gpt4o first 300      0.618   0.852          0.703       0.888   \n",
       "6    gpt5mini first 300      0.589   0.840          0.687       0.879   \n",
       "7      gpt4o random 100      0.621   0.849          0.701       0.885   \n",
       "8   gpt5mini random 100      0.544   0.829          0.651       0.873   \n",
       "9      gpt4o random 200      0.639   0.854          0.742       0.898   \n",
       "10  gpt5mini random 200      0.558   0.828          0.662       0.870   \n",
       "11     gpt4o random 300      0.618   0.852          0.703       0.888   \n",
       "12  gpt5mini random 300      0.548   0.814          0.664       0.860   \n",
       "\n",
       "   filter_prec false_rej_rate  rejections  false_rej  \n",
       "0        66.6%          15.1%         245         79  \n",
       "1        64.7%          14.6%         242         74  \n",
       "2        65.5%          13.7%         241         70  \n",
       "3        74.2%          15.3%         247         89  \n",
       "4        68.7%          15.1%         248         81  \n",
       "5        70.3%          16.3%         242         92  \n",
       "6        68.7%          15.2%         249         82  \n",
       "7        70.1%          15.5%         230         88  \n",
       "8        65.1%          15.1%         265         75  \n",
       "9        74.2%          15.3%         247         89  \n",
       "10       66.2%          13.8%         250         70  \n",
       "11       70.3%          16.3%         242         92  \n",
       "12       66.4%          15.8%         279         79  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saved to data\\augmentation_comparison_table.csv\n"
     ]
    }
   ],
   "source": [
    "# synthetic data augmentation comparison\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "def evaluate_augmentation_config(\n",
    "    synthetic_choice,\n",
    "    word_selection,\n",
    "    n_words,\n",
    "    str_df_base,\n",
    "    acc_df,\n",
    "    suffix_list,\n",
    "    best_hparams,\n",
    "    lambda_prior=0.15289202508573396,\n",
    "    lambda_k=0.2\n",
    "):\n",
    "    \"\"\"trains and evals with one augmentation setup.\"\"\"\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"trying: {synthetic_choice} | {word_selection} | {n_words}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "    if synthetic_choice == \"none\":\n",
    "        train_str_df = str_df_base.copy()\n",
    "    else:\n",
    "        synthetic_df = load_synthetic_data(synthetic_choice)\n",
    "        if synthetic_df is None:\n",
    "            print(f\"couldnt get {synthetic_choice} data, skipping\")\n",
    "            return None\n",
    "        \n",
    "        gpt_5_mini_words = set(gpt_5_mini_df['Word'])\n",
    "        gpt_4o_words = set(gpt_4o_df['Word'])\n",
    "        common_words = gpt_4o_words.intersection(gpt_5_mini_words)\n",
    "        \n",
    "        if word_selection == \"first\":\n",
    "            sorted_words = sorted(common_words)\n",
    "            n = min(n_words, len(sorted_words))\n",
    "            selected_words = set(sorted_words[:n])\n",
    "        elif word_selection == \"random\":\n",
    "            import random\n",
    "            random.seed(42)\n",
    "            n = min(n_words, len(common_words))\n",
    "            selected_words = set(random.sample(list(common_words), n))\n",
    "        else:\n",
    "            selected_words = common_words\n",
    "        \n",
    "        df_sampled = synthetic_df[synthetic_df['Word'].isin(selected_words)]\n",
    "        \n",
    "        # need fresh gold data\n",
    "        gold_df_temp = pd.read_parquet(os.path.join(DATA_FOLDER, \"Sue_kalt.parquet\"))\n",
    "        gold_df_temp['Word'] = gold_df_temp['word']\n",
    "        gold_df_temp['morph'] = gold_df_temp['morph'].str.replace('-', ' ')\n",
    "        gold_df_temp['Morph_split_str'] = gold_df_temp['morph']\n",
    "        gold_df_temp['Morph_split'] = gold_df_temp['morph'].str.split(' ')\n",
    "        gold_df_temp = gold_df_temp[['Word', 'Morph_split', 'Morph_split_str']]\n",
    "        gold_df_temp.drop_duplicates(subset='Word', keep='first', inplace=True)\n",
    "        gold_df_temp.dropna(subset=['Word'], inplace=True)\n",
    "        \n",
    "        train_df = pd.concat([df_sampled, gold_df_temp], ignore_index=True)\n",
    "        \n",
    "        # do the preprocessing\n",
    "        train_df[\"Char_split\"] = train_df[\"Morph_split\"].apply(tokenize_morphemes)\n",
    "        train_df[\"CV_split\"] = train_df[\"Char_split\"].apply(morphs_to_cv)\n",
    "        \n",
    "        train_str_df = pd.DataFrame()\n",
    "        train_str_df[\"Full_chain\"] = train_df[\"CV_split\"].apply(cv_to_string)\n",
    "        train_str_df[\"Trimmed_chain\"] = train_str_df[\"Full_chain\"].apply(\n",
    "            lambda x: x.split(\"-\", 1)[1] if \"-\" in x else np.nan\n",
    "        )\n",
    "        train_str_df[\"Word\"] = train_df[\"Word\"]\n",
    "        train_str_df[\"Char_split\"] = train_df[\"Char_split\"]\n",
    "        train_str_df[\"Morph_split\"] = train_df[\"Morph_split\"]\n",
    "        train_str_df = train_str_df.dropna(subset=[\"Trimmed_chain\"]).reset_index(drop=True)\n",
    "        \n",
    "        # add the features\n",
    "        train_str_df[\"Word_len\"] = train_str_df[\"Word\"].str.len()\n",
    "        train_str_df[\"Vowel_no\"] = train_str_df[\"Full_chain\"].str.count(\"V\")\n",
    "        train_str_df[\"Cons_no\"] = train_str_df[\"Full_chain\"].str.count(\"C\")\n",
    "        train_str_df[\"Tail_cons_no\"] = train_str_df[\"Trimmed_chain\"].str.count(\"C\")\n",
    "        train_str_df[\"Tail_vowel_no\"] = train_str_df[\"Trimmed_chain\"].str.count(\"V\")\n",
    "        train_str_df[\"No_splits\"] = train_str_df[\"Morph_split\"].str.len()\n",
    "        train_str_df[\"YW_count\"] = train_str_df[\"Word\"].str.count(\"[yw]\")\n",
    "        train_str_df[\"Tail_YW_count\"] = train_str_df[\"Morph_split\"].apply(\n",
    "            lambda ms: sum(m.count(\"y\") + m.count(\"w\") for m in ms[1:])\n",
    "        )\n",
    "    \n",
    "    model, vocab, out = run_segmentation_with_privK(\n",
    "        df=train_str_df,\n",
    "        provided_suffix_list=suffix_list,\n",
    "        use_suffix_list=False,\n",
    "        unk_penalty=-15.0,\n",
    "        epochs=15,\n",
    "        use_prior=True,\n",
    "        lambda_prior=lambda_prior,\n",
    "        lambda_k=lambda_k,\n",
    "        hparams=best_hparams,\n",
    "        synthetic_choice=synthetic_choice\n",
    "    )\n",
    "    \n",
    "    # without the suffix filter\n",
    "    results_base = evaluate_on_gold_df(\n",
    "        acc_df, model, vocab, out,\n",
    "        max_token_len=4,\n",
    "        use_tuned_thr=True,\n",
    "        show_sample=0\n",
    "    )\n",
    "    \n",
    "    # with suffix filter\n",
    "    results_filtered = evaluate_and_ignore_rejected(\n",
    "        acc_df, model, vocab, out,\n",
    "        allowed_suffixes=suffix_list,\n",
    "        max_token_len=4,\n",
    "        use_tuned_thr=True,\n",
    "        show_sample=0\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"base_exact_match\": results_base[\"exact_match_rate\"],\n",
    "        \"base_f1\": results_base[\"micro_f1\"],\n",
    "        \"filtered_exact_match\": results_filtered[\"exact_match_rate\"],\n",
    "        \"filtered_f1\": results_filtered[\"micro_f1\"],\n",
    "        \"filter_precision\": results_filtered[\"filter_precision\"],\n",
    "        \"false_rejection_rate\": results_filtered[\"false_rejection_rate\"],\n",
    "        \"rejection_count\": results_filtered[\"rejection_count\"],\n",
    "        \"false_rejection_count\": results_filtered[\"false_rejection_count\"]\n",
    "    }\n",
    "\n",
    "print(\"grabbing gold data for comparison...\")\n",
    "gold_df_base = pd.read_parquet(os.path.join(DATA_FOLDER, \"Sue_kalt.parquet\"))\n",
    "gold_df_base['Word'] = gold_df_base['word']\n",
    "gold_df_base['morph'] = gold_df_base['morph'].str.replace('-', ' ')\n",
    "gold_df_base['Morph_split_str'] = gold_df_base['morph']\n",
    "gold_df_base['Morph_split'] = gold_df_base['morph'].str.split(' ')\n",
    "gold_df_base = gold_df_base[['Word', 'Morph_split', 'Morph_split_str']]\n",
    "gold_df_base.drop_duplicates(subset='Word', keep='first', inplace=True)\n",
    "gold_df_base.dropna(subset=['Word'], inplace=True)\n",
    "\n",
    "gold_df_base[\"Char_split\"] = gold_df_base[\"Morph_split\"].apply(tokenize_morphemes)\n",
    "gold_df_base[\"CV_split\"] = gold_df_base[\"Char_split\"].apply(morphs_to_cv)\n",
    "\n",
    "str_df_base = pd.DataFrame()\n",
    "str_df_base[\"Full_chain\"] = gold_df_base[\"CV_split\"].apply(cv_to_string)\n",
    "str_df_base[\"Trimmed_chain\"] = str_df_base[\"Full_chain\"].apply(\n",
    "    lambda x: x.split(\"-\", 1)[1] if \"-\" in x else np.nan\n",
    ")\n",
    "str_df_base[\"Word\"] = gold_df_base[\"Word\"]\n",
    "str_df_base[\"Char_split\"] = gold_df_base[\"Char_split\"]\n",
    "str_df_base[\"Morph_split\"] = gold_df_base[\"Morph_split\"]\n",
    "str_df_base = str_df_base.dropna(subset=[\"Trimmed_chain\"]).reset_index(drop=True)\n",
    "\n",
    "str_df_base[\"Word_len\"] = str_df_base[\"Word\"].str.len()\n",
    "str_df_base[\"Vowel_no\"] = str_df_base[\"Full_chain\"].str.count(\"V\")\n",
    "str_df_base[\"Cons_no\"] = str_df_base[\"Full_chain\"].str.count(\"C\")\n",
    "str_df_base[\"Tail_cons_no\"] = str_df_base[\"Trimmed_chain\"].str.count(\"C\")\n",
    "str_df_base[\"Tail_vowel_no\"] = str_df_base[\"Trimmed_chain\"].str.count(\"V\")\n",
    "str_df_base[\"No_splits\"] = str_df_base[\"Morph_split\"].str.len()\n",
    "str_df_base[\"YW_count\"] = str_df_base[\"Word\"].str.count(\"[yw]\")\n",
    "str_df_base[\"Tail_YW_count\"] = str_df_base[\"Morph_split\"].apply(\n",
    "    lambda ms: sum(m.count(\"y\") + m.count(\"w\") for m in ms[1:])\n",
    ")\n",
    "\n",
    "# configs to try - none, gpt4o, gpt5mini with different word counts\n",
    "configs = [\n",
    "    (\"none\", None, None),\n",
    "    (\"gpt4o\", \"first\", 100),\n",
    "    (\"gpt5mini\", \"first\", 100),\n",
    "    (\"gpt4o\", \"first\", 200),\n",
    "    (\"gpt5mini\", \"first\", 200),\n",
    "    (\"gpt4o\", \"first\", 300),\n",
    "    (\"gpt5mini\", \"first\", 300),\n",
    "    (\"gpt4o\", \"random\", 100),\n",
    "    (\"gpt5mini\", \"random\", 100),\n",
    "    (\"gpt4o\", \"random\", 200),\n",
    "    (\"gpt5mini\", \"random\", 200),\n",
    "    (\"gpt4o\", \"random\", 300),\n",
    "    (\"gpt5mini\", \"random\", 300),\n",
    "]\n",
    "\n",
    "results_list = []\n",
    "for synthetic_choice, word_selection, n_words in configs:\n",
    "    try:\n",
    "        result = evaluate_augmentation_config(\n",
    "            synthetic_choice=synthetic_choice,\n",
    "            word_selection=word_selection,\n",
    "            n_words=n_words,\n",
    "            str_df_base=str_df_base,\n",
    "            acc_df=acc_df,\n",
    "            suffix_list=suffix_list,\n",
    "            best_hparams=best,\n",
    "            lambda_prior=0.15289202508573396,\n",
    "            lambda_k=0.2\n",
    "        )\n",
    "        \n",
    "        if result is not None:\n",
    "            if synthetic_choice == \"none\":\n",
    "                config_name = \"no augmentation\"\n",
    "            else:\n",
    "                config_name = f\"{synthetic_choice} {word_selection} {n_words}\"\n",
    "            \n",
    "            results_list.append({\n",
    "                \"config\": config_name,\n",
    "                \"base_exact\": f\"{result['base_exact_match']:.3f}\",\n",
    "                \"base_f1\": f\"{result['base_f1']:.3f}\",\n",
    "                \"filtered_exact\": f\"{result['filtered_exact_match']:.3f}\",\n",
    "                \"filtered_f1\": f\"{result['filtered_f1']:.3f}\",\n",
    "                \"filter_prec\": f\"{result['filter_precision']:.1%}\",\n",
    "                \"false_rej_rate\": f\"{result['false_rejection_rate']:.1%}\",\n",
    "                \"rejections\": result['rejection_count'],\n",
    "                \"false_rej\": result['false_rejection_count']\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"oops, {synthetic_choice} {word_selection} {n_words} failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if results_list:\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"augmentation comparison results\")\n",
    "    print(\"=\" * 80)\n",
    "    display(results_df)\n",
    "    \n",
    "    output_file = os.path.join(DATA_FOLDER, \"augmentation_comparison_table.csv\")\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nsaved to {output_file}\")\n",
    "else:\n",
    "    print(\"nothing to show\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
