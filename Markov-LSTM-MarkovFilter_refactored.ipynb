{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be5f0263",
   "metadata": {},
   "source": [
    "# Markov-LSTM-Markov Filter: Quechua Morphology Parser\n",
    "\n",
    "Morphological segmentation for Quechua using:\n",
    "- BiLSTM for boundary prediction\n",
    "- HMM priors from suffix patterns\n",
    "- K-teacher regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3edaf022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "import math\n",
    "import hashlib\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Set, Tuple\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ML & DL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold, GroupShuffleSplit\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715718fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_FOLDER = \"data\"\n",
    "MODEL_NAME = \"Markov-LSTM-MarkovFilter\"\n",
    "MODELS_FOLDER = f\"models_{MODEL_NAME}\"\n",
    "os.makedirs(MODELS_FOLDER, exist_ok=True)\n",
    "\n",
    "# Synthetic data options: \"none\", \"gpt4o\", \"gpt5mini\"\n",
    "SYNTHETIC_DATA_CHOICE = \"none\"\n",
    "\n",
    "# Word selection for augmentation: \"all\", \"first\", \"random\"\n",
    "AUGMENTATION_WORD_SELECTION = \"random\"\n",
    "AUGMENTATION_N_WORDS = 100\n",
    "\n",
    "# Random seed\n",
    "RNG = 42\n",
    "torch.manual_seed(RNG)\n",
    "np.random.seed(RNG)\n",
    "\n",
    "# Feature columns used for privileged knowledge\n",
    "NEW_NUM_FEATS = [\n",
    "    \"Word_len\", \"Vowel_no\", \"Cons_no\",\n",
    "    \"Tail_cons_no\", \"Tail_vowel_no\",\n",
    "    \"No_splits\", \"YW_count\", \"Tail_YW_count\"\n",
    "]\n",
    "\n",
    "# Quechua graphemes for tokenization\n",
    "graphemes = [\n",
    "    \"ch\", \"ll\", \"rr\", \"tr\", \"kw\", \"ph\",\n",
    "    \"a\", \"b\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"k\", \"l\", \"m\", \"n\", \"ñ\", \"o\", \"p\", \"q\",\n",
    "    \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ddf264e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading gold data...\n",
      "got 6,896 gold examples\n"
     ]
    }
   ],
   "source": [
    "# Load the gold standard segmentations\n",
    "print(\"loading gold data...\")\n",
    "gold_df = pd.read_parquet(os.path.join(DATA_FOLDER, \"Sue_kalt.parquet\"))\n",
    "gold_df['Word'] = gold_df['word']\n",
    "gold_df['morph'] = gold_df['morph'].str.replace('-', ' ')\n",
    "gold_df['Morph_split_str'] = gold_df['morph']\n",
    "gold_df['Morph_split'] = gold_df['morph'].str.split(' ')\n",
    "gold_df = gold_df[['Word', 'Morph_split', 'Morph_split_str']]\n",
    "gold_df.drop_duplicates(subset='Word', keep='first', inplace=True)\n",
    "gold_df.dropna(subset=['Word'], inplace=True)\n",
    "print(f\"got {len(gold_df):,} gold examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "511455b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no synthetic augmentation\n"
     ]
    }
   ],
   "source": [
    "def load_synthetic_data(choice):\n",
    "    \"\"\"Load GPT-generated segmentations if augmentation is enabled.\"\"\"\n",
    "    if choice == \"none\":\n",
    "        print(\"no synthetic augmentation\")\n",
    "        return None\n",
    "    \n",
    "    file_map = {\n",
    "        \"gpt4o\": \"gpt4o_synthetic_segmentations.csv\",\n",
    "        \"gpt5mini\": \"gpt5mini_synthetic_segmentations.csv\"\n",
    "    }\n",
    "    \n",
    "    if choice not in file_map:\n",
    "        print(f\"unknown choice '{choice}', skipping augmentation\")\n",
    "        return None\n",
    "    \n",
    "    file_path = os.path.join(DATA_FOLDER, file_map[choice])\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"file not found: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"loading synthetic data from {file_path}...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.drop_duplicates(subset=['Original_Word']).reset_index(drop=True)\n",
    "    \n",
    "    # Filter out garbage responses\n",
    "    bad_strings = ['can\\'t', 'quechua', 'sorry', 'could']\n",
    "    df = df[~df['Segmented_Morphemes'].str.contains('|'.join(bad_strings), case=False, na=False)]\n",
    "    \n",
    "    df = df.rename(columns={'Original_Word': 'Word'})\n",
    "    df['Morph_split_str'] = df['Segmented_Morphemes']\n",
    "    df['Morph_split'] = df['Segmented_Morphemes'].str.split(' ')\n",
    "    df = df[['Word', 'Morph_split', 'Morph_split_str']]\n",
    "    \n",
    "    print(f\"loaded {len(df):,} synthetic examples\")\n",
    "    return df\n",
    "\n",
    "synthetic_df = load_synthetic_data(SYNTHETIC_DATA_CHOICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c82ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words in both GPT sets: 469\n"
     ]
    }
   ],
   "source": [
    "# Load GPT data separately for finding common words\n",
    "gpt_5_mini_df = pd.read_csv(os.path.join(DATA_FOLDER, \"gpt5mini_synthetic_segmentations.csv\"))\n",
    "gpt_5_mini_df = gpt_5_mini_df.drop_duplicates(subset=['Original_Word']).reset_index(drop=True)\n",
    "bad_strings = ['can\\'t', 'quechua', 'sorry', 'could']\n",
    "gpt_5_mini_df = gpt_5_mini_df[~gpt_5_mini_df['Segmented_Morphemes'].str.contains('|'.join(bad_strings), case=False, na=False)]\n",
    "gpt_5_mini_df = gpt_5_mini_df.rename(columns={'Original_Word': 'Word'})\n",
    "gpt_5_mini_df['Morph_split_str'] = gpt_5_mini_df['Segmented_Morphemes']\n",
    "gpt_5_mini_df['Morph_split'] = gpt_5_mini_df['Segmented_Morphemes'].str.split(' ')\n",
    "gpt_5_mini_df = gpt_5_mini_df[['Word', 'Morph_split', 'Morph_split_str']]\n",
    "\n",
    "gpt_4o_df = pd.read_csv(os.path.join(DATA_FOLDER, \"gpt4o_synthetic_segmentations.csv\"))\n",
    "gpt_4o_df = gpt_4o_df.drop_duplicates(subset=['Original_Word']).reset_index(drop=True)\n",
    "gpt_4o_df = gpt_4o_df[~gpt_4o_df['Segmented_Morphemes'].str.contains('|'.join(bad_strings), case=False, na=False)]\n",
    "gpt_4o_df = gpt_4o_df.rename(columns={'Original_Word': 'Word'})\n",
    "gpt_4o_df['Morph_split_str'] = gpt_4o_df['Segmented_Morphemes']\n",
    "gpt_4o_df['Morph_split'] = gpt_4o_df['Segmented_Morphemes'].str.split(' ')\n",
    "gpt_4o_df = gpt_4o_df[['Word', 'Morph_split', 'Morph_split_str']]\n",
    "\n",
    "gpt_5_mini_words = set(gpt_5_mini_df['Word'])\n",
    "gpt_4o_words = set(gpt_4o_df['Word'])\n",
    "common_words = gpt_4o_words.intersection(gpt_5_mini_words)\n",
    "print(f\"words in both GPT sets: {len(common_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acc88edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold data only (no augmentation)\n"
     ]
    }
   ],
   "source": [
    "# Merge synthetic with gold if augmentation is on\n",
    "if synthetic_df is not None:\n",
    "    gpt_5_mini_words = set(gpt_5_mini_df['Word'])\n",
    "    gpt_4o_words = set(gpt_4o_df['Word'])\n",
    "    common_words = gpt_4o_words.intersection(gpt_5_mini_words)\n",
    "    print(f\"common words between GPT models: {len(common_words):,}\")\n",
    "    \n",
    "    if AUGMENTATION_WORD_SELECTION == \"all\":\n",
    "        selected_words = common_words\n",
    "        print(f\"using all {len(selected_words):,} common words\")\n",
    "    elif AUGMENTATION_WORD_SELECTION == \"first\":\n",
    "        sorted_words = sorted(common_words)\n",
    "        n = min(AUGMENTATION_N_WORDS, len(sorted_words))\n",
    "        selected_words = set(sorted_words[:n])\n",
    "        print(f\"using first {n:,} words alphabetically\")\n",
    "    elif AUGMENTATION_WORD_SELECTION == \"random\":\n",
    "        import random\n",
    "        seed = RNG if 'RNG' in globals() else 42\n",
    "        random.seed(seed)\n",
    "        n = min(AUGMENTATION_N_WORDS, len(common_words))\n",
    "        selected_words = set(random.sample(list(common_words), n))\n",
    "        print(f\"using {n:,} random words\")\n",
    "    else:\n",
    "        print(f\"unknown selection '{AUGMENTATION_WORD_SELECTION}', using all\")\n",
    "        selected_words = common_words\n",
    "    \n",
    "    if SYNTHETIC_DATA_CHOICE in [\"gpt5mini\", \"gpt4o\"]:\n",
    "        df_sampled = synthetic_df[synthetic_df['Word'].isin(selected_words)]\n",
    "    else:\n",
    "        df_sampled = None\n",
    "    \n",
    "    if df_sampled is not None and len(df_sampled) > 0:\n",
    "        gold_df = pd.concat([df_sampled, gold_df], ignore_index=True)\n",
    "        print(f\"combined: {len(gold_df):,} total examples\")\n",
    "    else:\n",
    "        print(\"no synthetic data added\")\n",
    "else:\n",
    "    print(\"gold data only (no augmentation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a08ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sampled words for reference\n",
    "if synthetic_df is not None and 'df_sampled' in locals() and df_sampled is not None:\n",
    "    df_sampled = df_sampled.sort_values(by=\"Word\")\n",
    "    output_file = os.path.join(DATA_FOLDER, f\"{SYNTHETIC_DATA_CHOICE}_common.parquet\")\n",
    "    df_sampled.to_parquet(output_file, index=False)\n",
    "    print(f\"saved common words to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7dfcfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET SUMMARY\n",
      "============================================================\n",
      "training: (6896, 3)\n",
      "test: (913, 5)\n",
      "augmentation: none\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load test set\n",
    "acc_df = pd.read_parquet(os.path.join(DATA_FOLDER, \"cleaned_data_df.parquet\"))\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"training: {gold_df.shape}\")\n",
    "print(f\"test: {acc_df.shape}\")\n",
    "print(f\"augmentation: {SYNTHETIC_DATA_CHOICE}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "549588f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"|\".join(sorted(graphemes, key=len, reverse=True)))\n",
    "\n",
    "def tokenize_morphemes(morphs):\n",
    "    \"\"\"Break morphemes into grapheme tokens.\"\"\"\n",
    "    return [pattern.findall(m.lower()) for m in morphs]\n",
    "\n",
    "gold_df[\"Char_split\"] = gold_df[\"Morph_split\"].apply(tokenize_morphemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "849abd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = {\"a\", \"i\", \"e\", \"o\", \"u\"}\n",
    "\n",
    "def grapheme_to_cv(grapheme):\n",
    "    return \"V\" if grapheme in vowels else \"C\"\n",
    "\n",
    "def morphs_to_cv(morphs):\n",
    "    \"\"\"Convert grapheme lists to CV (consonant/vowel) patterns.\"\"\"\n",
    "    return [[grapheme_to_cv(g) for g in morph] for morph in morphs]\n",
    "\n",
    "gold_df[\"CV_split\"] = gold_df[\"Char_split\"].apply(morphs_to_cv)\n",
    "\n",
    "def cv_to_string(cv_split):\n",
    "    \"\"\"Turn nested CV list into dash-separated string.\"\"\"\n",
    "    return \"-\".join(\"\".join(m) for m in cv_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ebf3dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full_chain</th>\n",
       "      <th>Trimmed_chain</th>\n",
       "      <th>Word</th>\n",
       "      <th>Char_split</th>\n",
       "      <th>Morph_split</th>\n",
       "      <th>Word_len</th>\n",
       "      <th>Vowel_no</th>\n",
       "      <th>Cons_no</th>\n",
       "      <th>Tail_cons_no</th>\n",
       "      <th>Tail_vowel_no</th>\n",
       "      <th>No_splits</th>\n",
       "      <th>YW_count</th>\n",
       "      <th>Tail_YW_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VCVCCVCVV-CVC</td>\n",
       "      <td>CVC</td>\n",
       "      <td>cementerioman</td>\n",
       "      <td>[[e, m, e, n, t, e, r, i, o], [m, a, n]]</td>\n",
       "      <td>[cementerio, man]</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVCCV-CCV-CV-C-CV</td>\n",
       "      <td>CCV-CV-C-CV</td>\n",
       "      <td>kawsachkananta</td>\n",
       "      <td>[[k, a, w, s, a], [ch, k, a], [n, a], [n], [t,...</td>\n",
       "      <td>[kawsa, chka, na, n, ta]</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVCV-CV-C-CVC</td>\n",
       "      <td>CV-C-CVC</td>\n",
       "      <td>mañakunpis</td>\n",
       "      <td>[[m, a, ñ, a], [k, u], [n], [p, i, s]]</td>\n",
       "      <td>[maña, ku, n, pis]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VCVCCV-CV-CVC</td>\n",
       "      <td>CV-CVC</td>\n",
       "      <td>imaynapichus</td>\n",
       "      <td>[[i, m, a, y, n, a], [p, i], [ch, u, s]]</td>\n",
       "      <td>[imayna, pi, chus]</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CVCV-CVC</td>\n",
       "      <td>CVC</td>\n",
       "      <td>qipiyuq</td>\n",
       "      <td>[[q, i, p, i], [y, u, q]]</td>\n",
       "      <td>[qipi, yuq]</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Full_chain Trimmed_chain            Word  \\\n",
       "0      VCVCCVCVV-CVC           CVC   cementerioman   \n",
       "1  CVCCV-CCV-CV-C-CV   CCV-CV-C-CV  kawsachkananta   \n",
       "2      CVCV-CV-C-CVC      CV-C-CVC      mañakunpis   \n",
       "3      VCVCCV-CV-CVC        CV-CVC    imaynapichus   \n",
       "4           CVCV-CVC           CVC         qipiyuq   \n",
       "\n",
       "                                          Char_split  \\\n",
       "0           [[e, m, e, n, t, e, r, i, o], [m, a, n]]   \n",
       "1  [[k, a, w, s, a], [ch, k, a], [n, a], [n], [t,...   \n",
       "2             [[m, a, ñ, a], [k, u], [n], [p, i, s]]   \n",
       "3           [[i, m, a, y, n, a], [p, i], [ch, u, s]]   \n",
       "4                          [[q, i, p, i], [y, u, q]]   \n",
       "\n",
       "                Morph_split  Word_len  Vowel_no  Cons_no  Tail_cons_no  \\\n",
       "0         [cementerio, man]        13         6        6             2   \n",
       "1  [kawsa, chka, na, n, ta]        14         5        8             5   \n",
       "2        [maña, ku, n, pis]        10         4        6             4   \n",
       "3        [imayna, pi, chus]        12         5        6             3   \n",
       "4               [qipi, yuq]         7         3        4             2   \n",
       "\n",
       "   Tail_vowel_no  No_splits  YW_count  Tail_YW_count  \n",
       "0              1          2         0              0  \n",
       "1              3          5         1              0  \n",
       "2              2          4         0              0  \n",
       "3              2          3         1              0  \n",
       "4              1          2         1              1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the feature dataframe\n",
    "str_df = pd.DataFrame()\n",
    "str_df[\"Full_chain\"] = gold_df[\"CV_split\"].apply(cv_to_string)\n",
    "str_df[\"Trimmed_chain\"] = str_df[\"Full_chain\"].apply(\n",
    "    lambda x: x.split(\"-\", 1)[1] if \"-\" in x else np.nan\n",
    ")\n",
    "str_df[\"Word\"] = gold_df[\"Word\"]\n",
    "str_df[\"Char_split\"] = gold_df[\"Char_split\"]\n",
    "str_df[\"Morph_split\"] = gold_df[\"Morph_split\"]\n",
    "str_df = str_df.dropna(subset=[\"Trimmed_chain\"]).reset_index(drop=True)\n",
    "\n",
    "# Numeric features\n",
    "str_df[\"Word_len\"] = str_df[\"Word\"].str.len()\n",
    "str_df[\"Vowel_no\"] = str_df[\"Full_chain\"].str.count(\"V\")\n",
    "str_df[\"Cons_no\"] = str_df[\"Full_chain\"].str.count(\"C\")\n",
    "str_df[\"Tail_cons_no\"] = str_df[\"Trimmed_chain\"].str.count(\"C\")\n",
    "str_df[\"Tail_vowel_no\"] = str_df[\"Trimmed_chain\"].str.count(\"V\")\n",
    "str_df[\"No_splits\"] = str_df[\"Morph_split\"].str.len()\n",
    "str_df[\"YW_count\"] = str_df[\"Word\"].str.count(\"[yw]\")\n",
    "str_df[\"Tail_YW_count\"] = str_df[\"Morph_split\"].apply(\n",
    "    lambda ms: sum(m.count(\"y\") + m.count(\"w\") for m in ms[1:])\n",
    ")\n",
    "\n",
    "str_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed0780b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_list(x):\n",
    "    \"\"\"Handle various list-like formats from dataframes.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    s = str(x)\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except Exception:\n",
    "        s2 = s.replace(\"[[\", \"[['\").replace(\"]]\", \"']]\").replace(\"], [\", \"'],['\").replace(\", \", \"','\")\n",
    "        return ast.literal_eval(s2)\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    \"\"\"Flatten nested list into single list of strings.\"\"\"\n",
    "    out = []\n",
    "    for seg in list_of_lists:\n",
    "        out.extend(seg)\n",
    "    return [str(t) for t in out]\n",
    "\n",
    "def extract_priv_features_from_row(row, feat_names):\n",
    "    \"\"\"Pull numeric features from a row into a vector.\"\"\"\n",
    "    vec = []\n",
    "    for k in feat_names:\n",
    "        val = row[k] if (k in row and pd.notna(row[k])) else 0.0\n",
    "        try:\n",
    "            vec.append(float(val))\n",
    "        except Exception:\n",
    "            vec.append(0.0)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56b8eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuffixHMMPrior:\n",
    "    \"\"\"\n",
    "    Forward-backward algorithm over a suffix vocabulary.\n",
    "    Gives boundary probabilities based on how well positions\n",
    "    align with known suffix patterns.\n",
    "    \"\"\"\n",
    "    def __init__(self, suffix_log_probs, max_suffix_len, unk_penalty=-15.0):\n",
    "        self.log_probs = suffix_log_probs\n",
    "        self.max_len = max_suffix_len\n",
    "        self.unk_penalty = unk_penalty\n",
    "        self.LOG_ZERO = -1e9\n",
    "\n",
    "    def _get_log_prob(self, segment):\n",
    "        return self.log_probs.get(segment, self.unk_penalty)\n",
    "\n",
    "    def _forward_pass(self, word):\n",
    "        n = len(word)\n",
    "        alpha = [self.LOG_ZERO] * (n + 1)\n",
    "        alpha[0] = 0.0\n",
    "\n",
    "        for i in range(1, n + 1):\n",
    "            log_sums = []\n",
    "            for j in range(max(0, i - self.max_len), i):\n",
    "                segment = word[j:i]\n",
    "                log_p_segment = self._get_log_prob(segment)\n",
    "                log_sums.append(alpha[j] + log_p_segment)\n",
    "            if log_sums:\n",
    "                alpha[i] = torch.logsumexp(torch.tensor(log_sums), dim=0).item()\n",
    "        return alpha\n",
    "\n",
    "    def _backward_pass(self, word):\n",
    "        n = len(word)\n",
    "        beta = [self.LOG_ZERO] * (n + 1)\n",
    "        beta[n] = 0.0\n",
    "\n",
    "        for i in range(n - 1, -1, -1):\n",
    "            log_sums = []\n",
    "            for j in range(i + 1, min(n + 1, i + self.max_len + 1)):\n",
    "                segment = word[i:j]\n",
    "                log_p_segment = self._get_log_prob(segment)\n",
    "                log_sums.append(beta[j] + log_p_segment)\n",
    "            if log_sums:\n",
    "                beta[i] = torch.logsumexp(torch.tensor(log_sums), dim=0).item()\n",
    "        return beta\n",
    "\n",
    "    def get_boundary_priors(self, word):\n",
    "        \"\"\"Compute P(boundary at position i | word) for each position.\"\"\"\n",
    "        n = len(word)\n",
    "        if n <= 1:\n",
    "            return []\n",
    "\n",
    "        alpha = self._forward_pass(word)\n",
    "        beta = self._backward_pass(word)\n",
    "        \n",
    "        log_total_prob = alpha[n]\n",
    "        if log_total_prob == self.LOG_ZERO:\n",
    "            return [0.0] * (n - 1)\n",
    "\n",
    "        log_priors = []\n",
    "        for i in range(1, n):\n",
    "            log_p_boundary = alpha[i] + beta[i]\n",
    "            log_priors.append(log_p_boundary)\n",
    "        \n",
    "        log_priors_tensor = torch.tensor(log_priors)\n",
    "        normalized_log_priors = log_priors_tensor - log_total_prob\n",
    "        return torch.exp(normalized_log_priors).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cd57800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hmm_prior(samples):\n",
    "    \"\"\"Learn suffix probabilities from training segmentations.\"\"\"\n",
    "    suffix_counts = Counter()\n",
    "    max_suffix_len = 0\n",
    "    \n",
    "    for s in samples:\n",
    "        cs = s[\"tokens\"]\n",
    "        morph_lens = [len(seg) for seg in safe_list(s['y_morphs'])]\n",
    "        \n",
    "        current_idx = len(cs)\n",
    "        for morph_len in reversed(morph_lens[1:]):\n",
    "            start_idx = current_idx - morph_len\n",
    "            suffix_tokens = cs[start_idx:current_idx]\n",
    "            suffix_str = \"\".join(suffix_tokens)\n",
    "            suffix_counts[suffix_str] += 1\n",
    "            max_suffix_len = max(max_suffix_len, len(suffix_str))\n",
    "            current_idx = start_idx\n",
    "\n",
    "    total_suffix_obs = sum(suffix_counts.values())\n",
    "    \n",
    "    log_probs = {\n",
    "        suffix: math.log((count + 1) / (total_suffix_obs + len(suffix_counts)))\n",
    "        for suffix, count in suffix_counts.items()\n",
    "    }\n",
    "\n",
    "    avg_log_prob = sum(log_probs.values()) / len(log_probs) if log_probs else 0\n",
    "    unk_penalty = avg_log_prob * 1.5\n",
    "\n",
    "    print(f\"HMM: {len(log_probs)} suffixes, max len {max_suffix_len}, unk penalty {unk_penalty:.2f}\")\n",
    "    return SuffixHMMPrior(log_probs, max_suffix_len, unk_penalty=unk_penalty)\n",
    "\n",
    "def create_hmm_prior_from_list(allowed_suffixes: list, unk_penalty: float = -15.0):\n",
    "    \"\"\"Build HMM prior from a predefined suffix list instead of learning.\"\"\"\n",
    "    if not allowed_suffixes:\n",
    "        raise ValueError(\"suffix list can't be empty\")\n",
    "\n",
    "    suffix_log_probs = {suffix: 0.0 for suffix in allowed_suffixes}\n",
    "    max_suffix_len = len(max(allowed_suffixes, key=len))\n",
    "\n",
    "    print(f\"HMM: initialized with {len(allowed_suffixes)} suffixes, max len {max_suffix_len}\")\n",
    "    return SuffixHMMPrior(suffix_log_probs, max_suffix_len, unk_penalty=unk_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bfadc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_samples_with_priv(df, feat_names=NEW_NUM_FEATS):\n",
    "    \"\"\"Convert dataframe rows to sample dicts for training.\"\"\"\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        cs = safe_list(r[\"Char_split\"])\n",
    "        toks = flatten(cs)\n",
    "        lens = [len(seg) for seg in cs]\n",
    "        cut_idxs = set(np.cumsum(lens)[:-1].tolist())\n",
    "        y = [1 if (i + 1) in cut_idxs else 0 for i in range(len(toks) - 1)]\n",
    "        priv = extract_priv_features_from_row(r, feat_names)\n",
    "        gold_morphs = [\"\".join(seg) for seg in cs]\n",
    "        rows.append({\"tokens\": toks, \"y\": y, \"priv\": priv, \"y_morphs\": gold_morphs})\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d00345c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_window(tokens, i, k_left=2, k_right=2):\n",
    "    \"\"\"Extract local context features around position i.\"\"\"\n",
    "    feats = {}\n",
    "    for k in range(1, k_left + 1):\n",
    "        idx = i - (k - 1)\n",
    "        feats[f\"L{k}\"] = tokens[idx] if idx >= 0 else \"<BOS>\"\n",
    "    for k in range(1, k_right + 1):\n",
    "        idx = i + k\n",
    "        feats[f\"R{k}\"] = tokens[idx] if idx < len(tokens) else \"<EOS>\"\n",
    "    \n",
    "    def is_vowel(ch):\n",
    "        return ch.lower() in \"aeiouáéíóú\"\n",
    "    \n",
    "    L1 = feats[\"L1\"]\n",
    "    R1 = feats[\"R1\"]\n",
    "    feats[\"L1_cv\"] = 'V' if is_vowel(L1[-1]) else 'C'\n",
    "    feats[\"R1_cv\"] = 'V' if (R1 != \"<EOS>\" and is_vowel(R1[0])) else 'C'\n",
    "    feats[\"L1_last\"] = L1[-1]\n",
    "    feats[\"R1_first\"] = R1[0] if R1 != \"<EOS>\" else \"<EOS>\"\n",
    "    return feats\n",
    "\n",
    "def prior_probs_for_sample(hmm_prior, tokens):\n",
    "    \"\"\"Get HMM boundary priors mapped to token positions.\"\"\"\n",
    "    if hmm_prior is None or len(tokens) <= 1:\n",
    "        return [0.5] * (max(len(tokens) - 1, 0))\n",
    "\n",
    "    word = \"\".join(tokens)\n",
    "    char_priors = hmm_prior.get_boundary_priors(word)\n",
    "\n",
    "    # Map character-level to token-level\n",
    "    token_boundary_indices = np.cumsum([len(t) for t in tokens[:-1]]) - 1\n",
    "    \n",
    "    token_priors = []\n",
    "    for idx in token_boundary_indices:\n",
    "        if 0 <= idx < len(char_priors):\n",
    "            token_priors.append(char_priors[idx])\n",
    "        else:\n",
    "            token_priors.append(0.5)\n",
    "\n",
    "    return token_priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "615bd211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_k_teacher_priv(samples, feat_dim):\n",
    "    \"\"\"Train a regressor to predict number of cuts from features.\"\"\"\n",
    "    X = np.array([s[\"priv\"] for s in samples], dtype=float)\n",
    "    y = np.array([int(np.sum(s[\"y\"])) for s in samples], dtype=float)\n",
    "    reg = DecisionTreeRegressor(max_depth=6, min_samples_leaf=10, random_state=RNG)\n",
    "    reg.fit(X, y)\n",
    "    return reg\n",
    "\n",
    "def predict_k_hat_priv(reg, priv_batch):\n",
    "    \"\"\"Predict expected number of cuts for a batch.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        k = reg.predict(priv_batch.cpu().numpy())\n",
    "    return torch.tensor(k, dtype=torch.float32, device=priv_batch.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "211565fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(samples, min_freq=1):\n",
    "    \"\"\"Build token vocabulary from samples.\"\"\"\n",
    "    ctr = Counter()\n",
    "    for s in samples:\n",
    "        ctr.update(s[\"tokens\"])\n",
    "    vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "    for t, c in sorted(ctr.items(), key=lambda x: (-x[1], x[0])):\n",
    "        if c >= min_freq and t not in vocab:\n",
    "            vocab[t] = len(vocab)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1c1a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegDataset(Dataset):\n",
    "    \"\"\"Dataset for boundary prediction training.\"\"\"\n",
    "    def __init__(self, samples, vocab, hmm_prior=None, feat_dim=0):\n",
    "        self.samples = samples\n",
    "        self.vocab = vocab\n",
    "        self.hmm_prior = hmm_prior\n",
    "        self.feat_dim = feat_dim\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        s = self.samples[idx]\n",
    "        tokens = s[\"tokens\"]\n",
    "        ids = [self.vocab.get(t, self.vocab[\"<UNK>\"]) for t in tokens]\n",
    "        y = s[\"y\"]\n",
    "        prior = prior_probs_for_sample(self.hmm_prior, tokens)\n",
    "        priv = s[\"priv\"] if self.feat_dim > 0 else []\n",
    "        return {\"ids\": ids, \"y\": y, \"prior\": prior, \"priv\": priv, \"tokens\": tokens}\n",
    "\n",
    "def collate(batch):\n",
    "    \"\"\"Collate samples into batched tensors.\"\"\"\n",
    "    maxT = max(len(b[\"ids\"]) for b in batch)\n",
    "    maxB = maxT - 1\n",
    "    B = len(batch)\n",
    "\n",
    "    ids = torch.full((B, maxT), 0, dtype=torch.long)\n",
    "    mask_tok = torch.zeros((B, maxT), dtype=torch.bool)\n",
    "    y = torch.full((B, maxB), -100, dtype=torch.long)\n",
    "    prior = torch.zeros((B, maxB), dtype=torch.float32)\n",
    "    mask_b = torch.zeros((B, maxB), dtype=torch.bool)\n",
    "\n",
    "    feat_dim = len(batch[0][\"priv\"]) if isinstance(batch[0][\"priv\"], list) else 0\n",
    "    priv = torch.zeros((B, feat_dim), dtype=torch.float32) if feat_dim > 0 else None\n",
    "\n",
    "    for i, b in enumerate(batch):\n",
    "        T = len(b[\"ids\"])\n",
    "        ids[i, :T] = torch.tensor(b[\"ids\"], dtype=torch.long)\n",
    "        mask_tok[i, :T] = True\n",
    "        if T > 1:\n",
    "            L = T - 1\n",
    "            y[i, :L] = torch.tensor(b[\"y\"], dtype=torch.long)\n",
    "            p = b[\"prior\"] if len(b[\"prior\"]) == L else [0.5] * L\n",
    "            prior[i, :L] = torch.tensor(p, dtype=torch.float32)\n",
    "            mask_b[i, :L] = True\n",
    "        if feat_dim > 0:\n",
    "            priv[i] = torch.tensor(b[\"priv\"], dtype=torch.float32)\n",
    "\n",
    "    return {\n",
    "        \"ids\": ids, \"mask_tok\": mask_tok,\n",
    "        \"y\": y, \"prior\": prior, \"mask_b\": mask_b,\n",
    "        \"priv\": priv\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a670e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMTagger(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional LSTM for boundary prediction.\n",
    "    Can fuse HMM prior via concatenation or logit addition.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, emb_dim=16, hidden_size=64, num_layers=2,\n",
    "                 use_prior=True, dropout=0.1, freeze_emb=False, fuse_mode=\"logit_add\"):\n",
    "        super().__init__()\n",
    "        self.use_prior = use_prior\n",
    "        self.fuse_mode = fuse_mode\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        if freeze_emb:\n",
    "            for p in self.emb.parameters():\n",
    "                p.requires_grad = False\n",
    "        lstm_dropout = dropout if num_layers > 1 else 0.0\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_dim, hidden_size=hidden_size // 2,\n",
    "            num_layers=num_layers, dropout=lstm_dropout,\n",
    "            bidirectional=True, batch_first=True\n",
    "        )\n",
    "        in_mlp = hidden_size + (1 if (use_prior and fuse_mode == \"concat\") else 0)\n",
    "        self.boundary_mlp = nn.Sequential(\n",
    "            nn.Linear(in_mlp, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size // 2, 2)\n",
    "        )\n",
    "        if use_prior and fuse_mode == \"logit_add\":\n",
    "            self.alpha = nn.Parameter(torch.tensor(1.0))\n",
    "\n",
    "    def forward(self, ids, prior, mask_tok):\n",
    "        emb = self.emb(ids)\n",
    "        h, _ = self.lstm(emb)\n",
    "        left = h[:, :-1, :]\n",
    "        if self.use_prior and self.fuse_mode == \"concat\":\n",
    "            feat = torch.cat([left, prior.unsqueeze(-1)], dim=-1)\n",
    "            return self.boundary_mlp(feat)\n",
    "        logits = self.boundary_mlp(left)\n",
    "        if self.use_prior and self.fuse_mode == \"logit_add\":\n",
    "            eps = 1e-6\n",
    "            p = prior.clamp(eps, 1 - eps)\n",
    "            prior_logit = torch.log(p) - torch.log(1 - p)\n",
    "            logits[..., 1] = logits[..., 1] + self.alpha * prior_logit\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5303aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_metrics_from_lists(probs_list, gold_list, thr=0.5):\n",
    "    \"\"\"Compute precision/recall/F1 for boundary prediction.\"\"\"\n",
    "    if not probs_list:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    p = torch.cat([t for t in probs_list if t.numel() > 0], dim=0).numpy()\n",
    "    g = torch.cat([t for t in gold_list if t.numel() > 0], dim=0).numpy()\n",
    "    pred = (p >= thr).astype(int)\n",
    "    P, R, F1, _ = precision_recall_fscore_support(g, pred, average='binary', zero_division=0)\n",
    "    return P, R, F1\n",
    "\n",
    "def exact_match_rate_from_lists(probs_list, gold_list, thr=0.5):\n",
    "    \"\"\"Fraction of words with perfectly predicted boundaries.\"\"\"\n",
    "    if not probs_list:\n",
    "        return 0.0\n",
    "    em = []\n",
    "    for p, g in zip(probs_list, gold_list):\n",
    "        if g.numel() == 0:\n",
    "            em.append(1.0)\n",
    "        else:\n",
    "            pred = (p.numpy() >= thr).astype(int)\n",
    "            em.append(float(np.array_equal(pred, g.numpy())))\n",
    "    return float(np.mean(em))\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, loader):\n",
    "    \"\"\"Run model on loader, return probability and gold lists.\"\"\"\n",
    "    model.eval()\n",
    "    probs_list, gold_list = [], []\n",
    "    for batch in loader:\n",
    "        logits = model(batch[\"ids\"], batch[\"prior\"], batch[\"mask_tok\"])\n",
    "        probs = torch.softmax(logits, dim=-1)[..., 1]\n",
    "        y = batch[\"y\"]\n",
    "        mask = batch[\"mask_b\"]\n",
    "        B = probs.shape[0]\n",
    "        for b in range(B):\n",
    "            L = int(mask[b].sum().item())\n",
    "            if L == 0:\n",
    "                probs_list.append(torch.empty(0))\n",
    "                gold_list.append(torch.empty(0, dtype=torch.long))\n",
    "            else:\n",
    "                probs_list.append(probs[b, :L].cpu())\n",
    "                gold_list.append(y[b, :L].cpu())\n",
    "    return probs_list, gold_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e80b3015",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "criterion_bce = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "mse = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "def train_epoch(model, loader, opt, lambda_prior=0.1, lambda_k=0.1, k_reg=None):\n",
    "    \"\"\"One training epoch with optional prior distillation and K regularization.\"\"\"\n",
    "    model.train()\n",
    "    tot = 0\n",
    "    n = 0\n",
    "    for batch in loader:\n",
    "        ids, prior, y, mask_b = batch[\"ids\"], batch[\"prior\"], batch[\"y\"], batch[\"mask_b\"]\n",
    "        priv = batch[\"priv\"]\n",
    "\n",
    "        logits = model(ids, prior, batch[\"mask_tok\"])\n",
    "        logits_flat = logits[mask_b]\n",
    "        y_true = y[mask_b]\n",
    "\n",
    "        # Main CE loss\n",
    "        loss = criterion_ce(logits_flat, y_true)\n",
    "\n",
    "        # Prior distillation\n",
    "        if lambda_prior > 0:\n",
    "            cut_logit = logits[..., 1]\n",
    "            prior_flat = prior[mask_b]\n",
    "            loss_pr = criterion_bce(cut_logit[mask_b], prior_flat)\n",
    "            loss = loss + lambda_prior * loss_pr\n",
    "\n",
    "        # K regularization\n",
    "        if (lambda_k > 0) and (k_reg is not None) and (priv is not None):\n",
    "            with torch.no_grad():\n",
    "                k_hat = predict_k_hat_priv(k_reg, priv)\n",
    "            cut_logit = logits[..., 1]\n",
    "            p_cut = torch.sigmoid(cut_logit)\n",
    "            exp_K = p_cut.sum(dim=1)\n",
    "            loss_k = mse(exp_K, k_hat)\n",
    "            loss = loss + lambda_k * loss_k\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        tot += loss.item()\n",
    "        n += 1\n",
    "    return tot / max(n, 1)\n",
    "\n",
    "def split_train_test(samples, test_ratio=0.2):\n",
    "    \"\"\"Random train/test split.\"\"\"\n",
    "    n = len(samples)\n",
    "    idx = np.arange(n)\n",
    "    np.random.shuffle(idx)\n",
    "    cut = int(n * (1 - test_ratio))\n",
    "    tr = [samples[i] for i in idx[:cut]]\n",
    "    te = [samples[i] for i in idx[cut:]]\n",
    "    return tr, te\n",
    "\n",
    "def best_threshold_for_exact(probs_list, gold_list, grid=None):\n",
    "    \"\"\"Find threshold that maximizes exact match rate.\"\"\"\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.3, 0.9, 61)\n",
    "    best_thr, best_em, best_f1 = 0.5, -1.0, 0.0\n",
    "    p_all = np.concatenate([t.numpy() for t in probs_list if t.numel() > 0], axis=0)\n",
    "    g_all = np.concatenate([t.numpy() for t in gold_list if t.numel() > 0], axis=0)\n",
    "    for thr in grid:\n",
    "        ems = []\n",
    "        for p, g in zip(probs_list, gold_list):\n",
    "            if g.numel() == 0:\n",
    "                ems.append(1.0)\n",
    "                continue\n",
    "            ems.append(float(np.array_equal((p.numpy() >= thr).astype(int), g.numpy())))\n",
    "        em = float(np.mean(ems))\n",
    "        pred_all = (p_all >= thr).astype(int)\n",
    "        P, R, F1, _ = precision_recall_fscore_support(g_all, pred_all, average='binary', zero_division=0)\n",
    "        if em > best_em or (np.isclose(em, best_em) and F1 > best_f1):\n",
    "            best_thr, best_em, best_f1 = thr, em, F1\n",
    "    print(f\"best threshold: {best_thr:.3f} | exact={best_em:.3f} | F1={best_f1:.3f}\")\n",
    "    return best_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19fac30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_id(df, provided_suffix_list, use_suffix_list, unk_penalty, epochs,\n",
    "                      use_prior, fuse_mode, lambda_prior, lambda_k, batch_size, hparams, synthetic_choice,\n",
    "                      augmentation_word_selection=None, augmentation_n_words=None):\n",
    "    \"\"\"Hash training params to get unique model ID.\"\"\"\n",
    "    if augmentation_word_selection is None:\n",
    "        augmentation_word_selection = globals().get('AUGMENTATION_WORD_SELECTION', 'all')\n",
    "    if augmentation_n_words is None:\n",
    "        augmentation_n_words = globals().get('AUGMENTATION_N_WORDS', None)\n",
    "    \n",
    "    params_dict = {\n",
    "        'synthetic_choice': synthetic_choice,\n",
    "        'use_suffix_list': use_suffix_list,\n",
    "        'unk_penalty': unk_penalty,\n",
    "        'epochs': epochs,\n",
    "        'use_prior': use_prior,\n",
    "        'fuse_mode': fuse_mode,\n",
    "        'lambda_prior': lambda_prior,\n",
    "        'lambda_k': lambda_k,\n",
    "        'batch_size': batch_size,\n",
    "        'hparams': hparams,\n",
    "        'suffix_list_len': len(provided_suffix_list) if provided_suffix_list else 0,\n",
    "        'df_shape': df.shape if df is not None else (0, 0),\n",
    "        'augmentation_word_selection': augmentation_word_selection,\n",
    "        'augmentation_n_words': augmentation_n_words\n",
    "    }\n",
    "    params_str = json.dumps(params_dict, sort_keys=True)\n",
    "    model_id = hashlib.md5(params_str.encode()).hexdigest()[:16]\n",
    "    return model_id\n",
    "\n",
    "def save_model(model, vocab, out, model_id, models_folder=MODELS_FOLDER,\n",
    "               synthetic_choice=None, augmentation_word_selection=None, augmentation_n_words=None):\n",
    "    \"\"\"Save model weights and artifacts.\"\"\"\n",
    "    model_dir = os.path.join(models_folder, model_id)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join(model_dir, \"model.pt\"))\n",
    "    \n",
    "    with open(os.path.join(model_dir, \"vocab.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(vocab, f)\n",
    "    \n",
    "    with open(os.path.join(model_dir, \"artifacts.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(out, f)\n",
    "    \n",
    "    if synthetic_choice is None:\n",
    "        synthetic_choice = globals().get('SYNTHETIC_DATA_CHOICE', 'none')\n",
    "    if augmentation_word_selection is None:\n",
    "        augmentation_word_selection = globals().get('AUGMENTATION_WORD_SELECTION', 'all')\n",
    "    if augmentation_n_words is None:\n",
    "        augmentation_n_words = globals().get('AUGMENTATION_N_WORDS', None)\n",
    "    \n",
    "    metadata = {\n",
    "        'model_id': model_id,\n",
    "        'vocab_size': len(vocab),\n",
    "        'synthetic_choice': synthetic_choice,\n",
    "        'augmentation_word_selection': augmentation_word_selection,\n",
    "    }\n",
    "    if augmentation_n_words is not None:\n",
    "        metadata['augmentation_n_words'] = augmentation_n_words\n",
    "    with open(os.path.join(model_dir, \"metadata.json\"), \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"saved model to {model_dir}\")\n",
    "    return model_dir\n",
    "\n",
    "def load_model(model_id, models_folder=MODELS_FOLDER, vocab_size=None):\n",
    "    \"\"\"Load saved model artifacts.\"\"\"\n",
    "    model_dir = os.path.join(models_folder, model_id)\n",
    "    if not os.path.exists(model_dir):\n",
    "        return None\n",
    "    \n",
    "    vocab_path = os.path.join(model_dir, \"vocab.pkl\")\n",
    "    if not os.path.exists(vocab_path):\n",
    "        return None\n",
    "    with open(vocab_path, \"rb\") as f:\n",
    "        vocab = pickle.load(f)\n",
    "    \n",
    "    artifacts_path = os.path.join(model_dir, \"artifacts.pkl\")\n",
    "    if not os.path.exists(artifacts_path):\n",
    "        return None\n",
    "    with open(artifacts_path, \"rb\") as f:\n",
    "        out = pickle.load(f)\n",
    "    \n",
    "    model_path = os.path.join(model_dir, \"model.pt\")\n",
    "    if not os.path.exists(model_path):\n",
    "        return None\n",
    "    \n",
    "    print(f\"loaded artifacts from {model_dir}\")\n",
    "    return {\n",
    "        'vocab': vocab,\n",
    "        'out': out,\n",
    "        'model_state_path': model_path,\n",
    "        'model_dir': model_dir\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32f7ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_segmentation_with_privK(\n",
    "    df,\n",
    "    provided_suffix_list,\n",
    "    use_suffix_list=True,\n",
    "    unk_penalty=-15.0,\n",
    "    epochs=15,\n",
    "    use_prior=True,\n",
    "    fuse_mode=\"logit_add\",\n",
    "    lambda_prior=0.1,\n",
    "    lambda_k=0.2,\n",
    "    batch_size=64,\n",
    "    hparams=None,\n",
    "    synthetic_choice=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Train or load a segmentation model. Checks for existing checkpoints first.\n",
    "    \"\"\"\n",
    "    if hparams is None:\n",
    "        hparams = dict(emb_dim=16, hidden_size=64, num_layers=2,\n",
    "                       dropout=0.25, lr=1e-3, weight_decay=1e-4, freeze_emb=False)\n",
    "    \n",
    "    if synthetic_choice is None:\n",
    "        synthetic_choice = SYNTHETIC_DATA_CHOICE if 'SYNTHETIC_DATA_CHOICE' in globals() else \"none\"\n",
    "    \n",
    "    augmentation_word_selection = globals().get('AUGMENTATION_WORD_SELECTION', 'all')\n",
    "    augmentation_n_words = globals().get('AUGMENTATION_N_WORDS', None)\n",
    "    \n",
    "    model_id = generate_model_id(\n",
    "        df, provided_suffix_list, use_suffix_list, unk_penalty, epochs,\n",
    "        use_prior, fuse_mode, lambda_prior, lambda_k, batch_size, hparams, synthetic_choice,\n",
    "        augmentation_word_selection=augmentation_word_selection,\n",
    "        augmentation_n_words=augmentation_n_words\n",
    "    )\n",
    "    \n",
    "    print(f\"looking for model {model_id}...\")\n",
    "    loaded = load_model(model_id, models_folder=MODELS_FOLDER)\n",
    "    \n",
    "    if loaded is not None:\n",
    "        print(f\"found it! loading from {loaded['model_dir']}\")\n",
    "        vocab = loaded['vocab']\n",
    "        out = loaded['out']\n",
    "        model_state_path = loaded['model_state_path']\n",
    "        \n",
    "        model = BiLSTMTagger(\n",
    "            vocab_size=len(vocab),\n",
    "            emb_dim=hparams.get(\"emb_dim\", 16),\n",
    "            hidden_size=hparams.get(\"hidden_size\", 64),\n",
    "            num_layers=hparams.get(\"num_layers\", 2),\n",
    "            use_prior=(use_prior and fuse_mode != \"none\"),\n",
    "            dropout=hparams.get(\"dropout\", 0.25),\n",
    "            freeze_emb=hparams.get(\"freeze_emb\", False),\n",
    "            fuse_mode=fuse_mode\n",
    "        )\n",
    "        model.load_state_dict(torch.load(model_state_path))\n",
    "        model.eval()\n",
    "        print(\"skipping training, model ready\")\n",
    "        return model, vocab, out\n",
    "    \n",
    "    print(f\"no checkpoint found, training from scratch...\")\n",
    "    \n",
    "    samples = build_samples_with_priv(df, feat_names=NEW_NUM_FEATS)\n",
    "    train_s, test_s = split_train_test(samples, 0.2)\n",
    "\n",
    "    hmm_prior = None\n",
    "    if use_prior and use_suffix_list:\n",
    "        hmm_prior = create_hmm_prior_from_list(provided_suffix_list, unk_penalty)\n",
    "    if use_prior and not use_suffix_list:\n",
    "        hmm_prior = train_hmm_prior(train_s)\n",
    "\n",
    "    feat_dim = len(NEW_NUM_FEATS)\n",
    "    k_reg = train_k_teacher_priv(train_s, feat_dim=feat_dim)\n",
    "\n",
    "    vocab = build_vocab(train_s, min_freq=1)\n",
    "\n",
    "    train_ds = SegDataset(train_s, vocab, hmm_prior=hmm_prior, feat_dim=feat_dim)\n",
    "    test_ds = SegDataset(test_s, vocab, hmm_prior=hmm_prior, feat_dim=feat_dim)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, collate_fn=collate)\n",
    "\n",
    "    model = BiLSTMTagger(\n",
    "        vocab_size=len(vocab),\n",
    "        emb_dim=hparams.get(\"emb_dim\", 16),\n",
    "        hidden_size=hparams.get(\"hidden_size\", 64),\n",
    "        num_layers=hparams.get(\"num_layers\", 2),\n",
    "        use_prior=(use_prior and fuse_mode != \"none\"),\n",
    "        dropout=hparams.get(\"dropout\", 0.25),\n",
    "        freeze_emb=hparams.get(\"freeze_emb\", False),\n",
    "        fuse_mode=fuse_mode\n",
    "    )\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=hparams.get(\"lr\", 1e-3), \n",
    "                            weight_decay=hparams.get(\"weight_decay\", 1e-4))\n",
    "\n",
    "    final_probs_list, final_gold_list = None, None\n",
    "    for ep in range(1, epochs + 1):\n",
    "        loss = train_epoch(model, train_loader, opt, lambda_prior=lambda_prior, lambda_k=lambda_k, k_reg=k_reg)\n",
    "        probs_list, gold_list = predict(model, test_loader)\n",
    "        P, R, F1 = boundary_metrics_from_lists(probs_list, gold_list, thr=0.5)\n",
    "        EM = exact_match_rate_from_lists(probs_list, gold_list, thr=0.5)\n",
    "        print(f\"epoch {ep:02d} | loss={loss:.4f} | P/R/F1={P:.3f}/{R:.3f}/{F1:.3f} | exact={EM:.3f}\")\n",
    "        final_probs_list, final_gold_list = probs_list, gold_list\n",
    "\n",
    "    best_thr = best_threshold_for_exact(final_probs_list, final_gold_list)\n",
    "\n",
    "    out = {\n",
    "        \"probs_list\": final_probs_list,\n",
    "        \"gold_list\": final_gold_list,\n",
    "        \"hmm_prior\": hmm_prior,\n",
    "        \"k_teacher\": k_reg,\n",
    "        \"best_thr\": best_thr\n",
    "    }\n",
    "    \n",
    "    print(f\"saving model {model_id}...\")\n",
    "    save_model(model, vocab, out, model_id, models_folder=MODELS_FOLDER,\n",
    "               synthetic_choice=synthetic_choice,\n",
    "               augmentation_word_selection=augmentation_word_selection,\n",
    "               augmentation_n_words=augmentation_n_words)\n",
    "\n",
    "    return model, vocab, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e46c9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_cross_validation(\n",
    "    df,\n",
    "    provided_suffix_list,\n",
    "    n_folds=5,\n",
    "    use_suffix_list=True,\n",
    "    unk_penalty=-15.0,\n",
    "    epochs=15,\n",
    "    use_prior=True,\n",
    "    fuse_mode=\"logit_add\",\n",
    "    lambda_prior=0.1,\n",
    "    lambda_k=0.2,\n",
    "    batch_size=64,\n",
    "    hparams=None,\n",
    "    synthetic_choice=None,\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"K-fold cross-validation for more robust evaluation.\"\"\"\n",
    "    if hparams is None:\n",
    "        hparams = dict(emb_dim=16, hidden_size=64, num_layers=2,\n",
    "                       dropout=0.25, lr=1e-3, weight_decay=1e-4, freeze_emb=False)\n",
    "    \n",
    "    if synthetic_choice is None:\n",
    "        synthetic_choice = SYNTHETIC_DATA_CHOICE if 'SYNTHETIC_DATA_CHOICE' in globals() else \"none\"\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"K-FOLD CV (k={n_folds})\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "    samples = build_samples_with_priv(df, feat_names=NEW_NUM_FEATS)\n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    fold_results = []\n",
    "    all_metrics = {\n",
    "        'boundary_precision': [],\n",
    "        'boundary_recall': [],\n",
    "        'boundary_f1': [],\n",
    "        'exact_match': [],\n",
    "        'best_threshold': []\n",
    "    }\n",
    "    \n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(kfold.split(samples), 1):\n",
    "        print(f\"\\n--- fold {fold_idx}/{n_folds} ---\")\n",
    "        print(f\"train: {len(train_indices)}, val: {len(val_indices)}\")\n",
    "        \n",
    "        train_samples = [samples[i] for i in train_indices]\n",
    "        val_samples = [samples[i] for i in val_indices]\n",
    "        \n",
    "        hmm_prior = None\n",
    "        if use_prior and use_suffix_list:\n",
    "            hmm_prior = create_hmm_prior_from_list(provided_suffix_list, unk_penalty)\n",
    "        elif use_prior and not use_suffix_list:\n",
    "            hmm_prior = train_hmm_prior(train_samples)\n",
    "        \n",
    "        feat_dim = len(NEW_NUM_FEATS)\n",
    "        k_reg = train_k_teacher_priv(train_samples, feat_dim=feat_dim)\n",
    "        vocab = build_vocab(train_samples, min_freq=1)\n",
    "        \n",
    "        train_ds = SegDataset(train_samples, vocab, hmm_prior=hmm_prior, feat_dim=feat_dim)\n",
    "        val_ds = SegDataset(val_samples, vocab, hmm_prior=hmm_prior, feat_dim=feat_dim)\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, collate_fn=collate)\n",
    "        \n",
    "        model = BiLSTMTagger(\n",
    "            vocab_size=len(vocab),\n",
    "            emb_dim=hparams.get(\"emb_dim\", 16),\n",
    "            hidden_size=hparams.get(\"hidden_size\", 64),\n",
    "            num_layers=hparams.get(\"num_layers\", 2),\n",
    "            use_prior=(use_prior and fuse_mode != \"none\"),\n",
    "            dropout=hparams.get(\"dropout\", 0.25),\n",
    "            freeze_emb=hparams.get(\"freeze_emb\", False),\n",
    "            fuse_mode=fuse_mode\n",
    "        )\n",
    "        \n",
    "        opt = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=hparams.get(\"lr\", 1e-3),\n",
    "            weight_decay=hparams.get(\"weight_decay\", 1e-4)\n",
    "        )\n",
    "        \n",
    "        best_val_em = -1.0\n",
    "        best_val_f1 = -1.0\n",
    "        best_epoch = 0\n",
    "        \n",
    "        for ep in range(1, epochs + 1):\n",
    "            loss = train_epoch(model, train_loader, opt, lambda_prior=lambda_prior, lambda_k=lambda_k, k_reg=k_reg)\n",
    "            probs_list, gold_list = predict(model, val_loader)\n",
    "            P, R, F1 = boundary_metrics_from_lists(probs_list, gold_list, thr=0.5)\n",
    "            EM = exact_match_rate_from_lists(probs_list, gold_list, thr=0.5)\n",
    "            \n",
    "            print(f\"  ep {ep:02d} | loss={loss:.4f} | P/R/F1={P:.3f}/{R:.3f}/{F1:.3f} | exact={EM:.3f}\")\n",
    "            \n",
    "            if EM > best_val_em or (np.isclose(EM, best_val_em) and F1 > best_val_f1):\n",
    "                best_val_em = EM\n",
    "                best_val_f1 = F1\n",
    "                best_epoch = ep\n",
    "                best_probs_list = probs_list\n",
    "                best_gold_list = gold_list\n",
    "        \n",
    "        best_thr = best_threshold_for_exact(best_probs_list, best_gold_list)\n",
    "        P_final, R_final, F1_final = boundary_metrics_from_lists(best_probs_list, best_gold_list, thr=best_thr)\n",
    "        EM_final = exact_match_rate_from_lists(best_probs_list, best_gold_list, thr=best_thr)\n",
    "        \n",
    "        print(f\"  best epoch: {best_epoch}\")\n",
    "        print(f\"  final (thr={best_thr:.3f}): P/R/F1={P_final:.3f}/{R_final:.3f}/{F1_final:.3f} | exact={EM_final:.3f}\")\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold_idx,\n",
    "            'boundary_precision': P_final,\n",
    "            'boundary_recall': R_final,\n",
    "            'boundary_f1': F1_final,\n",
    "            'exact_match': EM_final,\n",
    "            'best_threshold': best_thr,\n",
    "            'best_epoch': best_epoch\n",
    "        })\n",
    "        \n",
    "        all_metrics['boundary_precision'].append(P_final)\n",
    "        all_metrics['boundary_recall'].append(R_final)\n",
    "        all_metrics['boundary_f1'].append(F1_final)\n",
    "        all_metrics['exact_match'].append(EM_final)\n",
    "        all_metrics['best_threshold'].append(best_thr)\n",
    "    \n",
    "    mean_metrics = {k: np.mean(v) for k, v in all_metrics.items()}\n",
    "    std_metrics = {k: np.std(v) for k, v in all_metrics.items()}\n",
    "    best_fold_idx = max(range(len(fold_results)), key=lambda i: fold_results[i]['exact_match'])\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"CV SUMMARY\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    for r in fold_results:\n",
    "        print(f\"  fold {r['fold']}: P={r['boundary_precision']:.3f}, R={r['boundary_recall']:.3f}, \"\n",
    "              f\"F1={r['boundary_f1']:.3f}, EM={r['exact_match']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nmean +/- std over {n_folds} folds:\")\n",
    "    print(f\"  precision: {mean_metrics['boundary_precision']:.3f} +/- {std_metrics['boundary_precision']:.3f}\")\n",
    "    print(f\"  recall:    {mean_metrics['boundary_recall']:.3f} +/- {std_metrics['boundary_recall']:.3f}\")\n",
    "    print(f\"  F1:        {mean_metrics['boundary_f1']:.3f} +/- {std_metrics['boundary_f1']:.3f}\")\n",
    "    print(f\"  exact:     {mean_metrics['exact_match']:.3f} +/- {std_metrics['exact_match']:.3f}\")\n",
    "    print(f\"  threshold: {mean_metrics['best_threshold']:.3f} +/- {std_metrics['best_threshold']:.3f}\")\n",
    "    print(f\"\\nbest fold: {fold_results[best_fold_idx]['fold']} (exact={fold_results[best_fold_idx]['exact_match']:.3f})\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'fold_results': fold_results,\n",
    "        'mean_metrics': mean_metrics,\n",
    "        'std_metrics': std_metrics,\n",
    "        'best_fold_idx': best_fold_idx,\n",
    "        'all_metrics': all_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2de55644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_vocab(word: str, vocab: dict, max_token_len: int = 4):\n",
    "    \"\"\"Greedy left-to-right tokenization using vocab.\"\"\"\n",
    "    i, toks = 0, []\n",
    "    while i < len(word):\n",
    "        matched = None\n",
    "        Lmax = min(max_token_len, len(word) - i)\n",
    "        for L in range(Lmax, 0, -1):\n",
    "            seg = word[i:i + L]\n",
    "            if seg in vocab:\n",
    "                matched = seg\n",
    "                break\n",
    "        toks.append(matched if matched else word[i])\n",
    "        i += len(toks[-1])\n",
    "    return toks\n",
    "\n",
    "@torch.no_grad()\n",
    "def segment_tokens(model, vocab, tokens, hmm_prior=None, thr=0.5):\n",
    "    \"\"\"Segment a tokenized word and return the segmented string + probabilities.\"\"\"\n",
    "    ids = torch.tensor([[vocab.get(t, vocab[\"<UNK>\"]) for t in tokens]], dtype=torch.long)\n",
    "    mask_tok = torch.ones_like(ids, dtype=torch.bool)\n",
    "    T = len(tokens)\n",
    "    if T <= 1:\n",
    "        return \"\".join(tokens), np.array([])\n",
    "    \n",
    "    prior_list = prior_probs_for_sample(hmm_prior, tokens)\n",
    "    prior = torch.tensor([prior_list], dtype=torch.float32)\n",
    "    logits = model(ids, prior, mask_tok)\n",
    "    probs = torch.softmax(logits, dim=-1)[0, :, 1].cpu().numpy()\n",
    "    cuts = (probs >= thr).astype(int)\n",
    "    \n",
    "    out = []\n",
    "    for i, tok in enumerate(tokens):\n",
    "        out.append(tok)\n",
    "        if i < T - 1 and cuts[i] == 1:\n",
    "            out.append(\"-\")\n",
    "    return \"\".join(out), probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c89087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offsets_from_morphemes(morphs: List[str]) -> Set[int]:\n",
    "    \"\"\"Character offsets of boundaries between morphemes.\"\"\"\n",
    "    offs = []\n",
    "    s = 0\n",
    "    for i, m in enumerate(morphs):\n",
    "        s += len(m)\n",
    "        if i < len(morphs) - 1:\n",
    "            offs.append(s)\n",
    "    return set(offs)\n",
    "\n",
    "def offsets_from_tokens_and_mask(tokens: List[str], mask01: np.ndarray) -> Set[int]:\n",
    "    \"\"\"Character offsets where model predicted boundaries.\"\"\"\n",
    "    offs = set()\n",
    "    cum = 0\n",
    "    for i, t in enumerate(tokens):\n",
    "        cum += len(t)\n",
    "        if i < len(tokens) - 1 and mask01[i] == 1:\n",
    "            offs.add(cum)\n",
    "    return offs\n",
    "\n",
    "def f1_from_sets(pred: Set[int], gold: Set[int]) -> Tuple[float, float, float, int, int, int]:\n",
    "    \"\"\"P/R/F1 from predicted and gold boundary sets.\"\"\"\n",
    "    tp = len(pred & gold)\n",
    "    fp = len(pred - gold)\n",
    "    fn = len(gold - pred)\n",
    "    P = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    R = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    F1 = 2 * P * R / (P + R) if (P + R) > 0 else 0.0\n",
    "    return P, R, F1, tp, fp, fn\n",
    "\n",
    "def normalize_gold_variants(gold_variants):\n",
    "    \"\"\"Convert gold variants to proper list format.\"\"\"\n",
    "    if gold_variants is None:\n",
    "        return []\n",
    "    if isinstance(gold_variants, np.ndarray):\n",
    "        gold_variants = gold_variants.tolist()\n",
    "    if isinstance(gold_variants, list):\n",
    "        normalized = []\n",
    "        for variant in gold_variants:\n",
    "            if isinstance(variant, np.ndarray):\n",
    "                normalized.append(variant.tolist())\n",
    "            elif isinstance(variant, list):\n",
    "                normalized.append([item.tolist() if isinstance(item, np.ndarray) else item for item in variant])\n",
    "            else:\n",
    "                normalized.append(variant)\n",
    "        return normalized\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58daa711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_gold_df(df, model, vocab, out, max_token_len=4, use_tuned_thr=True, show_sample=5):\n",
    "    \"\"\"Evaluate model on test set with multiple gold variants per word.\"\"\"\n",
    "    hmm_prior = out[\"hmm_prior\"]\n",
    "    thr = float(out.get(\"best_thr\", 0.5)) if use_tuned_thr else 0.5\n",
    "\n",
    "    total_tp = total_fp = total_fn = 0\n",
    "    exact_hits = 0\n",
    "    n_eval = 0\n",
    "    examples = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        word = str(row[\"Word\"])\n",
    "        gold_variants = normalize_gold_variants(row[\"Gold\"])\n",
    "\n",
    "        if not isinstance(gold_variants, list) or len(gold_variants) == 0:\n",
    "            continue\n",
    "\n",
    "        toks = tokenize_with_vocab(word, vocab, max_token_len=max_token_len)\n",
    "        seg_string, probs = segment_tokens(model, vocab, toks, hmm_prior=hmm_prior, thr=thr)\n",
    "        mask01 = (probs >= thr).astype(int)\n",
    "        pred_set = offsets_from_tokens_and_mask(toks, mask01)\n",
    "\n",
    "        gold_sets = [offsets_from_morphemes(gv) for gv in gold_variants]\n",
    "\n",
    "        if any(pred_set == gs for gs in gold_sets):\n",
    "            exact_hits += 1\n",
    "\n",
    "        best = max((f1_from_sets(pred_set, gs) + (gs,) for gs in gold_sets), key=lambda z: z[2])\n",
    "        P, R, F1, tp, fp, fn, best_gs = best\n",
    "\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "        n_eval += 1\n",
    "\n",
    "        if len(examples) < show_sample:\n",
    "            best_morphs = None\n",
    "            for gv in gold_variants:\n",
    "                if offsets_from_morphemes(gv) == best_gs:\n",
    "                    best_morphs = gv\n",
    "                    break\n",
    "            gold_str = \"-\".join(best_morphs) if best_morphs else \"(ambig)\"\n",
    "            examples.append({\n",
    "                \"word\": word, \"tokens\": toks, \"pred_seg\": seg_string,\n",
    "                \"gold_best\": gold_str, \"P\": round(P, 3), \"R\": round(R, 3), \"F1\": round(F1, 3)\n",
    "            })\n",
    "\n",
    "    micro_P = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
    "    micro_R = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
    "    micro_F1 = 2 * micro_P * micro_R / (micro_P + micro_R) if (micro_P + micro_R) > 0 else 0.0\n",
    "    exact_rate = exact_hits / n_eval if n_eval > 0 else 0.0\n",
    "\n",
    "    print(f\"evaluated {n_eval} words\")\n",
    "    print(f\"boundary (micro) P/R/F1 = {micro_P:.3f}/{micro_R:.3f}/{micro_F1:.3f}\")\n",
    "    print(f\"exact match = {exact_rate:.3f}\")\n",
    "    if examples:\n",
    "        print(\"\\nsamples:\")\n",
    "        for ex in examples:\n",
    "            print(f\"- {ex['word']}\")\n",
    "            print(f\"  tokens: {ex['tokens']}\")\n",
    "            print(f\"  pred:   {ex['pred_seg']}\")\n",
    "            print(f\"  gold:   {ex['gold_best']}\")\n",
    "            print(f\"  P/R/F1: {ex['P']}/{ex['R']}/{ex['F1']}\\n\")\n",
    "\n",
    "    return {\n",
    "        \"n_eval\": n_eval, \"micro_precision\": micro_P, \"micro_recall\": micro_R,\n",
    "        \"micro_f1\": micro_F1, \"exact_match_rate\": exact_rate, \"examples\": examples\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c573d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_segmentation_valid(segmentation: list, allowed_suffixes: set) -> bool:\n",
    "    \"\"\"Check if all suffixes (non-root morphemes) are in the allowed set.\"\"\"\n",
    "    if len(segmentation) <= 1:\n",
    "        return True\n",
    "    for morpheme in segmentation[1:]:\n",
    "        if morpheme not in allowed_suffixes:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def evaluate_and_ignore_rejected(\n",
    "    df, model, vocab, out,\n",
    "    allowed_suffixes: list,\n",
    "    max_token_len=4,\n",
    "    use_tuned_thr=True,\n",
    "    show_sample=5\n",
    "):\n",
    "    \"\"\"Evaluate but skip predictions with invalid suffixes.\"\"\"\n",
    "    hmm_prior = out[\"hmm_prior\"]\n",
    "    thr = float(out.get(\"best_thr\", 0.5)) if use_tuned_thr else 0.5\n",
    "    allowed_suffixes_set = set(allowed_suffixes)\n",
    "\n",
    "    total_tp = total_fp = total_fn = 0\n",
    "    exact_hits = 0\n",
    "    n_total_words = 0\n",
    "    n_evaluated_words = 0\n",
    "    rejection_count = 0\n",
    "    false_rejection_count = 0\n",
    "    correct_kept_count = 0\n",
    "    examples = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        word = str(row[\"Word\"])\n",
    "        gold_variants = normalize_gold_variants(row[\"Gold\"])\n",
    "\n",
    "        if not isinstance(gold_variants, list) or len(gold_variants) == 0:\n",
    "            continue\n",
    "        \n",
    "        n_total_words += 1\n",
    "\n",
    "        toks = tokenize_with_vocab(word, vocab, max_token_len=max_token_len)\n",
    "        seg_string, probs = segment_tokens(model, vocab, toks, hmm_prior=hmm_prior, thr=thr)\n",
    "        predicted_morphs = seg_string.split('-')\n",
    "        \n",
    "        mask01 = (probs >= thr).astype(int)\n",
    "        pred_set = offsets_from_tokens_and_mask(toks, mask01)\n",
    "        gold_sets = [offsets_from_morphemes(gv) for gv in gold_variants]\n",
    "        is_correct = any(pred_set == gs for gs in gold_sets)\n",
    "\n",
    "        if not is_segmentation_valid(predicted_morphs, allowed_suffixes_set):\n",
    "            rejection_count += 1\n",
    "            if is_correct:\n",
    "                false_rejection_count += 1\n",
    "            continue\n",
    "\n",
    "        n_evaluated_words += 1\n",
    "        \n",
    "        if is_correct:\n",
    "            correct_kept_count += 1\n",
    "            exact_hits += 1\n",
    "\n",
    "        best = max((f1_from_sets(pred_set, gs) + (gs,) for gs in gold_sets), key=lambda z: z[2])\n",
    "        P, R, F1, tp, fp, fn, best_gs = best\n",
    "\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "\n",
    "        if len(examples) < show_sample:\n",
    "            best_morphs = None\n",
    "            for gv in gold_variants:\n",
    "                if offsets_from_morphemes(gv) == best_gs:\n",
    "                    best_morphs = gv\n",
    "                    break\n",
    "            gold_str = \"-\".join(best_morphs) if best_morphs else \"(ambig)\"\n",
    "            examples.append({\n",
    "                \"word\": word, \"tokens\": toks, \"pred_seg\": seg_string,\n",
    "                \"gold_best\": gold_str, \"P\": round(P, 3), \"R\": round(R, 3), \"F1\": round(F1, 3)\n",
    "            })\n",
    "\n",
    "    micro_P = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
    "    micro_R = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
    "    micro_F1 = 2 * micro_P * micro_R / (micro_P + micro_R) if (micro_P + micro_R) > 0 else 0.0\n",
    "    exact_rate = exact_hits / n_evaluated_words if n_evaluated_words > 0 else 0.0\n",
    "    \n",
    "    filter_precision = correct_kept_count / n_evaluated_words if n_evaluated_words > 0 else 0.0\n",
    "    total_correct = correct_kept_count + false_rejection_count\n",
    "    false_rejection_rate = false_rejection_count / total_correct if total_correct > 0 else 0.0\n",
    "\n",
    "    print(f\"tried {n_total_words} words\")\n",
    "    print(f\"rejected {rejection_count} ({rejection_count/n_total_words:.1%}) with invalid suffixes\")\n",
    "    print(f\"scoring {n_evaluated_words} valid predictions\")\n",
    "    print(f\"\\n--- filter analysis ---\")\n",
    "    print(f\"filter precision: {filter_precision:.1%}\")\n",
    "    print(f\"false rejection rate: {false_rejection_rate:.1%}\")\n",
    "    print(f\"  correct kept: {correct_kept_count}\")\n",
    "    print(f\"  correct rejected: {false_rejection_count}\")\n",
    "    print(f\"  total correct: {total_correct}\")\n",
    "    print(f\"\\n--- final scores (valid predictions only) ---\")\n",
    "    print(f\"boundary (micro) P/R/F1 = {micro_P:.3f}/{micro_R:.3f}/{micro_F1:.3f}\")\n",
    "    print(f\"exact match = {exact_rate:.3f}\")\n",
    "\n",
    "    if examples:\n",
    "        print(\"\\nsamples:\")\n",
    "        for ex in examples:\n",
    "            print(f\"- {ex['word']}\")\n",
    "            print(f\"  tokens: {ex['tokens']}\")\n",
    "            print(f\"  pred:   {ex['pred_seg']}\")\n",
    "            print(f\"  gold:   {ex['gold_best']}\")\n",
    "            print(f\"  P/R/F1: {ex['P']}/{ex['R']}/{ex['F1']}\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"micro_f1\": micro_F1, \"exact_match_rate\": exact_rate,\n",
    "        \"rejection_count\": rejection_count, \"false_rejection_count\": false_rejection_count,\n",
    "        \"filter_precision\": filter_precision, \"false_rejection_rate\": false_rejection_rate\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e4ea72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 88 suffixes from data\\suffixesCQ-Anettte-Rios_LS.txt\n"
     ]
    }
   ],
   "source": [
    "def read_suffixes(filename):\n",
    "    \"\"\"Read suffix list from file (format: 'number -suffix').\"\"\"\n",
    "    suffixes = []\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = line.split(maxsplit=1)\n",
    "            if len(parts) == 2:\n",
    "                _, suffix = parts\n",
    "                suffixes.append(suffix[1:])  # drop leading dash\n",
    "    return suffixes\n",
    "\n",
    "suffix_filename = os.path.join(DATA_FOLDER, \"suffixesCQ-Anettte-Rios_LS.txt\")\n",
    "if not os.path.exists(suffix_filename):\n",
    "    suffix_filename = \"suffixesCQ-Anettte-Rios_LS.txt\"\n",
    "    if not os.path.exists(suffix_filename):\n",
    "        print(f\"warning: suffix file not found\")\n",
    "        suffix_list = []\n",
    "    else:\n",
    "        suffix_list = read_suffixes(suffix_filename)\n",
    "        print(f\"loaded {len(suffix_list)} suffixes from {suffix_filename}\")\n",
    "else:\n",
    "    suffix_list = read_suffixes(suffix_filename)\n",
    "    print(f\"loaded {len(suffix_list)} suffixes from {suffix_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e06fc14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    \"\"\"Optuna objective for hyperparameter search.\"\"\"\n",
    "    hparams = {\n",
    "        \"emb_dim\": trial.suggest_categorical(\"emb_dim\", [16, 32, 64]),\n",
    "        \"hidden_size\": trial.suggest_categorical(\"hidden_size\", [32, 64, 128]),\n",
    "        \"num_layers\": trial.suggest_int(\"num_layers\", 1, 3),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5, step=0.05),\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True),\n",
    "        \"freeze_emb\": False,\n",
    "    }\n",
    "    lambda_prior_val = trial.suggest_float(\"lambda_prior\", 0.0, 0.5)\n",
    "\n",
    "    print(f\"\\n--- trial {trial.number} ---\")\n",
    "    model, vocab, out = run_segmentation_with_privK(\n",
    "        df=str_df,\n",
    "        provided_suffix_list=suffix_list,\n",
    "        use_suffix_list=True,\n",
    "        unk_penalty=-15,\n",
    "        epochs=15,\n",
    "        use_prior=True,\n",
    "        lambda_prior=lambda_prior_val,\n",
    "        lambda_k=0.2,\n",
    "        hparams=hparams,\n",
    "        synthetic_choice=SYNTHETIC_DATA_CHOICE\n",
    "    )\n",
    "\n",
    "    test_set_results = evaluate_on_gold_df(\n",
    "        df=acc_df, model=model, vocab=vocab, out=out,\n",
    "        max_token_len=4, use_tuned_thr=True, show_sample=0\n",
    "    )\n",
    "    test_exact_match = test_set_results[\"exact_match_rate\"]\n",
    "    \n",
    "    print(f\"trial {trial.number} done | exact match: {test_exact_match:.4f}\")\n",
    "    return test_exact_match\n",
    "\n",
    "# Uncomment to run hyperparameter search:\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=50)\n",
    "# print(f\"best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9eb1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters from optuna search\n",
    "best = {\n",
    "    \"emb_dim\": 32,\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.4,\n",
    "    \"lr\": 0.009213045798657327,\n",
    "    \"weight_decay\": 0.0001132283214088801,\n",
    "    \"freeze_emb\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "534143a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "K-FOLD CV (k=5)\n",
      "================================================================================\n",
      "\n",
      "--- fold 1/5 ---\n",
      "train: 5064, val: 1266\n",
      "HMM: 510 suffixes, max len 8, unk penalty -11.33\n",
      "  ep 01 | loss=0.7222 | P/R/F1=0.859/0.922/0.889 | exact=0.593\n",
      "  ep 02 | loss=0.2640 | P/R/F1=0.945/0.956/0.950 | exact=0.802\n",
      "  ep 03 | loss=0.1909 | P/R/F1=0.962/0.966/0.964 | exact=0.858\n",
      "  ep 04 | loss=0.1591 | P/R/F1=0.958/0.982/0.970 | exact=0.878\n",
      "  ep 05 | loss=0.1444 | P/R/F1=0.975/0.972/0.973 | exact=0.892\n",
      "  ep 06 | loss=0.1192 | P/R/F1=0.973/0.974/0.974 | exact=0.898\n",
      "  ep 07 | loss=0.1151 | P/R/F1=0.968/0.985/0.976 | exact=0.904\n",
      "  ep 08 | loss=0.1054 | P/R/F1=0.978/0.978/0.978 | exact=0.913\n",
      "  ep 09 | loss=0.1019 | P/R/F1=0.967/0.987/0.977 | exact=0.909\n",
      "  ep 10 | loss=0.1014 | P/R/F1=0.973/0.986/0.980 | exact=0.920\n",
      "  ep 11 | loss=0.0975 | P/R/F1=0.971/0.986/0.979 | exact=0.914\n",
      "  ep 12 | loss=0.0957 | P/R/F1=0.975/0.983/0.979 | exact=0.916\n",
      "  ep 13 | loss=0.0972 | P/R/F1=0.973/0.982/0.977 | exact=0.911\n",
      "  ep 14 | loss=0.0979 | P/R/F1=0.977/0.980/0.979 | exact=0.919\n",
      "  ep 15 | loss=0.0940 | P/R/F1=0.983/0.979/0.981 | exact=0.925\n",
      "best threshold: 0.590 | exact=0.929 | F1=0.982\n",
      "  best epoch: 15\n",
      "  final (thr=0.590): P/R/F1=0.985/0.979/0.982 | exact=0.929\n",
      "\n",
      "--- fold 2/5 ---\n",
      "train: 5064, val: 1266\n",
      "HMM: 517 suffixes, max len 8, unk penalty -11.35\n",
      "  ep 01 | loss=0.7274 | P/R/F1=0.881/0.853/0.867 | exact=0.573\n",
      "  ep 02 | loss=0.2708 | P/R/F1=0.914/0.971/0.941 | exact=0.769\n",
      "  ep 03 | loss=0.1914 | P/R/F1=0.941/0.979/0.959 | exact=0.841\n",
      "  ep 04 | loss=0.1666 | P/R/F1=0.959/0.976/0.968 | exact=0.870\n",
      "  ep 05 | loss=0.1443 | P/R/F1=0.971/0.982/0.977 | exact=0.908\n",
      "  ep 06 | loss=0.1286 | P/R/F1=0.978/0.980/0.979 | exact=0.912\n",
      "  ep 07 | loss=0.1203 | P/R/F1=0.966/0.988/0.977 | exact=0.908\n",
      "  ep 08 | loss=0.1210 | P/R/F1=0.973/0.986/0.979 | exact=0.921\n",
      "  ep 09 | loss=0.1085 | P/R/F1=0.972/0.987/0.979 | exact=0.915\n",
      "  ep 10 | loss=0.1024 | P/R/F1=0.978/0.983/0.981 | exact=0.923\n",
      "  ep 11 | loss=0.0998 | P/R/F1=0.977/0.989/0.983 | exact=0.931\n",
      "  ep 12 | loss=0.0951 | P/R/F1=0.982/0.986/0.984 | exact=0.934\n",
      "  ep 13 | loss=0.0950 | P/R/F1=0.976/0.986/0.981 | exact=0.924\n",
      "  ep 14 | loss=0.0939 | P/R/F1=0.976/0.990/0.983 | exact=0.930\n",
      "  ep 15 | loss=0.0893 | P/R/F1=0.979/0.988/0.983 | exact=0.935\n",
      "best threshold: 0.560 | exact=0.940 | F1=0.985\n",
      "  best epoch: 15\n",
      "  final (thr=0.560): P/R/F1=0.981/0.988/0.985 | exact=0.940\n",
      "\n",
      "--- fold 3/5 ---\n",
      "train: 5064, val: 1266\n",
      "HMM: 514 suffixes, max len 8, unk penalty -11.34\n",
      "  ep 01 | loss=0.7760 | P/R/F1=0.868/0.858/0.863 | exact=0.544\n",
      "  ep 02 | loss=0.2841 | P/R/F1=0.933/0.960/0.946 | exact=0.796\n",
      "  ep 03 | loss=0.2060 | P/R/F1=0.967/0.946/0.956 | exact=0.829\n",
      "  ep 04 | loss=0.1703 | P/R/F1=0.954/0.976/0.964 | exact=0.856\n",
      "  ep 05 | loss=0.1506 | P/R/F1=0.958/0.978/0.968 | exact=0.875\n",
      "  ep 06 | loss=0.1303 | P/R/F1=0.962/0.977/0.970 | exact=0.884\n",
      "  ep 07 | loss=0.1206 | P/R/F1=0.972/0.976/0.974 | exact=0.902\n",
      "  ep 08 | loss=0.1119 | P/R/F1=0.974/0.972/0.973 | exact=0.897\n",
      "  ep 09 | loss=0.1099 | P/R/F1=0.972/0.982/0.977 | exact=0.909\n",
      "  ep 10 | loss=0.1008 | P/R/F1=0.983/0.976/0.979 | exact=0.919\n",
      "  ep 11 | loss=0.0960 | P/R/F1=0.978/0.976/0.977 | exact=0.912\n",
      "  ep 12 | loss=0.0937 | P/R/F1=0.977/0.983/0.980 | exact=0.922\n",
      "  ep 13 | loss=0.0952 | P/R/F1=0.978/0.985/0.981 | exact=0.930\n",
      "  ep 14 | loss=0.0882 | P/R/F1=0.978/0.982/0.980 | exact=0.922\n",
      "  ep 15 | loss=0.0876 | P/R/F1=0.982/0.982/0.982 | exact=0.933\n",
      "best threshold: 0.540 | exact=0.934 | F1=0.982\n",
      "  best epoch: 15\n",
      "  final (thr=0.540): P/R/F1=0.983/0.981/0.982 | exact=0.934\n",
      "\n",
      "--- fold 4/5 ---\n",
      "train: 5064, val: 1266\n",
      "HMM: 523 suffixes, max len 8, unk penalty -11.35\n",
      "  ep 01 | loss=0.8623 | P/R/F1=0.793/0.830/0.811 | exact=0.420\n",
      "  ep 02 | loss=0.3340 | P/R/F1=0.924/0.943/0.933 | exact=0.740\n",
      "  ep 03 | loss=0.2082 | P/R/F1=0.960/0.963/0.962 | exact=0.855\n",
      "  ep 04 | loss=0.1754 | P/R/F1=0.932/0.987/0.959 | exact=0.836\n",
      "  ep 05 | loss=0.1579 | P/R/F1=0.972/0.971/0.971 | exact=0.885\n",
      "  ep 06 | loss=0.1370 | P/R/F1=0.967/0.976/0.971 | exact=0.885\n",
      "  ep 07 | loss=0.1224 | P/R/F1=0.966/0.984/0.975 | exact=0.897\n",
      "  ep 08 | loss=0.1148 | P/R/F1=0.970/0.982/0.976 | exact=0.905\n",
      "  ep 09 | loss=0.1081 | P/R/F1=0.968/0.982/0.975 | exact=0.904\n",
      "  ep 10 | loss=0.1001 | P/R/F1=0.970/0.982/0.976 | exact=0.907\n",
      "  ep 11 | loss=0.1002 | P/R/F1=0.974/0.979/0.977 | exact=0.908\n",
      "  ep 12 | loss=0.0988 | P/R/F1=0.975/0.982/0.978 | exact=0.913\n",
      "  ep 13 | loss=0.0933 | P/R/F1=0.974/0.978/0.976 | exact=0.909\n",
      "  ep 14 | loss=0.0964 | P/R/F1=0.977/0.981/0.979 | exact=0.919\n",
      "  ep 15 | loss=0.0962 | P/R/F1=0.974/0.982/0.978 | exact=0.915\n",
      "best threshold: 0.550 | exact=0.919 | F1=0.979\n",
      "  best epoch: 14\n",
      "  final (thr=0.550): P/R/F1=0.980/0.979/0.979 | exact=0.919\n",
      "\n",
      "--- fold 5/5 ---\n",
      "train: 5064, val: 1266\n",
      "HMM: 511 suffixes, max len 8, unk penalty -11.34\n",
      "  ep 01 | loss=0.8016 | P/R/F1=0.889/0.638/0.743 | exact=0.323\n",
      "  ep 02 | loss=0.2906 | P/R/F1=0.940/0.934/0.937 | exact=0.764\n",
      "  ep 03 | loss=0.1987 | P/R/F1=0.935/0.979/0.957 | exact=0.828\n",
      "  ep 04 | loss=0.1629 | P/R/F1=0.965/0.972/0.968 | exact=0.869\n",
      "  ep 05 | loss=0.1381 | P/R/F1=0.965/0.977/0.971 | exact=0.883\n",
      "  ep 06 | loss=0.1307 | P/R/F1=0.969/0.976/0.972 | exact=0.893\n",
      "  ep 07 | loss=0.1255 | P/R/F1=0.978/0.969/0.973 | exact=0.896\n",
      "  ep 08 | loss=0.1141 | P/R/F1=0.971/0.982/0.977 | exact=0.906\n",
      "  ep 09 | loss=0.1166 | P/R/F1=0.975/0.979/0.977 | exact=0.909\n",
      "  ep 10 | loss=0.1039 | P/R/F1=0.980/0.980/0.980 | exact=0.915\n",
      "  ep 11 | loss=0.1016 | P/R/F1=0.976/0.982/0.979 | exact=0.912\n",
      "  ep 12 | loss=0.0952 | P/R/F1=0.977/0.981/0.979 | exact=0.919\n",
      "  ep 13 | loss=0.0913 | P/R/F1=0.978/0.989/0.983 | exact=0.931\n",
      "  ep 14 | loss=0.0931 | P/R/F1=0.980/0.981/0.981 | exact=0.924\n",
      "  ep 15 | loss=0.0889 | P/R/F1=0.980/0.983/0.981 | exact=0.928\n",
      "best threshold: 0.520 | exact=0.932 | F1=0.984\n",
      "  best epoch: 13\n",
      "  final (thr=0.520): P/R/F1=0.978/0.989/0.984 | exact=0.932\n",
      "\n",
      "================================================================================\n",
      "CV SUMMARY\n",
      "================================================================================\n",
      "  fold 1: P=0.985, R=0.979, F1=0.982, EM=0.929\n",
      "  fold 2: P=0.981, R=0.988, F1=0.985, EM=0.940\n",
      "  fold 3: P=0.983, R=0.981, F1=0.982, EM=0.934\n",
      "  fold 4: P=0.980, R=0.979, F1=0.979, EM=0.919\n",
      "  fold 5: P=0.978, R=0.989, F1=0.984, EM=0.932\n",
      "\n",
      "mean +/- std over 5 folds:\n",
      "  precision: 0.981 +/- 0.002\n",
      "  recall:    0.983 +/- 0.004\n",
      "  F1:        0.982 +/- 0.002\n",
      "  exact:     0.931 +/- 0.007\n",
      "  threshold: 0.552 +/- 0.023\n",
      "\n",
      "best fold: 2 (exact=0.940)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "avg exact match: 0.931 +/- 0.007\n",
      "avg boundary F1: 0.982 +/- 0.002\n"
     ]
    }
   ],
   "source": [
    "# Run k-fold cross-validation\n",
    "kfold_results = run_kfold_cross_validation(\n",
    "    df=str_df,\n",
    "    provided_suffix_list=suffix_list,\n",
    "    n_folds=5,\n",
    "    use_suffix_list=False,\n",
    "    unk_penalty=-15.0,\n",
    "    epochs=15,\n",
    "    use_prior=True,\n",
    "    lambda_prior=0.15289202508573396,\n",
    "    lambda_k=0.2,\n",
    "    hparams=best,\n",
    "    synthetic_choice=SYNTHETIC_DATA_CHOICE,\n",
    "    random_state=RNG\n",
    ")\n",
    "\n",
    "print(f\"\\navg exact match: {kfold_results['mean_metrics']['exact_match']:.3f} +/- {kfold_results['std_metrics']['exact_match']:.3f}\")\n",
    "print(f\"avg boundary F1: {kfold_results['mean_metrics']['boundary_f1']:.3f} +/- {kfold_results['std_metrics']['boundary_f1']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "327aaced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for model 38f132fa19705d49...\n",
      "loaded artifacts from models_Markov-LSTM-MarkovFilter\\38f132fa19705d49\n",
      "found it! loading from models_Markov-LSTM-MarkovFilter\\38f132fa19705d49\n",
      "skipping training, model ready\n",
      "\n",
      "model ready, threshold: 0.420\n"
     ]
    }
   ],
   "source": [
    "# Train or load the model (this creates model, vocab, out for later use)\n",
    "model, vocab, out = run_segmentation_with_privK(\n",
    "    df=str_df,\n",
    "    provided_suffix_list=suffix_list,\n",
    "    use_suffix_list=False,\n",
    "    unk_penalty=-15.0,\n",
    "    epochs=15,\n",
    "    use_prior=True,\n",
    "    lambda_prior=0.15289202508573396,\n",
    "    lambda_k=0.2,\n",
    "    hparams=best,\n",
    "    synthetic_choice=SYNTHETIC_DATA_CHOICE\n",
    ")\n",
    "\n",
    "thr = out.get(\"best_thr\", 0.5)\n",
    "print(f\"\\nmodel ready, threshold: {thr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b54e3799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: pikunas\n",
      "tokens: ['p', 'i', 'k', 'u', 'n', 'a', 's']\n",
      "probs: [0.0, 0.9670000076293945, 0.0, 0.0010000000474974513, 0.0, 0.8569999933242798]\n",
      "segmented (thr=0.420): pi-kuna-s\n"
     ]
    }
   ],
   "source": [
    "# Example segmentation\n",
    "word = \"pikunas\"\n",
    "tokens = tokenize_with_vocab(word, vocab, max_token_len=4)\n",
    "thr = out.get(\"best_thr\", 0.5)\n",
    "\n",
    "seg_string, boundary_probs = segment_tokens(\n",
    "    model, vocab, tokens, hmm_prior=out[\"hmm_prior\"], thr=thr\n",
    ")\n",
    "\n",
    "print(f\"word: {word}\")\n",
    "print(f\"tokens: {tokens}\")\n",
    "print(f\"probs: {np.round(boundary_probs, 3).tolist()}\")\n",
    "print(f\"segmented (thr={thr:.3f}): {seg_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6648d1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- standard evaluation ---\n",
      "evaluated 913 words\n",
      "boundary (micro) P/R/F1 = 0.794/0.852/0.822\n",
      "exact match = 0.574\n",
      "\n",
      "samples:\n",
      "- unupas\n",
      "  tokens: ['u', 'n', 'u', 'p', 'a', 's']\n",
      "  pred:   unupa-s\n",
      "  gold:   unu-pas\n",
      "  P/R/F1: 0.0/0.0/0.0\n",
      "\n",
      "- umankus\n",
      "  tokens: ['u', 'm', 'a', 'n', 'k', 'u', 's']\n",
      "  pred:   uma-nku-s\n",
      "  gold:   uma-nku-s\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- hikurin\n",
      "  tokens: ['h', 'i', 'k', 'u', 'r', 'i', 'n']\n",
      "  pred:   hiku-ri-n\n",
      "  gold:   hikuri-n\n",
      "  P/R/F1: 0.5/1.0/0.667\n",
      "\n",
      "- sutipi\n",
      "  tokens: ['s', 'u', 't', 'i', 'p', 'i']\n",
      "  pred:   suti-pi\n",
      "  gold:   suti-pi\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- pikunas\n",
      "  tokens: ['p', 'i', 'k', 'u', 'n', 'a', 's']\n",
      "  pred:   pi-kuna-s\n",
      "  gold:   pi-kuna-s\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- atipaq\n",
      "  tokens: ['a', 't', 'i', 'p', 'a', 'q']\n",
      "  pred:   ati-paq\n",
      "  gold:   ati-paq\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- tomani\n",
      "  tokens: ['t', 'o', 'm', 'a', 'n', 'i']\n",
      "  pred:   toma-ni\n",
      "  gold:   toma-ni\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- rantiq\n",
      "  tokens: ['r', 'a', 'n', 't', 'i', 'q']\n",
      "  pred:   rantiq\n",
      "  gold:   ranti-q\n",
      "  P/R/F1: 0.0/0.0/0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "print(\"\\n--- standard evaluation ---\")\n",
    "results = evaluate_on_gold_df(\n",
    "    acc_df, model, vocab, out,\n",
    "    max_token_len=4,\n",
    "    use_tuned_thr=True,\n",
    "    show_sample=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70a217be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- evaluation with suffix filter ---\n",
      "tried 913 words\n",
      "rejected 245 (26.8%) with invalid suffixes\n",
      "scoring 668 valid predictions\n",
      "\n",
      "--- filter analysis ---\n",
      "filter precision: 66.6%\n",
      "false rejection rate: 15.1%\n",
      "  correct kept: 445\n",
      "  correct rejected: 79\n",
      "  total correct: 524\n",
      "\n",
      "--- final scores (valid predictions only) ---\n",
      "boundary (micro) P/R/F1 = 0.826/0.901/0.862\n",
      "exact match = 0.666\n",
      "\n",
      "samples:\n",
      "- unupas\n",
      "  tokens: ['u', 'n', 'u', 'p', 'a', 's']\n",
      "  pred:   unupa-s\n",
      "  gold:   unu-pas\n",
      "  P/R/F1: 0.0/0.0/0.0\n",
      "\n",
      "- umankus\n",
      "  tokens: ['u', 'm', 'a', 'n', 'k', 'u', 's']\n",
      "  pred:   uma-nku-s\n",
      "  gold:   uma-nku-s\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- hikurin\n",
      "  tokens: ['h', 'i', 'k', 'u', 'r', 'i', 'n']\n",
      "  pred:   hiku-ri-n\n",
      "  gold:   hikuri-n\n",
      "  P/R/F1: 0.5/1.0/0.667\n",
      "\n",
      "- sutipi\n",
      "  tokens: ['s', 'u', 't', 'i', 'p', 'i']\n",
      "  pred:   suti-pi\n",
      "  gold:   suti-pi\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- pikunas\n",
      "  tokens: ['p', 'i', 'k', 'u', 'n', 'a', 's']\n",
      "  pred:   pi-kuna-s\n",
      "  gold:   pi-kuna-s\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- atipaq\n",
      "  tokens: ['a', 't', 'i', 'p', 'a', 'q']\n",
      "  pred:   ati-paq\n",
      "  gold:   ati-paq\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- tomani\n",
      "  tokens: ['t', 'o', 'm', 'a', 'n', 'i']\n",
      "  pred:   toma-ni\n",
      "  gold:   toma-ni\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- rantiq\n",
      "  tokens: ['r', 'a', 'n', 't', 'i', 'q']\n",
      "  pred:   rantiq\n",
      "  gold:   ranti-q\n",
      "  P/R/F1: 0.0/0.0/0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with suffix filter\n",
    "print(\"\\n--- evaluation with suffix filter ---\")\n",
    "results_filtered = evaluate_and_ignore_rejected(\n",
    "    acc_df, model, vocab, out,\n",
    "    allowed_suffixes=suffix_list,\n",
    "    show_sample=8\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
