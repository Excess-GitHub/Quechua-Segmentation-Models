{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SEGMENTER-OLD: CHARACTER-LEVEL BILSTM MORPHOLOGY PARSER\n",
    "========================================================\n",
    "\n",
    "This notebook implements a character-level BiLSTM model for morphological segmentation\n",
    "of Quechua words. It predicts boundary positions at the character level, marking where\n",
    "morpheme boundaries occur within words.\n",
    "\n",
    "Key Features:\n",
    "- Character-level tokenization (each character is a token)\n",
    "- BiLSTM architecture for sequence labeling\n",
    "- Binary classification: predicts boundary (1) or no boundary (0) at each character position\n",
    "- Comprehensive evaluation metrics (precision, recall, F1, exact match, split-count accuracy)\n",
    "\n",
    "This is an older/alternative approach compared to the token-window based models in\n",
    "DT-LSTM-MarkovFilter.ipynb and Markov-LSTM-MarkovFilter.ipynb.\n",
    "\n",
    "All data is read from the 'data' folder and models are saved to the 'models_segmenter-old' folder.\n",
    "\"\"\"\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# DATA FOLDER CONFIGURATION\n",
    "# =========================\n",
    "# All data files should be read from and saved to the data folder\n",
    "DATA_FOLDER = \"data\"\n",
    "\n",
    "# Model folder named after this notebook\n",
    "MODEL_NAME = \"segmenter-old\"\n",
    "MODELS_FOLDER = f\"models_{MODEL_NAME}\"\n",
    "\n",
    "# Create folders if they don't exist\n",
    "os.makedirs(DATA_FOLDER, exist_ok=True)\n",
    "os.makedirs(MODELS_FOLDER, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# LOAD GOLD STANDARD DATA\n",
    "# =========================\n",
    "# The gold standard dataset contains high-quality morphological segmentations\n",
    "# This is the base training data for the character-level BiLSTM model\n",
    "print(\"Loading gold standard data...\")\n",
    "gold_df = pd.read_parquet(os.path.join(DATA_FOLDER, \"Sue_kalt.parquet\"))\n",
    "gold_df['Word'] = gold_df['word']\n",
    "gold_df['morph'] = gold_df['morph'].str.replace('-', ' ')  # Normalize separators\n",
    "gold_df['Morph_split_str'] = gold_df['morph']  # String version\n",
    "gold_df['Morph_split'] = gold_df['morph'].str.split(' ')  # List version\n",
    "gold_df = gold_df[['Word', 'Morph_split', 'Morph_split_str']]\n",
    "gold_df.drop_duplicates(subset='Word', keep='first', inplace=True)\n",
    "gold_df.dropna(subset=['Word'], inplace=True)\n",
    "print(f\"Loaded {len(gold_df):,} gold standard examples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# FEATURE EXTRACTION\n",
    "# =========================\n",
    "# Extract basic features for analysis and potential use in the model\n",
    "gold_df['num_morphemes'] = gold_df['Morph_split'].apply(len)  # Number of morphemes per word\n",
    "gold_df['word_len'] = gold_df['Word'].apply(len)  # Character length of word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# BOUNDARY LABEL GENERATION\n",
    "# =========================\n",
    "# Convert morpheme splits into character-level boundary labels\n",
    "# Labels mark the end position of each morpheme (except the last one)\n",
    "\n",
    "def get_boundary_labels(word, split):\n",
    "    \"\"\"\n",
    "    Generate binary boundary labels for a word given its morpheme split.\n",
    "    \n",
    "    Args:\n",
    "        word: The full word string\n",
    "        split: List of morphemes (e.g., ['kawsa', 'chka', 'na', 'n', 'ta'])\n",
    "    \n",
    "    Returns:\n",
    "        List of binary labels (0=no boundary, 1=boundary) for each character position\n",
    "        The label at position i indicates if there's a boundary after character i\n",
    "    \"\"\"\n",
    "    labels = [0] * len(word)\n",
    "    idx = 0\n",
    "    # Mark boundaries after each morpheme (except the last one)\n",
    "    for morpheme in split[:-1]: \n",
    "        idx += len(morpheme)\n",
    "        if idx < len(word):\n",
    "            labels[idx - 1] = 1  # Boundary at the end of this morpheme\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PREPARE TRAINING DATA\n",
    "# =========================\n",
    "# Convert words to character sequences and generate boundary labels\n",
    "# This prepares the data for the character-level BiLSTM model\n",
    "\n",
    "gold_df['char_seq'] = gold_df['Word'].apply(list)  # Convert word to list of characters\n",
    "gold_df['boundary_labels'] = gold_df.apply(\n",
    "    lambda row: get_boundary_labels(row['Word'], row['Morph_split']), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# K-FOLD CROSS-VALIDATION FUNCTION\n",
    "# ===================================================================\n",
    "# This function performs k-fold cross-validation on the training data\n",
    "# It splits the data into k folds and trains/evaluates on each fold\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def run_kfold_cross_validation(\n",
    "    df,\n",
    "    n_folds=5,\n",
    "    emb_dim=16,\n",
    "    hidden_size=32,\n",
    "    num_layers=2,\n",
    "    dropout=0.3,\n",
    "    epochs=35,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    random_state=42,\n",
    "    device=device\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation on the training data.\n",
    "    \n",
    "    Args:\n",
    "        df: Training DataFrame with 'char_seq' and 'boundary_labels' columns\n",
    "        n_folds: Number of folds for cross-validation (default: 5)\n",
    "        emb_dim: Embedding dimension\n",
    "        hidden_size: LSTM hidden size\n",
    "        num_layers: Number of LSTM layers\n",
    "        dropout: Dropout rate\n",
    "        epochs: Number of training epochs per fold\n",
    "        batch_size: Training batch size\n",
    "        lr: Learning rate\n",
    "        weight_decay: Weight decay for optimizer\n",
    "        random_state: Random seed for reproducibility\n",
    "        device: Device to run training on\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "        - fold_results: List of results for each fold\n",
    "        - mean_metrics: Average metrics across all folds\n",
    "        - std_metrics: Standard deviation of metrics across folds\n",
    "        - best_fold_idx: Index of the fold with best F1 score\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"K-FOLD CROSS-VALIDATION (k={n_folds})\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Create k-fold splitter\n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    indices = np.arange(len(df))\n",
    "    \n",
    "    fold_results = []\n",
    "    all_metrics = {\n",
    "        'boundary_precision': [],\n",
    "        'boundary_recall': [],\n",
    "        'boundary_f1': [],\n",
    "        'val_loss': []\n",
    "    }\n",
    "    \n",
    "    # Train and evaluate on each fold\n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(kfold.split(indices), 1):\n",
    "        print(f\"\\n{'─'*80}\")\n",
    "        print(f\"FOLD {fold_idx}/{n_folds}\")\n",
    "        print(f\"{'─'*80}\")\n",
    "        print(f\"Train samples: {len(train_indices)}, Validation samples: {len(val_indices)}\")\n",
    "        \n",
    "        # Split data into train and validation\n",
    "        train_df_fold = df.iloc[train_indices].reset_index(drop=True)\n",
    "        val_df_fold = df.iloc[val_indices].reset_index(drop=True)\n",
    "        \n",
    "        # Build vocabulary from training fold only\n",
    "        stoi_fold, itos_fold = build_vocab(train_df_fold[\"char_seq\"].tolist())\n",
    "        vocab_size = len(itos_fold)\n",
    "        \n",
    "        # Create datasets and loaders\n",
    "        train_ds_fold = CharBoundaryDataset(train_df_fold)\n",
    "        val_ds_fold = CharBoundaryDataset(val_df_fold)\n",
    "        train_loader_fold = DataLoader(train_ds_fold, batch_size=batch_size, shuffle=True, collate_fn=pad_batch)\n",
    "        val_loader_fold = DataLoader(val_ds_fold, batch_size=batch_size, shuffle=False, collate_fn=pad_batch)\n",
    "        \n",
    "        # Create model\n",
    "        model_fold = BiLSTMBoundary(\n",
    "            vocab_size=vocab_size,\n",
    "            emb_dim=emb_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        ).to(device)\n",
    "        \n",
    "        # Create optimizer\n",
    "        optimizer_fold = torch.optim.AdamW(model_fold.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        \n",
    "        # Training loop\n",
    "        best_val_f1 = 0.0\n",
    "        best_val_prec = 0.0\n",
    "        best_val_rec = 0.0\n",
    "        best_val_loss = float('inf')\n",
    "        best_epoch = 0\n",
    "        \n",
    "        for epoch in range(1, epochs+1):\n",
    "            # Training phase\n",
    "            model_fold.train()\n",
    "            total_loss = 0.0\n",
    "            total_tokens = 0\n",
    "            for x, y, mask, lengths in train_loader_fold:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                mask = mask.to(device)\n",
    "                lengths = lengths.to(device)\n",
    "                \n",
    "                logits = model_fold(x, lengths)\n",
    "                loss = masked_bce_loss(logits, y, mask)\n",
    "                \n",
    "                optimizer_fold.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model_fold.parameters(), 1.0)\n",
    "                optimizer_fold.step()\n",
    "                \n",
    "                total_loss += loss.item() * mask.sum().item()\n",
    "                total_tokens += mask.sum().item()\n",
    "            \n",
    "            train_loss = total_loss / max(total_tokens, 1)\n",
    "            \n",
    "            # Validation phase\n",
    "            model_fold.eval()\n",
    "            val_loss, val_tokens = 0.0, 0\n",
    "            all_prec, all_rec, all_f1 = [], [], []\n",
    "            with torch.no_grad():\n",
    "                for x, y, mask, lengths in val_loader_fold:\n",
    "                    x = x.to(device)\n",
    "                    y = y.to(device)\n",
    "                    mask = mask.to(device)\n",
    "                    lengths = lengths.to(device)\n",
    "                    \n",
    "                    logits = model_fold(x, lengths)\n",
    "                    loss = masked_bce_loss(logits, y, mask)\n",
    "                    val_loss += loss.item() * mask.sum().item()\n",
    "                    val_tokens += mask.sum().item()\n",
    "                    \n",
    "                    p, r, f = boundary_f1(logits, y, mask, threshold=0.5)\n",
    "                    all_prec.append(p)\n",
    "                    all_rec.append(r)\n",
    "                    all_f1.append(f)\n",
    "            \n",
    "            val_loss = val_loss / max(val_tokens, 1)\n",
    "            prec = np.mean(all_prec) if all_prec else 0.0\n",
    "            rec = np.mean(all_rec) if all_rec else 0.0\n",
    "            f1 = np.mean(all_f1) if all_f1 else 0.0\n",
    "            \n",
    "            print(f\"  Epoch {epoch:02d} | train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  P={prec:.3f} R={rec:.3f} F1={f1:.3f}\")\n",
    "            \n",
    "            # Track best validation performance\n",
    "            if f1 > best_val_f1 or (np.isclose(f1, best_val_f1) and val_loss < best_val_loss):\n",
    "                best_val_f1 = f1\n",
    "                best_val_prec = prec\n",
    "                best_val_rec = rec\n",
    "                best_val_loss = val_loss\n",
    "                best_epoch = epoch\n",
    "        \n",
    "        print(f\"\\n  Best epoch: {best_epoch}\")\n",
    "        print(f\"  Best validation: P={best_val_prec:.3f} R={best_val_rec:.3f} F1={best_val_f1:.3f} Loss={best_val_loss:.4f}\")\n",
    "        \n",
    "        # Store fold results\n",
    "        fold_result = {\n",
    "            'fold': fold_idx,\n",
    "            'boundary_precision': best_val_prec,\n",
    "            'boundary_recall': best_val_rec,\n",
    "            'boundary_f1': best_val_f1,\n",
    "            'val_loss': best_val_loss,\n",
    "            'best_epoch': best_epoch\n",
    "        }\n",
    "        fold_results.append(fold_result)\n",
    "        \n",
    "        # Collect metrics for averaging\n",
    "        all_metrics['boundary_precision'].append(best_val_prec)\n",
    "        all_metrics['boundary_recall'].append(best_val_rec)\n",
    "        all_metrics['boundary_f1'].append(best_val_f1)\n",
    "        all_metrics['val_loss'].append(best_val_loss)\n",
    "    \n",
    "    # Calculate mean and std across folds\n",
    "    mean_metrics = {\n",
    "        'boundary_precision': np.mean(all_metrics['boundary_precision']),\n",
    "        'boundary_recall': np.mean(all_metrics['boundary_recall']),\n",
    "        'boundary_f1': np.mean(all_metrics['boundary_f1']),\n",
    "        'val_loss': np.mean(all_metrics['val_loss'])\n",
    "    }\n",
    "    \n",
    "    std_metrics = {\n",
    "        'boundary_precision': np.std(all_metrics['boundary_precision']),\n",
    "        'boundary_recall': np.std(all_metrics['boundary_recall']),\n",
    "        'boundary_f1': np.std(all_metrics['boundary_f1']),\n",
    "        'val_loss': np.std(all_metrics['val_loss'])\n",
    "    }\n",
    "    \n",
    "    # Find best fold (highest F1 score)\n",
    "    best_fold_idx = max(range(len(fold_results)), key=lambda i: fold_results[i]['boundary_f1'])\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"K-FOLD CROSS-VALIDATION SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nPer-fold results:\")\n",
    "    for result in fold_results:\n",
    "        print(f\"  Fold {result['fold']}: \"\n",
    "              f\"P={result['boundary_precision']:.3f}, \"\n",
    "              f\"R={result['boundary_recall']:.3f}, \"\n",
    "              f\"F1={result['boundary_f1']:.3f}, \"\n",
    "              f\"Loss={result['val_loss']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nMean ± Std across {n_folds} folds:\")\n",
    "    print(f\"  Boundary Precision: {mean_metrics['boundary_precision']:.3f} ± {std_metrics['boundary_precision']:.3f}\")\n",
    "    print(f\"  Boundary Recall:    {mean_metrics['boundary_recall']:.3f} ± {std_metrics['boundary_recall']:.3f}\")\n",
    "    print(f\"  Boundary F1:        {mean_metrics['boundary_f1']:.3f} ± {std_metrics['boundary_f1']:.3f}\")\n",
    "    print(f\"  Validation Loss:   {mean_metrics['val_loss']:.4f} ± {std_metrics['val_loss']:.4f}\")\n",
    "    print(f\"\\nBest fold: Fold {fold_results[best_fold_idx]['fold']} \"\n",
    "          f\"(F1: {fold_results[best_fold_idx]['boundary_f1']:.3f})\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'fold_results': fold_results,\n",
    "        'mean_metrics': mean_metrics,\n",
    "        'std_metrics': std_metrics,\n",
    "        'best_fold_idx': best_fold_idx,\n",
    "        'all_metrics': all_metrics\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# K-FOLD CROSS-VALIDATION DEMONSTRATION\n",
    "# ===================================================================\n",
    "# This cell demonstrates how to use k-fold cross-validation to evaluate\n",
    "# model performance more robustly by training on multiple train/val splits\n",
    "\n",
    "# Run 5-fold cross-validation on the training data\n",
    "kfold_results = run_kfold_cross_validation(\n",
    "    df=gold_df,  # Use the full gold_df for cross-validation\n",
    "    n_folds=5,  # Number of folds\n",
    "    emb_dim=EMB_DIM,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    random_state=42,  # Use fixed seed for reproducibility\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# The results dictionary contains:\n",
    "# - fold_results: List of results for each fold\n",
    "# - mean_metrics: Average metrics across all folds\n",
    "# - std_metrics: Standard deviation of metrics across folds\n",
    "# - best_fold_idx: Index of the fold with best F1 score\n",
    "# - all_metrics: Raw metrics from all folds\n",
    "\n",
    "print(\"\\nK-fold cross-validation completed!\")\n",
    "print(f\"Average boundary F1: {kfold_results['mean_metrics']['boundary_f1']:.3f} ± {kfold_results['std_metrics']['boundary_f1']:.3f}\")\n",
    "print(f\"Average boundary precision: {kfold_results['mean_metrics']['boundary_precision']:.3f} ± {kfold_results['std_metrics']['boundary_precision']:.3f}\")\n",
    "print(f\"Average boundary recall: {kfold_results['mean_metrics']['boundary_recall']:.3f} ± {kfold_results['std_metrics']['boundary_recall']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PYTORCH IMPORTS AND SETUP\n",
    "# =========================\n",
    "# Import libraries for neural network training and data handling\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Set device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# =========================\n",
    "# VOCABULARY CONSTRUCTION\n",
    "# =========================\n",
    "# Build character-level vocabulary for embedding layer\n",
    "# Each unique character gets an integer ID\n",
    "\n",
    "PAD, UNK = \"<PAD>\", \"<UNK>\"  # Special tokens for padding and unknown characters\n",
    "\n",
    "def build_vocab(seqs: List[List[str]]):\n",
    "    \"\"\"\n",
    "    Build vocabulary from character sequences.\n",
    "    \n",
    "    Args:\n",
    "        seqs: List of character sequences (each sequence is a list of characters)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (stoi, itos):\n",
    "        - stoi: Dictionary mapping character to integer ID\n",
    "        - itos: List mapping integer ID to character\n",
    "    \"\"\"\n",
    "    chars = {c for seq in seqs for c in seq}  # Collect all unique characters\n",
    "    itos = [PAD, UNK] + sorted(chars)  # Index-to-string: [PAD, UNK, 'a', 'b', ...]\n",
    "    stoi = {ch: i for i, ch in enumerate(itos)}  # String-to-index dictionary\n",
    "    return stoi, itos\n",
    "\n",
    "# Build vocabulary from all character sequences in the gold data\n",
    "stoi, itos = build_vocab(gold_df[\"char_seq\"].tolist())\n",
    "print(f\"Vocabulary size: {len(itos)} characters\")\n",
    "\n",
    "def encode(seq: List[str]) -> List[int]:\n",
    "    \"\"\"Convert character sequence to integer IDs.\"\"\"\n",
    "    return [stoi.get(c, stoi[UNK]) for c in seq]\n",
    "\n",
    "def encode_labels(labels: List[int]) -> List[int]:\n",
    "    \"\"\"Labels are already 0/1, so just return them as-is.\"\"\"\n",
    "    return labels\n",
    "\n",
    "# =========================\n",
    "# DATASET AND DATALOADER\n",
    "# =========================\n",
    "# PyTorch Dataset and DataLoader for batching and padding sequences\n",
    "\n",
    "class CharBoundaryDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for character-level boundary prediction.\n",
    "    Each sample contains a character sequence and its boundary labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, df):\n",
    "        self.x = df[\"char_seq\"].tolist()  # Character sequences\n",
    "        self.y = df[\"boundary_labels\"].tolist()  # Boundary labels\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "def pad_batch(batch, pad_id=0):\n",
    "    \"\"\"\n",
    "    Collate function for DataLoader: pads sequences to the same length.\n",
    "    \n",
    "    Args:\n",
    "        batch: List of (character_sequence, boundary_labels) tuples\n",
    "        pad_id: ID to use for padding (default: 0, which is PAD token)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of tensors:\n",
    "        - x_pad: Padded character sequences (B, T)\n",
    "        - y_pad: Padded boundary labels (B, T)\n",
    "        - mask: Boolean mask indicating valid positions (B, T)\n",
    "        - lengths: Actual length of each sequence (B,)\n",
    "    \"\"\"\n",
    "    # batch: List[ (List[str], List[int]) ]\n",
    "    seqs, labels = zip(*batch)\n",
    "    x_ids = [encode(s) for s in seqs]  # Convert characters to IDs\n",
    "    y_ids = [encode_labels(y) for y in labels]  # Labels are already 0/1\n",
    "    lengths = [len(x) for x in x_ids]\n",
    "    maxlen = max(lengths)\n",
    "    \n",
    "    # Pad sequences and labels to maxlen\n",
    "    x_pad = [xi + [pad_id]*(maxlen - len(xi)) for xi in x_ids]\n",
    "    y_pad = [yi + [0]*(maxlen - len(yi)) for yi in y_ids]  # Pad labels as 0 (will be masked)\n",
    "    mask  = [[1]*len(xi) + [0]*(maxlen - len(xi)) for xi in x_ids]  # 1 for valid, 0 for padding\n",
    "    \n",
    "    return (\n",
    "        torch.LongTensor(x_pad),\n",
    "        torch.FloatTensor(y_pad),   # BCE expects float targets\n",
    "        torch.BoolTensor(mask),\n",
    "        torch.LongTensor(lengths),\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# TRAIN/VALIDATION SPLIT\n",
    "# =========================\n",
    "# Split data into 90% training and 10% validation\n",
    "rng = np.random.default_rng(42)  # Fixed seed for reproducibility\n",
    "indices = np.arange(len(gold_df))\n",
    "rng.shuffle(indices)\n",
    "split = int(0.9*len(indices))\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "\n",
    "train_df = gold_df.iloc[train_idx].reset_index(drop=True)\n",
    "val_df   = gold_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "print(f\"Training samples: {len(train_df):,}\")\n",
    "print(f\"Validation samples: {len(val_df):,}\")\n",
    "\n",
    "train_ds = CharBoundaryDataset(train_df)\n",
    "val_ds   = CharBoundaryDataset(val_df)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, collate_fn=pad_batch)\n",
    "\n",
    "# =========================\n",
    "# BILSTM MODEL ARCHITECTURE\n",
    "# =========================\n",
    "# Character-level BiLSTM for boundary prediction\n",
    "\n",
    "class BiLSTMBoundary(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional LSTM model for character-level boundary prediction.\n",
    "    \n",
    "    Architecture:\n",
    "    1. Character embeddings (emb_dim dimensions)\n",
    "    2. Bidirectional LSTM (hidden_size per direction)\n",
    "    3. Dropout for regularization\n",
    "    4. Linear output layer (predicts boundary probability at each position)\n",
    "    \n",
    "    The model processes sequences character-by-character and outputs a logit\n",
    "    for each position indicating the probability of a boundary after that character.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size: int, emb_dim: int = 16, hidden_size: int = 16, num_layers: int = 1, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        # Character embedding layer\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,  # Process sequence in both directions\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Output layer: 2*hidden_size because bidirectional LSTM concatenates forward/backward\n",
    "        self.out = nn.Linear(hidden_size * 2, 1)  # Binary classification per time-step\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "        \n",
    "        Args:\n",
    "            x: Input character IDs (B, T) - Long tensor\n",
    "            lengths: Actual length of each sequence (B,) - Long tensor\n",
    "        \n",
    "        Returns:\n",
    "            logits: Boundary prediction logits (B, T) - Float tensor\n",
    "        \"\"\"\n",
    "        emb = self.emb(x)  # (B, T, E) - Embed characters\n",
    "        \n",
    "        # Pack sequences to ignore padding during LSTM processing\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.lstm(packed)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)  # (B, T, 2H)\n",
    "        \n",
    "        out = self.dropout(out)\n",
    "        logits = self.out(out).squeeze(-1)  # (B, T) - One logit per character position\n",
    "        return logits\n",
    "\n",
    "# =========================\n",
    "# LOSS FUNCTION\n",
    "# =========================\n",
    "# Masked binary cross-entropy loss (ignores padding positions)\n",
    "\n",
    "def masked_bce_loss(logits, targets, mask):\n",
    "    \"\"\"\n",
    "    Compute masked binary cross-entropy loss.\n",
    "    Only computes loss on valid (non-padded) positions.\n",
    "    \n",
    "    Args:\n",
    "        logits: Model predictions (B, T)\n",
    "        targets: Ground truth labels (B, T)\n",
    "        mask: Boolean mask indicating valid positions (B, T)\n",
    "    \n",
    "    Returns:\n",
    "        Scalar loss value\n",
    "    \"\"\"\n",
    "    loss_fn = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    loss_per_token = loss_fn(logits, targets)\n",
    "    loss_per_token = loss_per_token * mask.float()  # Zero out padding positions\n",
    "    denom = mask.float().sum().clamp_min(1.0)  # Total number of valid tokens\n",
    "    return loss_per_token.sum() / denom\n",
    "\n",
    "# =========================\n",
    "# EVALUATION METRICS\n",
    "# =========================\n",
    "# Functions to compute precision, recall, and F1 score for boundary prediction\n",
    "\n",
    "def boundary_f1(logits, targets, mask, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Compute precision, recall, and F1 score for boundary prediction.\n",
    "    \n",
    "    Args:\n",
    "        logits: Model predictions (B, T)\n",
    "        targets: Ground truth labels (B, T)\n",
    "        mask: Boolean mask indicating valid positions (B, T)\n",
    "        threshold: Probability threshold for binary classification (default: 0.5)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (precision, recall, f1_score)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        probs = torch.sigmoid(logits)  # Convert logits to probabilities\n",
    "        preds = (probs >= threshold).long()  # Binary predictions\n",
    "        t = targets.long()\n",
    "        m = mask.long()\n",
    "\n",
    "        # Compute true positives, false positives, false negatives\n",
    "        tp = ((preds == 1) & (t == 1) & (m == 1)).sum().item()\n",
    "        fp = ((preds == 1) & (t == 0) & (m == 1)).sum().item()\n",
    "        fn = ((preds == 0) & (t == 1) & (m == 1)).sum().item()\n",
    "\n",
    "        # Compute metrics with safe division\n",
    "        prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        rec  = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1   = 2*prec*rec / (prec + rec) if (prec + rec) > 0 else 0.0\n",
    "        return prec, rec, f1\n",
    "\n",
    "# ==== 7) Inference: predict boundaries and reconstruct morphemes ====\n",
    "def predict_boundaries(words: List[str], model, stoi, threshold=0.5) -> List[List[int]]:\n",
    "    model.eval()\n",
    "    char_lists = [list(w) for w in words]\n",
    "    x_ids = [ [stoi.get(c, stoi[UNK]) for c in chars] for chars in char_lists ]\n",
    "    lengths = [len(x) for x in x_ids]\n",
    "    maxlen = max(lengths)\n",
    "    pad_id = stoi[PAD]\n",
    "\n",
    "    x_pad = [xi + [pad_id]*(maxlen - len(xi)) for xi in x_ids]\n",
    "    mask  = [[1]*len(xi) + [0]*(maxlen - len(xi)) for xi in x_ids]\n",
    "\n",
    "    x = torch.LongTensor(x_pad).to(device)\n",
    "    lengths_t = torch.LongTensor(lengths).to(device)\n",
    "    mask_t = torch.BoolTensor(mask).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x, lengths_t)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= threshold) & mask_t\n",
    "    # trim pad and convert to 0/1\n",
    "    out = []\n",
    "    for i, L in enumerate(lengths):\n",
    "        out.append(preds[i, :L].int().tolist())\n",
    "    return out\n",
    "\n",
    "def apply_boundaries(word: str, boundary_labels: List[int]) -> List[str]:\n",
    "    # boundary_labels marks the *end* of a morpheme at that position (same convention as your helper)\n",
    "    segs = []\n",
    "    start = 0\n",
    "    for i, b in enumerate(boundary_labels, start=0):\n",
    "        if b == 1:\n",
    "            segs.append(word[start:i+1])\n",
    "            start = i+1\n",
    "    if start < len(word):\n",
    "        segs.append(word[start:])\n",
    "    return segs\n",
    "\n",
    "# Example usage:\n",
    "# test_words = [\"rikuchkani\", \"pikunas\", \"ñichkanchus\"]\n",
    "# pred_b = predict_boundaries(test_words, model, stoi, threshold=0.5)\n",
    "# for w, b in zip(test_words, pred_b):\n",
    "#     print(w, b, \"->\", apply_boundaries(w, b))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# MODEL CHECKPOINTING FUNCTIONS\n",
    "# =========================\n",
    "# Functions to save and load trained models to avoid retraining\n",
    "\n",
    "def generate_model_id(emb_dim, hidden_size, num_layers, dropout, epochs, batch_size, lr, weight_decay):\n",
    "    \"\"\"\n",
    "    Generate a unique identifier for a model based on its training parameters.\n",
    "    \n",
    "    Args:\n",
    "        All training hyperparameters\n",
    "    \n",
    "    Returns:\n",
    "        A string identifier (hash) for the model\n",
    "    \"\"\"\n",
    "    params_dict = {\n",
    "        'emb_dim': emb_dim,\n",
    "        'hidden_size': hidden_size,\n",
    "        'num_layers': num_layers,\n",
    "        'dropout': dropout,\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'lr': lr,\n",
    "        'weight_decay': weight_decay,\n",
    "        'vocab_size': len(itos)\n",
    "    }\n",
    "    params_str = json.dumps(params_dict, sort_keys=True)\n",
    "    model_id = hashlib.md5(params_str.encode()).hexdigest()[:16]\n",
    "    return model_id\n",
    "\n",
    "def save_model_checkpoint(model, stoi, itos, model_id, models_folder=MODELS_FOLDER):\n",
    "    \"\"\"\n",
    "    Save model checkpoint to the models folder.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained BiLSTMBoundary model\n",
    "        stoi: String-to-index vocabulary dictionary\n",
    "        itos: Index-to-string vocabulary list\n",
    "        model_id: Unique identifier for this model\n",
    "        models_folder: Folder to save models in\n",
    "    \"\"\"\n",
    "    model_dir = os.path.join(models_folder, model_id)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    checkpoint_path = os.path.join(model_dir, \"bilstm_char_boundary.pt\")\n",
    "    torch.save({\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"stoi\": stoi,\n",
    "        \"itos\": itos\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata_path = os.path.join(model_dir, \"metadata.json\")\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            'model_id': model_id,\n",
    "            'vocab_size': len(itos),\n",
    "            'model_name': MODEL_NAME\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"Model checkpoint saved to {model_dir}\")\n",
    "    return model_dir\n",
    "\n",
    "def load_model_checkpoint(model_id, models_folder=MODELS_FOLDER):\n",
    "    \"\"\"\n",
    "    Load model checkpoint from the models folder.\n",
    "    \n",
    "    Args:\n",
    "        model_id: Unique identifier for the model\n",
    "        models_folder: Folder where models are saved\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with 'model_state', 'stoi', 'itos', 'checkpoint_path', 'model_dir' or None if not found\n",
    "    \"\"\"\n",
    "    model_dir = os.path.join(models_folder, model_id)\n",
    "    checkpoint_path = os.path.join(model_dir, \"bilstm_char_boundary.pt\")\n",
    "    \n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        return None\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    print(f\"Model checkpoint loaded from {model_dir}\")\n",
    "    return {\n",
    "        'model_state': checkpoint['model_state'],\n",
    "        'stoi': checkpoint['stoi'],\n",
    "        'itos': checkpoint['itos'],\n",
    "        'checkpoint_path': checkpoint_path,\n",
    "        'model_dir': model_dir\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# MODEL INITIALIZATION AND TRAINING\n",
    "# =========================\n",
    "# Initialize model and optimizer, then train (or load if already trained)\n",
    "\n",
    "# Model hyperparameters\n",
    "EMB_DIM = 16\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "EPOCHS = 35\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Generate model identifier\n",
    "model_id = generate_model_id(EMB_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT, EPOCHS, BATCH_SIZE, LR, WEIGHT_DECAY)\n",
    "\n",
    "# Try to load existing model\n",
    "print(f\"Checking for existing model with ID: {model_id}\")\n",
    "loaded = load_model_checkpoint(model_id, models_folder=MODELS_FOLDER)\n",
    "\n",
    "if loaded is not None:\n",
    "    print(f\"✅ Found existing model! Loading from {loaded['model_dir']}\")\n",
    "    stoi = loaded['stoi']\n",
    "    itos = loaded['itos']\n",
    "    model = BiLSTMBoundary(vocab_size=len(itos), emb_dim=EMB_DIM, hidden_size=HIDDEN_SIZE, \n",
    "                           num_layers=NUM_LAYERS, dropout=DROPOUT).to(device)\n",
    "    model.load_state_dict(loaded['model_state'])\n",
    "    model.eval()\n",
    "    print(\"Model loaded successfully. Skipping training.\")\n",
    "else:\n",
    "    print(f\"No existing model found. Training new model...\")\n",
    "    \n",
    "    # Initialize model and optimizer\n",
    "    model = BiLSTMBoundary(vocab_size=len(itos), emb_dim=EMB_DIM, hidden_size=HIDDEN_SIZE, \n",
    "                          num_layers=NUM_LAYERS, dropout=DROPOUT).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    # =========================\n",
    "    # TRAINING LOOP\n",
    "    # =========================\n",
    "    # Train the model for specified number of epochs\n",
    "    # Save checkpoint whenever validation F1 improves\n",
    "    \n",
    "    best_val_f1 = 0.0\n",
    "    \n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_tokens = 0\n",
    "        for x, y, mask, lengths in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            mask = mask.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            logits = model(x, lengths)\n",
    "            loss = masked_bce_loss(logits, y, mask)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * mask.sum().item()\n",
    "            total_tokens += mask.sum().item()\n",
    "\n",
    "        train_loss = total_loss / max(total_tokens, 1)\n",
    "\n",
    "        # ---- Validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_tokens = 0.0, 0\n",
    "        all_prec, all_rec, all_f1 = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y, mask, lengths in val_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                mask = mask.to(device)\n",
    "                lengths = lengths.to(device)\n",
    "\n",
    "                logits = model(x, lengths)\n",
    "                loss = masked_bce_loss(logits, y, mask)\n",
    "                val_loss += loss.item() * mask.sum().item()\n",
    "                val_tokens += mask.sum().item()\n",
    "\n",
    "                p, r, f = boundary_f1(logits, y, mask, threshold=0.5)\n",
    "                all_prec.append(p); all_rec.append(r); all_f1.append(f)\n",
    "\n",
    "        val_loss = val_loss / max(val_tokens, 1)\n",
    "        prec = np.mean(all_prec) if all_prec else 0.0\n",
    "        rec  = np.mean(all_rec)  if all_rec  else 0.0\n",
    "        f1   = np.mean(all_f1)   if all_f1   else 0.0\n",
    "\n",
    "        print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  P={prec:.3f} R={rec:.3f} F1={f1:.3f}\")\n",
    "\n",
    "        # Keep best model based on validation F1\n",
    "        if f1 > best_val_f1:\n",
    "            best_val_f1 = f1\n",
    "            save_model_checkpoint(model, stoi, itos, model_id, models_folder=MODELS_FOLDER)\n",
    "            print(\"  ↳ saved checkpoint (best F1 so far)\")\n",
    "    \n",
    "    print(f\"\\nTraining complete! Best validation F1: {best_val_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "\n",
    "# =========================\n",
    "# LOAD TEST DATA\n",
    "# =========================\n",
    "# Load the test/accuracy evaluation dataset\n",
    "print(\"Loading test data...\")\n",
    "df = pd.read_parquet(os.path.join(DATA_FOLDER, \"cleaned_data_df.parquet\"))\n",
    "print(f\"Loaded {len(df):,} test examples\")\n",
    "\n",
    "# =========================\n",
    "# LOAD TRAINED MODEL\n",
    "# =========================\n",
    "# Load the best model checkpoint from the models folder\n",
    "# Use the same model ID that was generated during training\n",
    "\n",
    "# Model hyperparameters (must match training)\n",
    "EMB_DIM = 16\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "EPOCHS = 35\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Generate the same model ID\n",
    "model_id = generate_model_id(EMB_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT, EPOCHS, BATCH_SIZE, LR, WEIGHT_DECAY)\n",
    "\n",
    "# Load checkpoint\n",
    "loaded = load_model_checkpoint(model_id, models_folder=MODELS_FOLDER)\n",
    "if loaded is None:\n",
    "    raise FileNotFoundError(f\"Model checkpoint not found. Please train the model first (model_id: {model_id})\")\n",
    "\n",
    "stoi, itos = loaded[\"stoi\"], loaded[\"itos\"]\n",
    "model = BiLSTMBoundary(vocab_size=len(itos), emb_dim=EMB_DIM, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS)\n",
    "model.load_state_dict(loaded[\"model_state\"])\n",
    "model.eval()\n",
    "print(\"Model loaded successfully for evaluation.\")\n",
    "\n",
    "# =========================\n",
    "# EVALUATION HELPER FUNCTIONS\n",
    "# =========================\n",
    "# Functions for predicting boundaries and evaluating segmentation accuracy\n",
    "\n",
    "def predict_boundaries(words, model, stoi, threshold=0.5):\n",
    "    model.eval()\n",
    "    char_lists = [list(w) for w in words]\n",
    "    x_ids = [[stoi.get(c, stoi[\"<UNK>\"]) for c in chars] for chars in char_lists]\n",
    "    lengths = [len(x) for x in x_ids]\n",
    "    maxlen = max(lengths)\n",
    "    pad_id = stoi[\"<PAD>\"]\n",
    "\n",
    "    x_pad = [xi + [pad_id] * (maxlen - len(xi)) for xi in x_ids]\n",
    "    mask = [[1] * len(xi) + [0] * (maxlen - len(xi)) for xi in x_ids]\n",
    "\n",
    "    x = torch.LongTensor(x_pad)\n",
    "    lengths_t = torch.LongTensor(lengths)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x, lengths_t)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= threshold)\n",
    "    out = []\n",
    "    for i, L in enumerate(lengths):\n",
    "        out.append(preds[i, :L].int().tolist())\n",
    "    return out\n",
    "\n",
    "def apply_boundaries(word, boundary_labels):\n",
    "    segs = []\n",
    "    start = 0\n",
    "    for i, b in enumerate(boundary_labels):\n",
    "        if b == 1:\n",
    "            segs.append(word[start:i+1])\n",
    "            start = i+1\n",
    "    if start < len(word):\n",
    "        segs.append(word[start:])\n",
    "    return segs\n",
    "\n",
    "\n",
    "# =========================\n",
    "# EVALUATION METRICS FUNCTIONS\n",
    "# =========================\n",
    "# Functions to compute various evaluation metrics for morphological segmentation\n",
    "\n",
    "def is_correct_prediction(predicted, gold_variants):\n",
    "    \"\"\"\n",
    "    Check if predicted segmentation exactly matches any gold variant.\n",
    "    \n",
    "    Args:\n",
    "        predicted: List of predicted morphemes\n",
    "        gold_variants: List of gold segmentation variants\n",
    "    \n",
    "    Returns:\n",
    "        True if prediction matches any gold variant, False otherwise\n",
    "    \"\"\"\n",
    "    return any(predicted == variant for variant in gold_variants)\n",
    "\n",
    "def boundary_positions_from_labels(labels):\n",
    "    \"\"\"\n",
    "    Convert per-char boundary labels (length L) into boundary positions\n",
    "    at indices 0..L-2 (between characters). We ignore any label at the last index.\n",
    "    \"\"\"\n",
    "    if not labels:\n",
    "        return set()\n",
    "    L = len(labels)\n",
    "    return {i for i in range(min(L-1, len(labels))) if labels[i] == 1}\n",
    "\n",
    "def boundary_positions_from_segments(segments):\n",
    "    \"\"\"\n",
    "    Convert a list of segments into boundary positions (end-of-segment indices)\n",
    "    excluding the final segment end.\n",
    "    \"\"\"\n",
    "    pos = set()\n",
    "    acc = 0\n",
    "    for k, seg in enumerate(segments):\n",
    "        acc += len(seg)\n",
    "        if k < len(segments) - 1:\n",
    "            pos.add(acc - 1)  # boundary after this segment at index acc-1\n",
    "    return pos\n",
    "\n",
    "def prf_from_sets(pred_set, gold_set):\n",
    "    tp = len(pred_set & gold_set)\n",
    "    fp = len(pred_set - gold_set)\n",
    "    fn = len(gold_set - pred_set)\n",
    "    # Precision, recall, F1 with safe 0/0 handling (define as 1.0 when both empty)\n",
    "    if tp + fp == 0:\n",
    "        precision = 1.0 if tp + fp + fn == 0 else 0.0\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "    if tp + fn == 0:\n",
    "        recall = 1.0 if tp + fp + fn == 0 else 0.0\n",
    "    else:\n",
    "        recall = tp / (tp + fn)\n",
    "    if precision + recall == 0:\n",
    "        f1 = 1.0 if tp + fp + fn == 0 else 0.0\n",
    "    else:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    return tp, fp, fn, precision, recall, f1\n",
    "\n",
    "def best_variant_metrics(pred_boundaries, gold_variants):\n",
    "    \"\"\"\n",
    "    Among multiple gold segmentations (variants), pick the one that maximizes F1.\n",
    "    Returns: (best_gold_boundaries, tp, fp, fn, P, R, F1)\n",
    "    \"\"\"\n",
    "    best = None\n",
    "    for variant in gold_variants:\n",
    "        gold_b = boundary_positions_from_segments(variant)\n",
    "        tp, fp, fn, P, R, F1 = prf_from_sets(pred_boundaries, gold_b)\n",
    "        key = (F1, tp, -fn, -fp)  # tie-breakers\n",
    "        if (best is None) or (key > best[0]):\n",
    "            best = (key, gold_b, tp, fp, fn, P, R, F1)\n",
    "    # If no variants (shouldn't happen after your cleaning), fall back to empty\n",
    "    if best is None:\n",
    "        gold_b = set()\n",
    "        tp, fp, fn, P, R, F1 = prf_from_sets(pred_boundaries, gold_b)\n",
    "        return gold_b, tp, fp, fn, P, R, F1\n",
    "    _, gold_b, tp, fp, fn, P, R, F1 = best\n",
    "    return gold_b, tp, fp, fn, P, R, F1\n",
    "\n",
    "def normalize_gold_variants(gold_variants):\n",
    "    \"\"\"\n",
    "    Convert gold_variants to a list format, handling numpy arrays and nested structures.\n",
    "    \"\"\"\n",
    "    if gold_variants is None:\n",
    "        return []\n",
    "    \n",
    "    # If it's a numpy array, convert to list\n",
    "    if isinstance(gold_variants, np.ndarray):\n",
    "        gold_variants = gold_variants.tolist()\n",
    "    \n",
    "    # If it's already a list, ensure nested elements are also lists (not numpy arrays)\n",
    "    if isinstance(gold_variants, list):\n",
    "        normalized = []\n",
    "        for variant in gold_variants:\n",
    "            if isinstance(variant, np.ndarray):\n",
    "                normalized.append(variant.tolist())\n",
    "            elif isinstance(variant, list):\n",
    "                # Recursively normalize nested lists\n",
    "                normalized.append([item.tolist() if isinstance(item, np.ndarray) else item for item in variant])\n",
    "            else:\n",
    "                normalized.append(variant)\n",
    "        return normalized\n",
    "    \n",
    "    return []\n",
    "\n",
    "# =========================\n",
    "# EVALUATION ON TEST SET\n",
    "# =========================\n",
    "# Predict boundaries for all test words and compute evaluation metrics\n",
    "\n",
    "# Batch predict boundaries for all test words\n",
    "all_words = df[\"Word\"].tolist()\n",
    "all_boundaries = predict_boundaries(all_words, model, stoi, threshold=0.5)\n",
    "\n",
    "# Initialize metrics accumulators\n",
    "results = []\n",
    "micro_tp = micro_fp = micro_fn = 0  # Micro-averaged metrics (global counts)\n",
    "macro_Ps, macro_Rs, macro_F1s = [], [], []  # Macro-averaged metrics (per-word averages)\n",
    "\n",
    "# Evaluate each word\n",
    "for word, gold_variants, boundary_labels in zip(all_words, df[\"Gold\"], all_boundaries):\n",
    "    # Normalize gold_variants (convert numpy arrays to lists)\n",
    "    gold_variants = normalize_gold_variants(gold_variants)\n",
    "\n",
    "    # Per-word predicted boundaries from labels (ignore last index)\n",
    "    pred_b = boundary_positions_from_labels(boundary_labels)\n",
    "    # Choose the best gold variant for boundary comparison\n",
    "    gold_b, tp, fp, fn, P, R, F1 = best_variant_metrics(pred_b, gold_variants)\n",
    "\n",
    "    # Also compute the segmentation strings (as you had) for the exact-match accuracy\n",
    "    predicted_segments = apply_boundaries(word, boundary_labels)\n",
    "    correct = is_correct_prediction(predicted_segments, gold_variants)\n",
    "\n",
    "    results.append({\n",
    "        \"Word\": word,\n",
    "        \"Prediction\": predicted_segments,\n",
    "        \"Gold\": gold_variants,\n",
    "        \"PredBoundaries\": sorted(pred_b),\n",
    "        \"GoldBoundaries(Chosen)\": sorted(gold_b),\n",
    "        \"TP\": tp, \"FP\": fp, \"FN\": fn,\n",
    "        \"P_word\": P, \"R_word\": R, \"F1_word\": F1,\n",
    "        \"CorrectExactSeg\": correct\n",
    "    })\n",
    "\n",
    "    micro_tp += tp\n",
    "    micro_fp += fp\n",
    "    micro_fn += fn\n",
    "    macro_Ps.append(P)\n",
    "    macro_Rs.append(R)\n",
    "    macro_F1s.append(F1)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Exact segmentation accuracy (same as before)\n",
    "accuracy = results_df[\"CorrectExactSeg\"].mean()\n",
    "\n",
    "# Micro metrics (global)\n",
    "if micro_tp + micro_fp == 0:\n",
    "    P_micro = 1.0 if micro_tp + micro_fn == 0 else 0.0\n",
    "else:\n",
    "    P_micro = micro_tp / (micro_tp + micro_fp)\n",
    "if micro_tp + micro_fn == 0:\n",
    "    R_micro = 1.0 if micro_tp + micro_fp == 0 else 0.0\n",
    "else:\n",
    "    R_micro = micro_tp / (micro_tp + micro_fn)\n",
    "if P_micro + R_micro == 0:\n",
    "    F1_micro = 1.0 if (micro_tp + micro_fp + micro_fn) == 0 else 0.0\n",
    "else:\n",
    "    F1_micro = 2 * P_micro * R_micro / (P_micro + R_micro)\n",
    "\n",
    "# Macro metrics (average of per-word scores)\n",
    "P_macro = float(pd.Series(macro_Ps).mean()) if macro_Ps else 0.0\n",
    "R_macro = float(pd.Series(macro_Rs).mean()) if macro_Rs else 0.0\n",
    "F1_macro = float(pd.Series(macro_F1s).mean()) if macro_F1s else 0.0\n",
    "\n",
    "print(f\"Exact segmentation accuracy: {accuracy:.4f}\")\n",
    "print(\"Boundary metrics:\")\n",
    "print(f\"  Micro  - P: {P_micro:.4f}  R: {R_micro:.4f}  F1: {F1_micro:.4f}\")\n",
    "print(f\"  Macro  - P: {P_macro:.4f}  R: {R_macro:.4f}  F1: {F1_macro:.4f}\")\n",
    "\n",
    "# =========================\n",
    "# SPLIT-COUNT ACCURACY METRICS\n",
    "# =========================\n",
    "# Additional metrics that measure how close the predicted number of morphemes\n",
    "# is to the gold standard, even if the exact segmentation differs\n",
    "\n",
    "def split_count_metrics(predicted_segments, gold_variants):\n",
    "    \"\"\"\n",
    "    Compute split-count accuracy variants:\n",
    "    - Exact: same number of morphemes as any gold variant\n",
    "    - +1: one more split than any gold variant\n",
    "    - -1: one fewer split than any gold variant\n",
    "    - ±1: difference ≤ 1 with any gold variant\n",
    "    \"\"\"\n",
    "    pred_count = len(predicted_segments)\n",
    "    gold_counts = [len(gold) for gold in gold_variants]\n",
    "\n",
    "    exact = any(pred_count == g for g in gold_counts)\n",
    "    plus1 = any(pred_count == g + 1 for g in gold_counts)\n",
    "    minus1 = any(pred_count == g - 1 for g in gold_counts)\n",
    "    pm1 = any(abs(pred_count - g) <= 1 for g in gold_counts)\n",
    "\n",
    "    return {\"Exact\": exact, \"+1\": plus1, \"-1\": minus1, \"±1\": pm1}\n",
    "\n",
    "\n",
    "# ---- Extend results with split metrics ----\n",
    "split_exact_flags = []\n",
    "split_plus1_flags = []\n",
    "split_minus1_flags = []\n",
    "split_pm1_flags = []\n",
    "overlap_flags = []\n",
    "\n",
    "for rec in results:\n",
    "    predicted_segments = rec[\"Prediction\"]\n",
    "    gold_variants = rec[\"Gold\"]\n",
    "\n",
    "    # Normalize gold_variants (convert numpy arrays to lists)\n",
    "    gold_variants = normalize_gold_variants(gold_variants)\n",
    "\n",
    "    split_metrics = split_count_metrics(predicted_segments, gold_variants)\n",
    "    rec[\"CorrectSplitCount\"] = split_metrics[\"Exact\"]\n",
    "    rec[\"SplitCount+1\"] = split_metrics[\"+1\"]\n",
    "    rec[\"SplitCount-1\"] = split_metrics[\"-1\"]\n",
    "    rec[\"SplitCount±1\"] = split_metrics[\"±1\"]\n",
    "\n",
    "    # Overlap between exact segmentation and correct split-count\n",
    "    overlap = rec[\"CorrectExactSeg\"] and split_metrics[\"Exact\"]\n",
    "    rec[\"OverlapExactAndSplit\"] = overlap\n",
    "\n",
    "    split_exact_flags.append(split_metrics[\"Exact\"])\n",
    "    split_plus1_flags.append(split_metrics[\"+1\"])\n",
    "    split_minus1_flags.append(split_metrics[\"-1\"])\n",
    "    split_pm1_flags.append(split_metrics[\"±1\"])\n",
    "    overlap_flags.append(overlap)\n",
    "\n",
    "\n",
    "# ---- Aggregate metrics ----\n",
    "split_exact_acc = np.mean(split_exact_flags)\n",
    "split_plus1_acc = np.mean(split_plus1_flags)\n",
    "split_minus1_acc = np.mean(split_minus1_flags)\n",
    "split_pm1_acc = np.mean(split_pm1_flags)\n",
    "overlap_accuracy = np.mean(overlap_flags)\n",
    "\n",
    "# ---- Print summary ----\n",
    "print(\"\\n=== Split-count metrics ===\")\n",
    "print(f\"Split-count (Exact):          {split_exact_acc:.4f}\")\n",
    "print(f\"Split-count (+1):             {split_plus1_acc:.4f}\")\n",
    "print(f\"Split-count (−1):             {split_minus1_acc:.4f}\")\n",
    "print(f\"Split-count (±1):             {split_pm1_acc:.4f}\")\n",
    "print(f\"Overlap (Exact ∩ Split):      {overlap_accuracy:.4f}\")\n",
    "\n",
    "# ---- Save updated results ----\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# SAVE EVALUATION RESULTS\n",
    "# =========================\n",
    "# Save evaluation results to the data folder with a descriptive filename\n",
    "results_output_path = os.path.join(DATA_FOLDER, \"bilstm_eval_results.csv\")\n",
    "results_df.to_csv(results_output_path, index=False)\n",
    "print(f\"\\nEvaluation results saved to {results_output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
