{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b9ebff",
   "metadata": {},
   "source": [
    "# DT-LSTM-Markov Filter: Quechua Morphology Parser\n",
    "\n",
    "Morphological segmentation for Quechua using:\n",
    "- BiLSTM for boundary prediction\n",
    "- Decision Tree priors from token-window features\n",
    "- K-teacher regularization\n",
    "\n",
    "Unlike the HMM variant, this uses Decision Trees trained on local context features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "184db355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "import math\n",
    "import hashlib\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Set, Tuple\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ML & DL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold, GroupShuffleSplit\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93937abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_FOLDER = \"data\"\n",
    "MODEL_NAME = \"DT-LSTM-MarkovFilter\"\n",
    "MODELS_FOLDER = f\"models_{MODEL_NAME}\"\n",
    "os.makedirs(MODELS_FOLDER, exist_ok=True)\n",
    "\n",
    "# Random seeds\n",
    "RANDOM_STATE = 42\n",
    "RNG = 42\n",
    "torch.manual_seed(RNG)\n",
    "np.random.seed(RNG)\n",
    "\n",
    "# Constants\n",
    "END_LABEL = \"Ø\"\n",
    "VOWELS = set(list(\"aeiou\"))\n",
    "\n",
    "# Feature columns used for privileged knowledge\n",
    "NEW_NUM_FEATS = [\n",
    "    \"Word_len\", \"Vowel_no\", \"Cons_no\",\n",
    "    \"Tail_cons_no\", \"Tail_vowel_no\",\n",
    "    \"No_splits\", \"YW_count\", \"Tail_YW_count\"\n",
    "]\n",
    "\n",
    "# Quechua graphemes for tokenization\n",
    "graphemes = [\n",
    "    \"ch\", \"ll\", \"rr\", \"tr\", \"kw\", \"ph\",\n",
    "    \"a\", \"b\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"k\", \"l\", \"m\", \"n\", \"ñ\", \"o\", \"p\", \"q\",\n",
    "    \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d482bdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading gold data...\n",
      "got 6,896 gold examples\n"
     ]
    }
   ],
   "source": [
    "# Load the gold standard segmentations\n",
    "print(\"loading gold data...\")\n",
    "gold_df = pd.read_parquet(os.path.join(DATA_FOLDER, \"Sue_kalt.parquet\"))\n",
    "gold_df['Word'] = gold_df['word']\n",
    "gold_df['morph'] = gold_df['morph'].str.replace('-', ' ')\n",
    "gold_df['Morph_split_str'] = gold_df['morph']\n",
    "gold_df['Morph_split'] = gold_df['morph'].str.split(' ')\n",
    "gold_df = gold_df[['Word', 'Morph_split', 'Morph_split_str']]\n",
    "gold_df.drop_duplicates(subset='Word', keep='first', inplace=True)\n",
    "gold_df.dropna(subset=['Word'], inplace=True)\n",
    "print(f\"got {len(gold_df):,} gold examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "779fedd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET SUMMARY\n",
      "============================================================\n",
      "training: (6896, 3)\n",
      "test: (913, 5)\n",
      "models folder: models_DT-LSTM-MarkovFilter\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load test set\n",
    "acc_df = pd.read_parquet(os.path.join(DATA_FOLDER, \"cleaned_data_df.parquet\"))\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"training: {gold_df.shape}\")\n",
    "print(f\"test: {acc_df.shape}\")\n",
    "print(f\"models folder: {MODELS_FOLDER}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a35e8a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"|\".join(sorted(graphemes, key=len, reverse=True)))\n",
    "\n",
    "def tokenize_morphemes(morphs):\n",
    "    \"\"\"Break morphemes into grapheme tokens.\"\"\"\n",
    "    return [pattern.findall(m.lower()) for m in morphs]\n",
    "\n",
    "gold_df[\"Char_split\"] = gold_df[\"Morph_split\"].apply(tokenize_morphemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ec1479",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels_set = {\"a\", \"i\", \"e\", \"o\", \"u\"}\n",
    "\n",
    "def grapheme_to_cv(grapheme):\n",
    "    return \"V\" if grapheme in vowels_set else \"C\"\n",
    "\n",
    "def morphs_to_cv(morphs):\n",
    "    \"\"\"Convert grapheme lists to CV patterns.\"\"\"\n",
    "    return [[grapheme_to_cv(g) for g in morph] for morph in morphs]\n",
    "\n",
    "gold_df[\"CV_split\"] = gold_df[\"Char_split\"].apply(morphs_to_cv)\n",
    "\n",
    "def cv_to_string(cv_split):\n",
    "    \"\"\"Turn nested CV list into dash-separated string.\"\"\"\n",
    "    return \"-\".join(\"\".join(m) for m in cv_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44db416e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full_chain</th>\n",
       "      <th>Trimmed_chain</th>\n",
       "      <th>Word</th>\n",
       "      <th>Char_split</th>\n",
       "      <th>Morph_split</th>\n",
       "      <th>Word_len</th>\n",
       "      <th>Vowel_no</th>\n",
       "      <th>Cons_no</th>\n",
       "      <th>Tail_cons_no</th>\n",
       "      <th>Tail_vowel_no</th>\n",
       "      <th>No_splits</th>\n",
       "      <th>YW_count</th>\n",
       "      <th>Tail_YW_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VCVCCVCVV-CVC</td>\n",
       "      <td>CVC</td>\n",
       "      <td>cementerioman</td>\n",
       "      <td>[[e, m, e, n, t, e, r, i, o], [m, a, n]]</td>\n",
       "      <td>[cementerio, man]</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVCCV-CCV-CV-C-CV</td>\n",
       "      <td>CCV-CV-C-CV</td>\n",
       "      <td>kawsachkananta</td>\n",
       "      <td>[[k, a, w, s, a], [ch, k, a], [n, a], [n], [t,...</td>\n",
       "      <td>[kawsa, chka, na, n, ta]</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVCV-CV-C-CVC</td>\n",
       "      <td>CV-C-CVC</td>\n",
       "      <td>mañakunpis</td>\n",
       "      <td>[[m, a, ñ, a], [k, u], [n], [p, i, s]]</td>\n",
       "      <td>[maña, ku, n, pis]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VCVCCV-CV-CVC</td>\n",
       "      <td>CV-CVC</td>\n",
       "      <td>imaynapichus</td>\n",
       "      <td>[[i, m, a, y, n, a], [p, i], [ch, u, s]]</td>\n",
       "      <td>[imayna, pi, chus]</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CVCV-CVC</td>\n",
       "      <td>CVC</td>\n",
       "      <td>qipiyuq</td>\n",
       "      <td>[[q, i, p, i], [y, u, q]]</td>\n",
       "      <td>[qipi, yuq]</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Full_chain Trimmed_chain            Word  \\\n",
       "0      VCVCCVCVV-CVC           CVC   cementerioman   \n",
       "1  CVCCV-CCV-CV-C-CV   CCV-CV-C-CV  kawsachkananta   \n",
       "2      CVCV-CV-C-CVC      CV-C-CVC      mañakunpis   \n",
       "3      VCVCCV-CV-CVC        CV-CVC    imaynapichus   \n",
       "4           CVCV-CVC           CVC         qipiyuq   \n",
       "\n",
       "                                          Char_split  \\\n",
       "0           [[e, m, e, n, t, e, r, i, o], [m, a, n]]   \n",
       "1  [[k, a, w, s, a], [ch, k, a], [n, a], [n], [t,...   \n",
       "2             [[m, a, ñ, a], [k, u], [n], [p, i, s]]   \n",
       "3           [[i, m, a, y, n, a], [p, i], [ch, u, s]]   \n",
       "4                          [[q, i, p, i], [y, u, q]]   \n",
       "\n",
       "                Morph_split  Word_len  Vowel_no  Cons_no  Tail_cons_no  \\\n",
       "0         [cementerio, man]        13         6        6             2   \n",
       "1  [kawsa, chka, na, n, ta]        14         5        8             5   \n",
       "2        [maña, ku, n, pis]        10         4        6             4   \n",
       "3        [imayna, pi, chus]        12         5        6             3   \n",
       "4               [qipi, yuq]         7         3        4             2   \n",
       "\n",
       "   Tail_vowel_no  No_splits  YW_count  Tail_YW_count  \n",
       "0              1          2         0              0  \n",
       "1              3          5         1              0  \n",
       "2              2          4         0              0  \n",
       "3              2          3         1              0  \n",
       "4              1          2         1              1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the feature dataframe\n",
    "str_df = pd.DataFrame()\n",
    "str_df[\"Full_chain\"] = gold_df[\"CV_split\"].apply(cv_to_string)\n",
    "str_df[\"Trimmed_chain\"] = str_df[\"Full_chain\"].apply(\n",
    "    lambda x: x.split(\"-\", 1)[1] if \"-\" in x else np.nan\n",
    ")\n",
    "str_df[\"Word\"] = gold_df[\"Word\"]\n",
    "str_df[\"Char_split\"] = gold_df[\"Char_split\"]\n",
    "str_df[\"Morph_split\"] = gold_df[\"Morph_split\"]\n",
    "str_df = str_df.dropna(subset=[\"Trimmed_chain\"]).reset_index(drop=True)\n",
    "\n",
    "# Numeric features\n",
    "str_df[\"Word_len\"] = str_df[\"Word\"].str.len()\n",
    "str_df[\"Vowel_no\"] = str_df[\"Full_chain\"].str.count(\"V\")\n",
    "str_df[\"Cons_no\"] = str_df[\"Full_chain\"].str.count(\"C\")\n",
    "str_df[\"Tail_cons_no\"] = str_df[\"Trimmed_chain\"].str.count(\"C\")\n",
    "str_df[\"Tail_vowel_no\"] = str_df[\"Trimmed_chain\"].str.count(\"V\")\n",
    "str_df[\"No_splits\"] = str_df[\"Morph_split\"].str.len()\n",
    "str_df[\"YW_count\"] = str_df[\"Word\"].str.count(\"[yw]\")\n",
    "str_df[\"Tail_YW_count\"] = str_df[\"Morph_split\"].apply(\n",
    "    lambda ms: sum(m.count(\"y\") + m.count(\"w\") for m in ms[1:])\n",
    ")\n",
    "\n",
    "str_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88953c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_literal_list(obj):\n",
    "    \"\"\"Parse string list representation to actual list.\"\"\"\n",
    "    if isinstance(obj, list):\n",
    "        return obj\n",
    "    if pd.isna(obj):\n",
    "        return None\n",
    "    s = str(obj).strip()\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def flatten_char_split(char_split):\n",
    "    \"\"\"Flatten list-of-lists into single list.\"\"\"\n",
    "    if not isinstance(char_split, list):\n",
    "        return None\n",
    "    out = []\n",
    "    for seg in char_split:\n",
    "        if isinstance(seg, list):\n",
    "            out.extend([str(x) for x in seg])\n",
    "        else:\n",
    "            out.append(str(seg))\n",
    "    return out\n",
    "\n",
    "def tokens_to_word(tokens):\n",
    "    \"\"\"Join tokens to surface word.\"\"\"\n",
    "    if not tokens:\n",
    "        return \"\"\n",
    "    return \"\".join(tokens)\n",
    "\n",
    "def split_chain(chain: str):\n",
    "    if chain is None:\n",
    "        return []\n",
    "    s = str(chain).strip()\n",
    "    return [] if not s else s.split('-')\n",
    "\n",
    "def extract_root_and_trimmed(full_chain: str):\n",
    "    segs = split_chain(full_chain)\n",
    "    if not segs:\n",
    "        return \"\", END_LABEL\n",
    "    root = segs[0]\n",
    "    trimmed = '-'.join(segs[1:]) if len(segs) > 1 else END_LABEL\n",
    "    return root, trimmed\n",
    "\n",
    "def suffixes_from_trimmed(trimmed: str):\n",
    "    if trimmed is None or trimmed == END_LABEL or str(trimmed).strip() == \"\":\n",
    "        return []\n",
    "    return str(trimmed).split('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a98d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_cv_features(root_cv: str):\n",
    "    s = root_cv or \"\"\n",
    "    L = len(s)\n",
    "    feats = {\n",
    "        \"root_cv\": s,\n",
    "        \"root_len\": L,\n",
    "        \"root_end\": s[-1:] if L else \"\",\n",
    "        \"root_start\": s[:1] if L else \"\",\n",
    "        \"root_suffix2\": s[-2:] if L >= 2 else s,\n",
    "        \"root_prefix2\": s[:2] if L >= 2 else s,\n",
    "        \"num_C\": s.count('C'),\n",
    "        \"num_V\": s.count('V'),\n",
    "        \"has_CC\": int('CC' in s),\n",
    "        \"has_VV\": int('VV' in s),\n",
    "    }\n",
    "    for i in range(L-1):\n",
    "        feats[f\"bg_{s[i:i+2]}\"] = 1\n",
    "    for i in range(L-2):\n",
    "        feats[f\"tg_{s[i:i+3]}\"] = 1\n",
    "    return feats\n",
    "\n",
    "def last_char_features(word: str, k_chars=(1,2,3)):\n",
    "    feats = {}\n",
    "    if not word:\n",
    "        return feats\n",
    "    w = word\n",
    "    for k in k_chars:\n",
    "        s = w[-k:] if len(w) >= k else w\n",
    "        feats[f\"last{k}\"] = s\n",
    "    last = w[-1]\n",
    "    feats[\"last_is_vowel\"] = int(last in VOWELS)\n",
    "    feats[\"last_char\"] = last\n",
    "    last_vowel = ''\n",
    "    for ch in reversed(w):\n",
    "        if ch in VOWELS:\n",
    "            last_vowel = ch.lower()\n",
    "            break\n",
    "    feats[\"last_vowel\"] = last_vowel\n",
    "    return feats\n",
    "\n",
    "def last_cluster_features(char_tokens: list, k_clusters=(1,2)):\n",
    "    feats = {}\n",
    "    if not char_tokens:\n",
    "        return feats\n",
    "    toks = char_tokens\n",
    "    for k in k_clusters:\n",
    "        tail = toks[-k:] if len(toks) >= k else toks\n",
    "        feats[f\"lastTok{k}\"] = \"|\".join(tail)\n",
    "    feats[\"lastTok1\"] = toks[-1]\n",
    "    return feats\n",
    "\n",
    "def cv_tail_features(word: str):\n",
    "    \"\"\"Approximate CV tail from raw word.\"\"\"\n",
    "    if not word:\n",
    "        return {}\n",
    "    def cv(c):\n",
    "        return 'V' if c in VOWELS else 'C'\n",
    "    tail_cv = ''.join(cv(ch) for ch in word[-3:])\n",
    "    return {\"tail_cv_approx\": tail_cv, \"tail_last_cv\": tail_cv[-1:]}\n",
    "\n",
    "def build_features_row(row):\n",
    "    \"\"\"Build feature dict from a dataframe row.\"\"\"\n",
    "    feats = {}\n",
    "    feats.update(root_cv_features(row.get(\"root_cv\", \"\")))\n",
    "\n",
    "    word = \"\"\n",
    "    char_tokens = None\n",
    "\n",
    "    if \"Char_split\" in row and row[\"Char_split\"] is not None:\n",
    "        cs = safe_literal_list(row[\"Char_split\"])\n",
    "        toks = flatten_char_split(cs) if cs is not None else None\n",
    "        char_tokens = toks\n",
    "        word = tokens_to_word(toks) if toks else \"\"\n",
    "    elif \"Word\" in row and pd.notna(row.get(\"Word\", None)):\n",
    "        word = str(row[\"Word\"])\n",
    "    else:\n",
    "        word = \"\"\n",
    "\n",
    "    feats.update(last_char_features(word, k_chars=(1,2,3)))\n",
    "    if char_tokens:\n",
    "        feats.update(last_cluster_features(char_tokens, k_clusters=(1,2)))\n",
    "    feats.update(cv_tail_features(word))\n",
    "\n",
    "    # Numeric features\n",
    "    for k in NEW_NUM_FEATS:\n",
    "        if k in row and pd.notna(row[k]):\n",
    "            try:\n",
    "                feats[k] = float(row[k])\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bdb639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(df_in: pd.DataFrame):\n",
    "    rows = []\n",
    "    for _, r in df_in.iterrows():\n",
    "        full = r['Full_chain']\n",
    "        root, trimmed_auto = extract_root_and_trimmed(full)\n",
    "        trimmed = r['Trimmed_chain'] if 'Trimmed_chain' in df_in.columns and pd.notna(r['Trimmed_chain']) else trimmed_auto\n",
    "        suffixes = suffixes_from_trimmed(trimmed)\n",
    "\n",
    "        row = {\n",
    "            \"full_chain\": full,\n",
    "            \"root_cv\": root,\n",
    "            \"trimmed\": trimmed if trimmed else END_LABEL,\n",
    "            \"suffixes\": suffixes,\n",
    "            \"suffix_len\": len(suffixes),\n",
    "        }\n",
    "        for opt in (\"Word\", \"Char_split\", \"CV_split\"):\n",
    "            if opt in df_in.columns:\n",
    "                row[opt] = r[opt]\n",
    "\n",
    "        for k in NEW_NUM_FEATS:\n",
    "            if k in df_in.columns:\n",
    "                row[k] = r[k]\n",
    "\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def dicts_from_df(df: pd.DataFrame, add_prev=None):\n",
    "    \"\"\"Turn rows into feature dicts.\"\"\"\n",
    "    feat_dicts = []\n",
    "    for _, r in df.iterrows():\n",
    "        base = build_features_row(r)\n",
    "        if add_prev:\n",
    "            for k in add_prev:\n",
    "                if k in r and pd.notna(r[k]):\n",
    "                    base[k] = r[k]\n",
    "        feat_dicts.append(base)\n",
    "    return feat_dicts\n",
    "\n",
    "def vec_fit_transform(feat_dicts):\n",
    "    vec = DictVectorizer(sparse=True)\n",
    "    X = vec.fit_transform(feat_dicts)\n",
    "    return X, vec\n",
    "\n",
    "def vec_transform(vec, feat_dicts):\n",
    "    return vec.transform(feat_dicts)\n",
    "\n",
    "def grouped_split(df, train_size=0.8, seed=RANDOM_STATE):\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=train_size, random_state=seed)\n",
    "    groups = df['root_cv'].astype(str).values\n",
    "    tr_idx, te_idx = next(gss.split(df, groups=groups))\n",
    "    return df.iloc[tr_idx].reset_index(drop=True), df.iloc[te_idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14b18444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topN_labels_by_freq(y, Ns=(16,25,37,57,103)):\n",
    "    ctr = Counter(y)\n",
    "    most_common = ctr.most_common()\n",
    "    return {N: set([lab for lab,_ in most_common[:N]]) for N in Ns}, ctr\n",
    "\n",
    "def eval_subsets(y_true, y_pred, labels_by_topN):\n",
    "    out = {}\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    for N, labelset in labels_by_topN.items():\n",
    "        idx = [i for i,lab in enumerate(y_true) if lab in labelset]\n",
    "        if not idx:\n",
    "            out[N] = {\"accuracy\": np.nan, \"f1_macro\": np.nan, \"f1_weighted\": np.nan, \"support\": 0}\n",
    "            continue\n",
    "        yt, yp = y_true[idx], y_pred[idx]\n",
    "        out[N] = {\n",
    "            \"accuracy\": accuracy_score(yt, yp),\n",
    "            \"f1_macro\": f1_score(yt, yp, average='macro', zero_division=0),\n",
    "            \"f1_weighted\": f1_score(yt, yp, average='weighted', zero_division=0),\n",
    "            \"support\": len(idx),\n",
    "        }\n",
    "    return out\n",
    "\n",
    "def print_subset_metrics(name, d):\n",
    "    print(f\"\\n== {name}: Top-N subsets ==\")\n",
    "    for N in sorted(d.keys()):\n",
    "        m = d[N]\n",
    "        print(f\"Top-{N:>3} (n={m['support']:>4}): Acc={m['accuracy']:.3f} | F1_mac={m['f1_macro']:.3f} | F1_wt={m['f1_weighted']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a848c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classifier(kind=\"tree\", **kwargs):\n",
    "    if kind == \"rf\":\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=80, max_depth=10, min_samples_leaf=5,\n",
    "            random_state=RANDOM_STATE, n_jobs=-1\n",
    "        )\n",
    "    return DecisionTreeClassifier(\n",
    "        criterion=\"entropy\",\n",
    "        max_depth=kwargs.get(\"max_depth\", 6),\n",
    "        min_samples_leaf=kwargs.get(\"min_samples_leaf\", 10),\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "def run_single_shot(df_all, clf_kind=\"tree\"):\n",
    "    df_tr, df_te = grouped_split(df_all, train_size=0.8)\n",
    "    Xtr_dicts = dicts_from_df(df_tr)\n",
    "    Xtr, vec = vec_fit_transform(Xtr_dicts)\n",
    "    ytr = df_tr['trimmed'].astype(str).values\n",
    "\n",
    "    clf = make_classifier(clf_kind)\n",
    "    clf.fit(Xtr, ytr)\n",
    "\n",
    "    Xte = vec_transform(vec, dicts_from_df(df_te))\n",
    "    yte = df_te['trimmed'].astype(str).values\n",
    "    yhat = clf.predict(Xte)\n",
    "\n",
    "    acc = accuracy_score(yte, yhat)\n",
    "    f1m = f1_score(yte, yhat, average='macro', zero_division=0)\n",
    "    f1w = f1_score(yte, yhat, average='weighted', zero_division=0)\n",
    "\n",
    "    print(\"=== single-shot classifier ===\")\n",
    "    print(f\"test: acc={acc:.3f} | F1_macro={f1m:.3f} | F1_weighted={f1w:.3f}\")\n",
    "\n",
    "    labels_by_topN, _ = topN_labels_by_freq(df_tr['trimmed'].astype(str).values)\n",
    "    subset = eval_subsets(yte, yhat, labels_by_topN)\n",
    "    print_subset_metrics(\"single-shot\", subset)\n",
    "\n",
    "    if (\"Word\" not in df_all.columns) and (\"Char_split\" not in df_all.columns):\n",
    "        print(\"\\n[warn] no Word/Char_split columns - using root-only features\")\n",
    "\n",
    "    return {\"clf\": clf, \"vec\": vec, \"test_df\": df_te, \"test_pred\": yhat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdf005b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_length_classifier(df_tr, clf_kind=\"tree\"):\n",
    "    ylen = []\n",
    "    for n in df_tr['suffix_len'].values:\n",
    "        ylen.append(str(n) if n in (1,2,3) else \"4+\")\n",
    "    ylen = np.array(ylen)\n",
    "\n",
    "    X_dicts = dicts_from_df(df_tr)\n",
    "    X, vec = vec_fit_transform(X_dicts)\n",
    "    clf = make_classifier(clf_kind, max_depth=5, min_samples_leaf=10)\n",
    "    clf.fit(X, ylen)\n",
    "    return clf, vec\n",
    "\n",
    "def make_step_frame(df, step):\n",
    "    y = []\n",
    "    for sufs in df['suffixes']:\n",
    "        if len(sufs) >= step:\n",
    "            y.append(sufs[-step])\n",
    "        else:\n",
    "            y.append(END_LABEL)\n",
    "    df2 = df.copy()\n",
    "    df2[f\"y_step{step}\"] = y\n",
    "    return df2\n",
    "\n",
    "def run_sequential(df_all, clf_kind=\"tree\", max_steps_cap=5):\n",
    "    df_tr, df_te = grouped_split(df_all, train_size=0.8)\n",
    "\n",
    "    len_clf, len_vec = train_length_classifier(df_tr, clf_kind=clf_kind)\n",
    "\n",
    "    max_steps = min(max_steps_cap, 4)\n",
    "    print(f\"\\n=== length-first + sequential ===\")\n",
    "    print(f\"training up to {max_steps} steps (last→first)\")\n",
    "\n",
    "    step_vecs, step_clfs = {}, {}\n",
    "    prev_cols = []\n",
    "    for step in range(1, max_steps+1):\n",
    "        df_step = make_step_frame(df_tr, step)\n",
    "        X_dicts = dicts_from_df(df_step, add_prev=set(prev_cols))\n",
    "        X, vec = vec_fit_transform(X_dicts)\n",
    "        y = df_step[f\"y_step{step}\"].astype(str).values\n",
    "\n",
    "        clf = make_classifier(clf_kind, max_depth=6, min_samples_leaf=8)\n",
    "        clf.fit(X, y)\n",
    "\n",
    "        step_vecs[step] = vec\n",
    "        step_clfs[step] = clf\n",
    "        prev_cols.append(f\"y_step{step}\")\n",
    "\n",
    "    gold_full = df_te['trimmed'].astype(str).values\n",
    "    preds_full = []\n",
    "\n",
    "    per_step_gold = defaultdict(list)\n",
    "    per_step_pred = defaultdict(list)\n",
    "\n",
    "    Xlen = vec_transform(len_vec, dicts_from_df(df_te))\n",
    "    ylen_pred = len_clf.predict(Xlen)\n",
    "\n",
    "    for i, r in df_te.iterrows():\n",
    "        k_str = ylen_pred[i]\n",
    "        K = 4 if k_str == \"4+\" else int(k_str)\n",
    "\n",
    "        prev_preds = []\n",
    "        base_row = r.to_dict()\n",
    "\n",
    "        for step in range(1, K+1):\n",
    "            feat = build_features_row(base_row)\n",
    "            for j, lab in enumerate(prev_preds, start=1):\n",
    "                feat[f\"y_step{j}\"] = lab\n",
    "\n",
    "            X_one = vec_transform(step_vecs[step], [feat])\n",
    "            yhat = step_clfs[step].predict(X_one)[0]\n",
    "\n",
    "            gold_suffixes = r['suffixes']\n",
    "            ygold = gold_suffixes[-step] if len(gold_suffixes) >= step else END_LABEL\n",
    "            per_step_gold[step].append(ygold)\n",
    "            per_step_pred[step].append(yhat)\n",
    "\n",
    "            if yhat == END_LABEL:\n",
    "                break\n",
    "            prev_preds.append(yhat)\n",
    "\n",
    "        pred_chain = '-'.join(reversed(prev_preds)) if prev_preds else END_LABEL\n",
    "        preds_full.append(pred_chain)\n",
    "\n",
    "    acc = accuracy_score(gold_full, preds_full)\n",
    "    f1m = f1_score(gold_full, preds_full, average='macro', zero_division=0)\n",
    "    f1w = f1_score(gold_full, preds_full, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"test: acc={acc:.3f} | F1_macro={f1m:.3f} | F1_weighted={f1w:.3f}\")\n",
    "\n",
    "    labels_by_topN, _ = topN_labels_by_freq(df_tr['trimmed'].astype(str).values)\n",
    "    subset = eval_subsets(gold_full, preds_full, labels_by_topN)\n",
    "    print_subset_metrics(\"sequential\", subset)\n",
    "\n",
    "    for step in range(1, max_steps+1):\n",
    "        if len(per_step_gold[step]) == 0:\n",
    "            continue\n",
    "        ys = np.array(per_step_gold[step])\n",
    "        ps = np.array(per_step_pred[step])\n",
    "        a = accuracy_score(ys, ps)\n",
    "        fm = f1_score(ys, ps, average='macro', zero_division=0)\n",
    "        fw = f1_score(ys, ps, average='weighted', zero_division=0)\n",
    "        print(f\"step {step}: acc={a:.3f} | F1_macro={fm:.3f} | F1_weighted={fw:.3f}\")\n",
    "\n",
    "    if (\"Word\" not in df_all.columns) and (\"Char_split\" not in df_all.columns):\n",
    "        print(\"\\n[warn] no Word/Char_split found\")\n",
    "\n",
    "    return {\"len_clf\": len_clf, \"len_vec\": len_vec,\n",
    "            \"step_clfs\": step_clfs, \"step_vecs\": step_vecs,\n",
    "            \"test_df\": df_te, \"test_pred\": preds_full}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d002e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_suffix_classifier_id(str_df, clf_kind=\"tree\"):\n",
    "    \"\"\"Hash data/params to get unique classifier ID.\"\"\"\n",
    "    params_dict = {\n",
    "        'clf_kind': clf_kind,\n",
    "        'df_shape': str_df.shape if str_df is not None else (0, 0),\n",
    "        'df_columns': sorted(str_df.columns.tolist()) if str_df is not None else []\n",
    "    }\n",
    "    params_str = json.dumps(params_dict, sort_keys=True)\n",
    "    return hashlib.md5(params_str.encode()).hexdigest()[:16]\n",
    "\n",
    "def save_suffix_classifiers(single, seq, classifier_id, data_folder=DATA_FOLDER):\n",
    "    \"\"\"Save suffix classifiers.\"\"\"\n",
    "    classifier_dir = os.path.join(data_folder, f\"suffix_classifiers_{classifier_id}\")\n",
    "    os.makedirs(classifier_dir, exist_ok=True)\n",
    "    \n",
    "    if single is not None:\n",
    "        with open(os.path.join(classifier_dir, \"single.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(single, f)\n",
    "    \n",
    "    if seq is not None:\n",
    "        with open(os.path.join(classifier_dir, \"seq.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(seq, f)\n",
    "    \n",
    "    with open(os.path.join(classifier_dir, \"metadata.json\"), \"w\") as f:\n",
    "        json.dump({\n",
    "            'classifier_id': classifier_id,\n",
    "            'clf_kind': single.get('clf').__class__.__name__ if single and 'clf' in single else 'unknown'\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"saved suffix classifiers to {classifier_dir}\")\n",
    "    return classifier_dir\n",
    "\n",
    "def load_suffix_classifiers(classifier_id, data_folder=DATA_FOLDER):\n",
    "    \"\"\"Load suffix classifiers.\"\"\"\n",
    "    classifier_dir = os.path.join(data_folder, f\"suffix_classifiers_{classifier_id}\")\n",
    "    \n",
    "    if not os.path.exists(classifier_dir):\n",
    "        return None, None\n",
    "    \n",
    "    single = None\n",
    "    seq = None\n",
    "    \n",
    "    single_path = os.path.join(classifier_dir, \"single.pkl\")\n",
    "    seq_path = os.path.join(classifier_dir, \"seq.pkl\")\n",
    "    \n",
    "    if os.path.exists(single_path):\n",
    "        with open(single_path, \"rb\") as f:\n",
    "            single = pickle.load(f)\n",
    "    \n",
    "    if os.path.exists(seq_path):\n",
    "        with open(seq_path, \"rb\") as f:\n",
    "            seq = pickle.load(f)\n",
    "    \n",
    "    if single is not None or seq is not None:\n",
    "        print(f\"loaded suffix classifiers from {classifier_dir}\")\n",
    "    \n",
    "    return single, seq\n",
    "\n",
    "def run_all(str_df, clf_kind=\"tree\"):\n",
    "    \"\"\"Train or load suffix classifiers.\"\"\"\n",
    "    classifier_id = generate_suffix_classifier_id(str_df, clf_kind=clf_kind)\n",
    "    \n",
    "    print(f\"looking for suffix classifiers {classifier_id}...\")\n",
    "    single, seq = load_suffix_classifiers(classifier_id, data_folder=DATA_FOLDER)\n",
    "    \n",
    "    if single is not None and seq is not None:\n",
    "        print(f\"found them! skipping training\")\n",
    "        return single, seq\n",
    "    \n",
    "    print(f\"not found, training...\")\n",
    "    \n",
    "    df_all = build_dataset(str_df)\n",
    "    print(f\"samples: {len(df_all)}\")\n",
    "    print(f\"unique trimmed: {df_all['trimmed'].nunique()}\")\n",
    "    print(f\"suffix len dist: {df_all['suffix_len'].value_counts().sort_index().to_dict()}\")\n",
    "\n",
    "    single = run_single_shot(df_all, clf_kind=clf_kind)\n",
    "    seq = run_sequential(df_all, clf_kind=clf_kind, max_steps_cap=5)\n",
    "    \n",
    "    print(f\"\\nsaving classifiers {classifier_id}...\")\n",
    "    save_suffix_classifiers(single, seq, classifier_id, data_folder=DATA_FOLDER)\n",
    "    \n",
    "    return single, seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b63cb3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for suffix classifiers eeab9cd2ca1ef3f6...\n",
      "loaded suffix classifiers from data\\suffix_classifiers_eeab9cd2ca1ef3f6\n",
      "found them! skipping training\n"
     ]
    }
   ],
   "source": [
    "single, seq = run_all(str_df, clf_kind=\"tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3d06dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for suffix classifiers b04651ccd6358c94...\n",
      "loaded suffix classifiers from data\\suffix_classifiers_b04651ccd6358c94\n",
      "found them! skipping training\n"
     ]
    }
   ],
   "source": [
    "single, seq = run_all(str_df, clf_kind=\"rf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ac23bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_list(x):\n",
    "    \"\"\"Handle various list formats from dataframes.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    s = str(x)\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except Exception:\n",
    "        s2 = s.replace(\"[[\", \"[['\").replace(\"]]\", \"']]\").replace(\"], [\", \"'],['\").replace(\", \", \"','\")\n",
    "        return ast.literal_eval(s2)\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    \"\"\"Flatten nested list.\"\"\"\n",
    "    out = []\n",
    "    for seg in list_of_lists:\n",
    "        out.extend(seg)\n",
    "    return [str(t) for t in out]\n",
    "\n",
    "def extract_priv_features_from_row(row, feat_names):\n",
    "    \"\"\"Pull numeric features from row into vector.\"\"\"\n",
    "    vec = []\n",
    "    for k in feat_names:\n",
    "        val = row[k] if (k in row and pd.notna(row[k])) else 0.0\n",
    "        try:\n",
    "            vec.append(float(val))\n",
    "        except Exception:\n",
    "            vec.append(0.0)\n",
    "    return vec\n",
    "\n",
    "def build_samples_with_priv(df, feat_names=NEW_NUM_FEATS):\n",
    "    \"\"\"Convert dataframe rows to sample dicts for training.\"\"\"\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        cs = safe_list(r[\"Char_split\"])\n",
    "        toks = flatten(cs)\n",
    "        lens = [len(seg) for seg in cs]\n",
    "        cut_idxs = set(np.cumsum(lens)[:-1].tolist())\n",
    "        y = [1 if (i + 1) in cut_idxs else 0 for i in range(len(toks) - 1)]\n",
    "        priv = extract_priv_features_from_row(r, feat_names)\n",
    "        rows.append({\"tokens\": toks, \"y\": y, \"priv\": priv})\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "088ec274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_window(tokens, i, k_left=2, k_right=2):\n",
    "    \"\"\"Extract local context features around position i.\"\"\"\n",
    "    feats = {}\n",
    "    for k in range(1, k_left + 1):\n",
    "        idx = i - (k - 1)\n",
    "        feats[f\"L{k}\"] = tokens[idx] if idx >= 0 else \"<BOS>\"\n",
    "    for k in range(1, k_right + 1):\n",
    "        idx = i + k\n",
    "        feats[f\"R{k}\"] = tokens[idx] if idx < len(tokens) else \"<EOS>\"\n",
    "    \n",
    "    def is_vowel(ch):\n",
    "        return ch.lower() in \"aeiouáéíóú\"\n",
    "    \n",
    "    L1 = feats[\"L1\"]\n",
    "    R1 = feats[\"R1\"]\n",
    "    feats[\"L1_cv\"] = 'V' if is_vowel(L1[-1]) else 'C'\n",
    "    feats[\"R1_cv\"] = 'V' if (R1 != \"<EOS>\" and is_vowel(R1[0])) else 'C'\n",
    "    feats[\"L1_last\"] = L1[-1]\n",
    "    feats[\"R1_first\"] = R1[0] if R1 != \"<EOS>\" else \"<EOS>\"\n",
    "    return feats\n",
    "\n",
    "def train_dt_prior(samples, max_depth=6, min_leaf=8):\n",
    "    \"\"\"Train DT to predict boundary probabilities from local context.\"\"\"\n",
    "    Xdict, y = [], []\n",
    "    for s in samples:\n",
    "        T = len(s[\"tokens\"])\n",
    "        for i in range(T - 1):\n",
    "            Xdict.append(featurize_window(s[\"tokens\"], i))\n",
    "            y.append(s[\"y\"][i])\n",
    "    \n",
    "    vec = DictVectorizer(sparse=True)\n",
    "    X = vec.fit_transform(Xdict)\n",
    "    \n",
    "    clf = DecisionTreeClassifier(\n",
    "        criterion=\"entropy\",\n",
    "        max_depth=max_depth,\n",
    "        min_samples_leaf=min_leaf,\n",
    "        random_state=RNG\n",
    "    )\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    print(f\"DT prior: {clf.tree_.node_count} nodes, depth={clf.tree_.max_depth}\")\n",
    "    return clf, vec\n",
    "\n",
    "def prior_probs_for_sample(clf, vec, tokens):\n",
    "    \"\"\"Get boundary probabilities from DT for a tokenized word.\"\"\"\n",
    "    if clf is None or vec is None or len(tokens) <= 1:\n",
    "        return [0.5] * (max(len(tokens) - 1, 0))\n",
    "    \n",
    "    Xd = [featurize_window(tokens, i) for i in range(len(tokens) - 1)]\n",
    "    X = vec.transform(Xd)\n",
    "    proba = clf.predict_proba(X)\n",
    "    return proba[:, 1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e244f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_k_teacher_priv(samples, feat_dim):\n",
    "    \"\"\"Train regressor to predict number of cuts from features.\"\"\"\n",
    "    X = np.array([s[\"priv\"] for s in samples], dtype=float)\n",
    "    y = np.array([int(np.sum(s[\"y\"])) for s in samples], dtype=float)\n",
    "    reg = DecisionTreeRegressor(max_depth=6, min_samples_leaf=10, random_state=RNG)\n",
    "    reg.fit(X, y)\n",
    "    return reg\n",
    "\n",
    "def predict_k_hat_priv(reg, priv_batch):\n",
    "    \"\"\"Predict expected number of cuts for a batch.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        k = reg.predict(priv_batch.cpu().numpy())\n",
    "    return torch.tensor(k, dtype=torch.float32, device=priv_batch.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5baf8304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(samples, min_freq=1):\n",
    "    \"\"\"Build token vocabulary from samples.\"\"\"\n",
    "    ctr = Counter()\n",
    "    for s in samples:\n",
    "        ctr.update(s[\"tokens\"])\n",
    "    vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "    for t, c in sorted(ctr.items(), key=lambda x: (-x[1], x[0])):\n",
    "        if c >= min_freq and t not in vocab:\n",
    "            vocab[t] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "class SegDataset(Dataset):\n",
    "    \"\"\"Dataset for boundary prediction training.\"\"\"\n",
    "    def __init__(self, samples, vocab, dt_clf=None, dt_vec=None, feat_dim=0):\n",
    "        self.samples = samples\n",
    "        self.vocab = vocab\n",
    "        self.dt_clf = dt_clf\n",
    "        self.dt_vec = dt_vec\n",
    "        self.feat_dim = feat_dim\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        s = self.samples[idx]\n",
    "        tokens = s[\"tokens\"]\n",
    "        ids = [self.vocab.get(t, self.vocab[\"<UNK>\"]) for t in tokens]\n",
    "        y = s[\"y\"]\n",
    "        prior = prior_probs_for_sample(self.dt_clf, self.dt_vec, tokens)\n",
    "        priv = s[\"priv\"] if self.feat_dim > 0 else []\n",
    "        return {\"ids\": ids, \"y\": y, \"prior\": prior, \"priv\": priv, \"tokens\": tokens}\n",
    "\n",
    "def collate(batch):\n",
    "    \"\"\"Collate samples into batched tensors.\"\"\"\n",
    "    maxT = max(len(b[\"ids\"]) for b in batch)\n",
    "    maxB = maxT - 1\n",
    "    B = len(batch)\n",
    "\n",
    "    ids = torch.full((B, maxT), 0, dtype=torch.long)\n",
    "    mask_tok = torch.zeros((B, maxT), dtype=torch.bool)\n",
    "    y = torch.full((B, maxB), -100, dtype=torch.long)\n",
    "    prior = torch.zeros((B, maxB), dtype=torch.float32)\n",
    "    mask_b = torch.zeros((B, maxB), dtype=torch.bool)\n",
    "\n",
    "    feat_dim = len(batch[0][\"priv\"]) if isinstance(batch[0][\"priv\"], list) else 0\n",
    "    priv = torch.zeros((B, feat_dim), dtype=torch.float32) if feat_dim > 0 else None\n",
    "\n",
    "    for i, b in enumerate(batch):\n",
    "        T = len(b[\"ids\"])\n",
    "        ids[i, :T] = torch.tensor(b[\"ids\"], dtype=torch.long)\n",
    "        mask_tok[i, :T] = True\n",
    "        if T > 1:\n",
    "            L = T - 1\n",
    "            y[i, :L] = torch.tensor(b[\"y\"], dtype=torch.long)\n",
    "            p = b[\"prior\"] if len(b[\"prior\"]) == L else [0.5] * L\n",
    "            prior[i, :L] = torch.tensor(p, dtype=torch.float32)\n",
    "            mask_b[i, :L] = True\n",
    "        if feat_dim > 0:\n",
    "            priv[i] = torch.tensor(b[\"priv\"], dtype=torch.float32)\n",
    "\n",
    "    return {\n",
    "        \"ids\": ids, \"mask_tok\": mask_tok,\n",
    "        \"y\": y, \"prior\": prior, \"mask_b\": mask_b,\n",
    "        \"priv\": priv\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78589060",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMTagger(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional LSTM for boundary prediction.\n",
    "    Can fuse DT prior via concatenation or logit addition.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, emb_dim=16, hidden_size=64, num_layers=2,\n",
    "                 use_prior=True, dropout=0.1, freeze_emb=False, fuse_mode=\"logit_add\"):\n",
    "        super().__init__()\n",
    "        self.use_prior = use_prior\n",
    "        self.fuse_mode = fuse_mode\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        if freeze_emb:\n",
    "            for p in self.emb.parameters():\n",
    "                p.requires_grad = False\n",
    "        lstm_dropout = dropout if num_layers > 1 else 0.0\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_dim, hidden_size=hidden_size // 2,\n",
    "            num_layers=num_layers, dropout=lstm_dropout,\n",
    "            bidirectional=True, batch_first=True\n",
    "        )\n",
    "        in_mlp = hidden_size + (1 if (use_prior and fuse_mode == \"concat\") else 0)\n",
    "        self.boundary_mlp = nn.Sequential(\n",
    "            nn.Linear(in_mlp, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size // 2, 2)\n",
    "        )\n",
    "        if use_prior and fuse_mode == \"logit_add\":\n",
    "            self.alpha = nn.Parameter(torch.tensor(1.0))\n",
    "\n",
    "    def forward(self, ids, prior, mask_tok):\n",
    "        emb = self.emb(ids)\n",
    "        h, _ = self.lstm(emb)\n",
    "        left = h[:, :-1, :]\n",
    "        if self.use_prior and self.fuse_mode == \"concat\":\n",
    "            feat = torch.cat([left, prior.unsqueeze(-1)], dim=-1)\n",
    "            return self.boundary_mlp(feat)\n",
    "        logits = self.boundary_mlp(left)\n",
    "        if self.use_prior and self.fuse_mode == \"logit_add\":\n",
    "            eps = 1e-6\n",
    "            p = prior.clamp(eps, 1 - eps)\n",
    "            prior_logit = torch.log(p) - torch.log(1 - p)\n",
    "            logits[..., 1] = logits[..., 1] + self.alpha * prior_logit\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f02aa143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_metrics_from_lists(probs_list, gold_list, thr=0.5):\n",
    "    \"\"\"Compute P/R/F1 for boundary prediction.\"\"\"\n",
    "    if not probs_list:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    p = torch.cat([t for t in probs_list if t.numel() > 0], dim=0).numpy()\n",
    "    g = torch.cat([t for t in gold_list if t.numel() > 0], dim=0).numpy()\n",
    "    pred = (p >= thr).astype(int)\n",
    "    P, R, F1, _ = precision_recall_fscore_support(g, pred, average='binary', zero_division=0)\n",
    "    return P, R, F1\n",
    "\n",
    "def exact_match_rate_from_lists(probs_list, gold_list, thr=0.5):\n",
    "    \"\"\"Fraction of words with perfectly predicted boundaries.\"\"\"\n",
    "    if not probs_list:\n",
    "        return 0.0\n",
    "    em = []\n",
    "    for p, g in zip(probs_list, gold_list):\n",
    "        if g.numel() == 0:\n",
    "            em.append(1.0)\n",
    "        else:\n",
    "            pred = (p.numpy() >= thr).astype(int)\n",
    "            em.append(float(np.array_equal(pred, g.numpy())))\n",
    "    return float(np.mean(em))\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, loader):\n",
    "    \"\"\"Run model on loader, return probability and gold lists.\"\"\"\n",
    "    model.eval()\n",
    "    probs_list, gold_list = [], []\n",
    "    for batch in loader:\n",
    "        logits = model(batch[\"ids\"], batch[\"prior\"], batch[\"mask_tok\"])\n",
    "        probs = torch.softmax(logits, dim=-1)[..., 1]\n",
    "        y = batch[\"y\"]\n",
    "        mask = batch[\"mask_b\"]\n",
    "        B = probs.shape[0]\n",
    "        for b in range(B):\n",
    "            L = int(mask[b].sum().item())\n",
    "            if L == 0:\n",
    "                probs_list.append(torch.empty(0))\n",
    "                gold_list.append(torch.empty(0, dtype=torch.long))\n",
    "            else:\n",
    "                probs_list.append(probs[b, :L].cpu())\n",
    "                gold_list.append(y[b, :L].cpu())\n",
    "    return probs_list, gold_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62f69a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "criterion_bce = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "mse = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "def train_epoch(model, loader, opt, lambda_prior=0.1, lambda_k=0.1, k_reg=None):\n",
    "    \"\"\"One training epoch with optional prior distillation and K regularization.\"\"\"\n",
    "    model.train()\n",
    "    tot = 0\n",
    "    n = 0\n",
    "    for batch in loader:\n",
    "        ids, prior, y, mask_b = batch[\"ids\"], batch[\"prior\"], batch[\"y\"], batch[\"mask_b\"]\n",
    "        priv = batch[\"priv\"]\n",
    "\n",
    "        logits = model(ids, prior, batch[\"mask_tok\"])\n",
    "        logits_flat = logits[mask_b]\n",
    "        y_true = y[mask_b]\n",
    "\n",
    "        loss = criterion_ce(logits_flat, y_true)\n",
    "\n",
    "        if lambda_prior > 0:\n",
    "            cut_logit = logits[..., 1]\n",
    "            prior_flat = prior[mask_b]\n",
    "            loss_pr = criterion_bce(cut_logit[mask_b], prior_flat)\n",
    "            loss = loss + lambda_prior * loss_pr\n",
    "\n",
    "        if (lambda_k > 0) and (k_reg is not None) and (priv is not None):\n",
    "            with torch.no_grad():\n",
    "                k_hat = predict_k_hat_priv(k_reg, priv)\n",
    "            cut_logit = logits[..., 1]\n",
    "            p_cut = torch.sigmoid(cut_logit)\n",
    "            exp_K = p_cut.sum(dim=1)\n",
    "            loss_k = mse(exp_K, k_hat)\n",
    "            loss = loss + lambda_k * loss_k\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        tot += loss.item()\n",
    "        n += 1\n",
    "    return tot / max(n, 1)\n",
    "\n",
    "def split_train_test(samples, test_ratio=0.2):\n",
    "    \"\"\"Random train/test split.\"\"\"\n",
    "    n = len(samples)\n",
    "    idx = np.arange(n)\n",
    "    np.random.shuffle(idx)\n",
    "    cut = int(n * (1 - test_ratio))\n",
    "    tr = [samples[i] for i in idx[:cut]]\n",
    "    te = [samples[i] for i in idx[cut:]]\n",
    "    return tr, te\n",
    "\n",
    "def best_threshold_for_exact(probs_list, gold_list, grid=None):\n",
    "    \"\"\"Find threshold that maximizes exact match rate.\"\"\"\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.3, 0.9, 61)\n",
    "    best_thr, best_em, best_f1 = 0.5, -1.0, 0.0\n",
    "    p_all = np.concatenate([t.numpy() for t in probs_list if t.numel() > 0], axis=0)\n",
    "    g_all = np.concatenate([t.numpy() for t in gold_list if t.numel() > 0], axis=0)\n",
    "    for thr in grid:\n",
    "        ems = []\n",
    "        for p, g in zip(probs_list, gold_list):\n",
    "            if g.numel() == 0:\n",
    "                ems.append(1.0)\n",
    "                continue\n",
    "            ems.append(float(np.array_equal((p.numpy() >= thr).astype(int), g.numpy())))\n",
    "        em = float(np.mean(ems))\n",
    "        pred_all = (p_all >= thr).astype(int)\n",
    "        P, R, F1, _ = precision_recall_fscore_support(g_all, pred_all, average='binary', zero_division=0)\n",
    "        if em > best_em or (np.isclose(em, best_em) and F1 > best_f1):\n",
    "            best_thr, best_em, best_f1 = thr, em, F1\n",
    "    print(f\"best threshold: {best_thr:.3f} | exact={best_em:.3f} | F1={best_f1:.3f}\")\n",
    "    return best_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83bd4c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_id(df, epochs, use_prior, fuse_mode, lambda_prior, lambda_k,\n",
    "                      batch_size, hparams, max_depth=6, min_leaf=8):\n",
    "    \"\"\"Hash training params to get unique model ID.\"\"\"\n",
    "    params_dict = {\n",
    "        'epochs': epochs,\n",
    "        'use_prior': use_prior,\n",
    "        'fuse_mode': fuse_mode,\n",
    "        'lambda_prior': lambda_prior,\n",
    "        'lambda_k': lambda_k,\n",
    "        'batch_size': batch_size,\n",
    "        'hparams': hparams,\n",
    "        'max_depth': max_depth,\n",
    "        'min_leaf': min_leaf,\n",
    "        'df_shape': df.shape if df is not None else (0, 0)\n",
    "    }\n",
    "    params_str = json.dumps(params_dict, sort_keys=True)\n",
    "    return hashlib.md5(params_str.encode()).hexdigest()[:16]\n",
    "\n",
    "def save_dt_prior(dt_clf, dt_vec, model_id, models_folder=MODELS_FOLDER):\n",
    "    \"\"\"Save DT prior.\"\"\"\n",
    "    model_dir = os.path.join(models_folder, model_id)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    with open(os.path.join(model_dir, \"dt_clf.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(dt_clf, f)\n",
    "    with open(os.path.join(model_dir, \"dt_vec.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(dt_vec, f)\n",
    "    print(f\"saved DT prior to {model_dir}\")\n",
    "\n",
    "def load_dt_prior(model_id, models_folder=MODELS_FOLDER):\n",
    "    \"\"\"Load DT prior.\"\"\"\n",
    "    model_dir = os.path.join(models_folder, model_id)\n",
    "    dt_clf_path = os.path.join(model_dir, \"dt_clf.pkl\")\n",
    "    dt_vec_path = os.path.join(model_dir, \"dt_vec.pkl\")\n",
    "    \n",
    "    if not os.path.exists(dt_clf_path) or not os.path.exists(dt_vec_path):\n",
    "        return None, None\n",
    "    \n",
    "    with open(dt_clf_path, \"rb\") as f:\n",
    "        dt_clf = pickle.load(f)\n",
    "    with open(dt_vec_path, \"rb\") as f:\n",
    "        dt_vec = pickle.load(f)\n",
    "    print(f\"loaded DT prior from {model_dir}\")\n",
    "    return dt_clf, dt_vec\n",
    "\n",
    "def save_model(model, vocab, out, model_id, models_folder=MODELS_FOLDER):\n",
    "    \"\"\"Save model weights and artifacts.\"\"\"\n",
    "    model_dir = os.path.join(models_folder, model_id)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join(model_dir, \"model.pt\"))\n",
    "    \n",
    "    with open(os.path.join(model_dir, \"vocab.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(vocab, f)\n",
    "    \n",
    "    if out.get(\"dt_clf\") is not None and out.get(\"dt_vec\") is not None:\n",
    "        save_dt_prior(out[\"dt_clf\"], out[\"dt_vec\"], model_id, models_folder)\n",
    "    \n",
    "    artifacts = {k: v for k, v in out.items() if k not in [\"dt_clf\", \"dt_vec\"]}\n",
    "    with open(os.path.join(model_dir, \"artifacts.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(artifacts, f)\n",
    "    \n",
    "    with open(os.path.join(model_dir, \"metadata.json\"), \"w\") as f:\n",
    "        json.dump({\n",
    "            'model_id': model_id,\n",
    "            'vocab_size': len(vocab),\n",
    "            'model_name': MODEL_NAME\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"saved model to {model_dir}\")\n",
    "    return model_dir\n",
    "\n",
    "def load_model(model_id, models_folder=MODELS_FOLDER, vocab_size=None):\n",
    "    \"\"\"Load saved model artifacts.\"\"\"\n",
    "    model_dir = os.path.join(models_folder, model_id)\n",
    "    if not os.path.exists(model_dir):\n",
    "        return None\n",
    "    \n",
    "    vocab_path = os.path.join(model_dir, \"vocab.pkl\")\n",
    "    if not os.path.exists(vocab_path):\n",
    "        return None\n",
    "    with open(vocab_path, \"rb\") as f:\n",
    "        vocab = pickle.load(f)\n",
    "    \n",
    "    dt_clf, dt_vec = load_dt_prior(model_id, models_folder)\n",
    "    \n",
    "    artifacts_path = os.path.join(model_dir, \"artifacts.pkl\")\n",
    "    if not os.path.exists(artifacts_path):\n",
    "        return None\n",
    "    with open(artifacts_path, \"rb\") as f:\n",
    "        artifacts = pickle.load(f)\n",
    "    \n",
    "    out = {**artifacts, \"dt_clf\": dt_clf, \"dt_vec\": dt_vec}\n",
    "    \n",
    "    model_path = os.path.join(model_dir, \"model.pt\")\n",
    "    if not os.path.exists(model_path):\n",
    "        return None\n",
    "    \n",
    "    print(f\"loaded artifacts from {model_dir}\")\n",
    "    return {\n",
    "        'vocab': vocab,\n",
    "        'out': out,\n",
    "        'dt_clf': dt_clf,\n",
    "        'dt_vec': dt_vec,\n",
    "        'model_state_path': model_path,\n",
    "        'model_dir': model_dir\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92efaaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_segmentation_with_privK(\n",
    "    df,\n",
    "    epochs=15,\n",
    "    use_prior=True,\n",
    "    fuse_mode=\"logit_add\",\n",
    "    lambda_prior=0.1,\n",
    "    lambda_k=0.2,\n",
    "    batch_size=64,\n",
    "    hparams=None,\n",
    "    max_depth=6,\n",
    "    min_leaf=8\n",
    "):\n",
    "    \"\"\"Train or load a segmentation model with DT priors.\"\"\"\n",
    "    if hparams is None:\n",
    "        hparams = dict(emb_dim=16, hidden_size=64, num_layers=2,\n",
    "                       dropout=0.25, lr=1e-3, weight_decay=1e-4, freeze_emb=False)\n",
    "    \n",
    "    model_id = generate_model_id(\n",
    "        df, epochs, use_prior, fuse_mode, lambda_prior, lambda_k,\n",
    "        batch_size, hparams, max_depth=max_depth, min_leaf=min_leaf\n",
    "    )\n",
    "    \n",
    "    print(f\"looking for model {model_id}...\")\n",
    "    loaded = load_model(model_id, models_folder=MODELS_FOLDER)\n",
    "    \n",
    "    if loaded is not None:\n",
    "        print(f\"found it! loading from {loaded['model_dir']}\")\n",
    "        vocab = loaded['vocab']\n",
    "        out = loaded['out']\n",
    "        dt_clf = loaded['dt_clf']\n",
    "        dt_vec = loaded['dt_vec']\n",
    "        model_state_path = loaded['model_state_path']\n",
    "        \n",
    "        model = BiLSTMTagger(\n",
    "            vocab_size=len(vocab),\n",
    "            emb_dim=hparams.get(\"emb_dim\", 16),\n",
    "            hidden_size=hparams.get(\"hidden_size\", 64),\n",
    "            num_layers=hparams.get(\"num_layers\", 2),\n",
    "            use_prior=(use_prior and fuse_mode != \"none\"),\n",
    "            dropout=hparams.get(\"dropout\", 0.25),\n",
    "            freeze_emb=hparams.get(\"freeze_emb\", False),\n",
    "            fuse_mode=fuse_mode\n",
    "        )\n",
    "        model.load_state_dict(torch.load(model_state_path))\n",
    "        model.eval()\n",
    "        print(\"skipping training, model ready\")\n",
    "        return model, vocab, out\n",
    "    \n",
    "    print(f\"not found, training from scratch...\")\n",
    "    \n",
    "    samples = build_samples_with_priv(df, feat_names=NEW_NUM_FEATS)\n",
    "    train_s, test_s = split_train_test(samples, 0.2)\n",
    "\n",
    "    dt_clf, dt_vec = (None, None)\n",
    "    if use_prior:\n",
    "        dt_clf, dt_vec = load_dt_prior(model_id, models_folder=MODELS_FOLDER)\n",
    "        if dt_clf is None or dt_vec is None:\n",
    "            print(\"training DT prior...\")\n",
    "            dt_clf, dt_vec = train_dt_prior(train_s, max_depth=max_depth, min_leaf=min_leaf)\n",
    "        else:\n",
    "            print(\"using existing DT prior\")\n",
    "\n",
    "    feat_dim = len(NEW_NUM_FEATS)\n",
    "    k_reg = train_k_teacher_priv(train_s, feat_dim=feat_dim)\n",
    "\n",
    "    vocab = build_vocab(train_s, min_freq=1)\n",
    "\n",
    "    train_ds = SegDataset(train_s, vocab, dt_clf, dt_vec, feat_dim=feat_dim)\n",
    "    test_ds = SegDataset(test_s, vocab, dt_clf, dt_vec, feat_dim=feat_dim)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, collate_fn=collate)\n",
    "\n",
    "    model = BiLSTMTagger(\n",
    "        vocab_size=len(vocab),\n",
    "        emb_dim=hparams.get(\"emb_dim\", 16),\n",
    "        hidden_size=hparams.get(\"hidden_size\", 64),\n",
    "        num_layers=hparams.get(\"num_layers\", 2),\n",
    "        use_prior=(use_prior and fuse_mode != \"none\"),\n",
    "        dropout=hparams.get(\"dropout\", 0.25),\n",
    "        freeze_emb=hparams.get(\"freeze_emb\", False),\n",
    "        fuse_mode=fuse_mode\n",
    "    )\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=hparams.get(\"lr\", 1e-3),\n",
    "                            weight_decay=hparams.get(\"weight_decay\", 1e-4))\n",
    "\n",
    "    final_probs_list, final_gold_list = None, None\n",
    "    for ep in range(1, epochs + 1):\n",
    "        loss = train_epoch(model, train_loader, opt, lambda_prior=lambda_prior, lambda_k=lambda_k, k_reg=k_reg)\n",
    "        probs_list, gold_list = predict(model, test_loader)\n",
    "        P, R, F1 = boundary_metrics_from_lists(probs_list, gold_list, thr=0.5)\n",
    "        EM = exact_match_rate_from_lists(probs_list, gold_list, thr=0.5)\n",
    "        print(f\"epoch {ep:02d} | loss={loss:.4f} | P/R/F1={P:.3f}/{R:.3f}/{F1:.3f} | exact={EM:.3f}\")\n",
    "        final_probs_list, final_gold_list = probs_list, gold_list\n",
    "\n",
    "    best_thr = best_threshold_for_exact(final_probs_list, final_gold_list)\n",
    "\n",
    "    out = {\n",
    "        \"probs_list\": final_probs_list,\n",
    "        \"gold_list\": final_gold_list,\n",
    "        \"dt_clf\": dt_clf,\n",
    "        \"dt_vec\": dt_vec,\n",
    "        \"k_teacher\": k_reg,\n",
    "        \"best_thr\": best_thr\n",
    "    }\n",
    "    \n",
    "    print(f\"saving model {model_id}...\")\n",
    "    save_model(model, vocab, out, model_id, models_folder=MODELS_FOLDER)\n",
    "\n",
    "    return model, vocab, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96f12702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_cross_validation(\n",
    "    df,\n",
    "    n_folds=5,\n",
    "    epochs=15,\n",
    "    use_prior=True,\n",
    "    fuse_mode=\"logit_add\",\n",
    "    lambda_prior=0.1,\n",
    "    lambda_k=0.2,\n",
    "    batch_size=64,\n",
    "    hparams=None,\n",
    "    max_depth=6,\n",
    "    min_leaf=8,\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"K-fold cross-validation for more robust evaluation.\"\"\"\n",
    "    if hparams is None:\n",
    "        hparams = dict(emb_dim=16, hidden_size=64, num_layers=2,\n",
    "                       dropout=0.25, lr=1e-3, weight_decay=1e-4, freeze_emb=False)\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"K-FOLD CV (k={n_folds})\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "    samples = build_samples_with_priv(df, feat_names=NEW_NUM_FEATS)\n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    fold_results = []\n",
    "    all_metrics = {\n",
    "        'boundary_precision': [],\n",
    "        'boundary_recall': [],\n",
    "        'boundary_f1': [],\n",
    "        'exact_match': [],\n",
    "        'best_threshold': []\n",
    "    }\n",
    "    \n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(kfold.split(samples), 1):\n",
    "        print(f\"\\n--- fold {fold_idx}/{n_folds} ---\")\n",
    "        print(f\"train: {len(train_indices)}, val: {len(val_indices)}\")\n",
    "        \n",
    "        train_samples = [samples[i] for i in train_indices]\n",
    "        val_samples = [samples[i] for i in val_indices]\n",
    "        \n",
    "        dt_clf, dt_vec = (None, None)\n",
    "        if use_prior:\n",
    "            print(\"training DT prior...\")\n",
    "            dt_clf, dt_vec = train_dt_prior(train_samples, max_depth=max_depth, min_leaf=min_leaf)\n",
    "        \n",
    "        feat_dim = len(NEW_NUM_FEATS)\n",
    "        k_reg = train_k_teacher_priv(train_samples, feat_dim=feat_dim)\n",
    "        vocab = build_vocab(train_samples, min_freq=1)\n",
    "        \n",
    "        train_ds = SegDataset(train_samples, vocab, dt_clf=dt_clf, dt_vec=dt_vec, feat_dim=feat_dim)\n",
    "        val_ds = SegDataset(val_samples, vocab, dt_clf=dt_clf, dt_vec=dt_vec, feat_dim=feat_dim)\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, collate_fn=collate)\n",
    "        \n",
    "        model = BiLSTMTagger(\n",
    "            vocab_size=len(vocab),\n",
    "            emb_dim=hparams.get(\"emb_dim\", 16),\n",
    "            hidden_size=hparams.get(\"hidden_size\", 64),\n",
    "            num_layers=hparams.get(\"num_layers\", 2),\n",
    "            use_prior=(use_prior and fuse_mode != \"none\"),\n",
    "            dropout=hparams.get(\"dropout\", 0.25),\n",
    "            freeze_emb=hparams.get(\"freeze_emb\", False),\n",
    "            fuse_mode=fuse_mode\n",
    "        )\n",
    "        \n",
    "        opt = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=hparams.get(\"lr\", 1e-3),\n",
    "            weight_decay=hparams.get(\"weight_decay\", 1e-4)\n",
    "        )\n",
    "        \n",
    "        best_val_em = -1.0\n",
    "        best_val_f1 = -1.0\n",
    "        best_epoch = 0\n",
    "        \n",
    "        for ep in range(1, epochs + 1):\n",
    "            loss = train_epoch(model, train_loader, opt, lambda_prior=lambda_prior, lambda_k=lambda_k, k_reg=k_reg)\n",
    "            probs_list, gold_list = predict(model, val_loader)\n",
    "            P, R, F1 = boundary_metrics_from_lists(probs_list, gold_list, thr=0.5)\n",
    "            EM = exact_match_rate_from_lists(probs_list, gold_list, thr=0.5)\n",
    "            \n",
    "            print(f\"  ep {ep:02d} | loss={loss:.4f} | P/R/F1={P:.3f}/{R:.3f}/{F1:.3f} | exact={EM:.3f}\")\n",
    "            \n",
    "            if EM > best_val_em or (np.isclose(EM, best_val_em) and F1 > best_val_f1):\n",
    "                best_val_em = EM\n",
    "                best_val_f1 = F1\n",
    "                best_epoch = ep\n",
    "                best_probs_list = probs_list\n",
    "                best_gold_list = gold_list\n",
    "        \n",
    "        best_thr = best_threshold_for_exact(best_probs_list, best_gold_list)\n",
    "        P_final, R_final, F1_final = boundary_metrics_from_lists(best_probs_list, best_gold_list, thr=best_thr)\n",
    "        EM_final = exact_match_rate_from_lists(best_probs_list, best_gold_list, thr=best_thr)\n",
    "        \n",
    "        print(f\"  best epoch: {best_epoch}\")\n",
    "        print(f\"  final (thr={best_thr:.3f}): P/R/F1={P_final:.3f}/{R_final:.3f}/{F1_final:.3f} | exact={EM_final:.3f}\")\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold_idx,\n",
    "            'boundary_precision': P_final,\n",
    "            'boundary_recall': R_final,\n",
    "            'boundary_f1': F1_final,\n",
    "            'exact_match': EM_final,\n",
    "            'best_threshold': best_thr,\n",
    "            'best_epoch': best_epoch\n",
    "        })\n",
    "        \n",
    "        all_metrics['boundary_precision'].append(P_final)\n",
    "        all_metrics['boundary_recall'].append(R_final)\n",
    "        all_metrics['boundary_f1'].append(F1_final)\n",
    "        all_metrics['exact_match'].append(EM_final)\n",
    "        all_metrics['best_threshold'].append(best_thr)\n",
    "    \n",
    "    mean_metrics = {k: np.mean(v) for k, v in all_metrics.items()}\n",
    "    std_metrics = {k: np.std(v) for k, v in all_metrics.items()}\n",
    "    best_fold_idx = max(range(len(fold_results)), key=lambda i: fold_results[i]['exact_match'])\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"CV SUMMARY\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    for r in fold_results:\n",
    "        print(f\"  fold {r['fold']}: P={r['boundary_precision']:.3f}, R={r['boundary_recall']:.3f}, \"\n",
    "              f\"F1={r['boundary_f1']:.3f}, EM={r['exact_match']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nmean +/- std over {n_folds} folds:\")\n",
    "    print(f\"  precision: {mean_metrics['boundary_precision']:.3f} +/- {std_metrics['boundary_precision']:.3f}\")\n",
    "    print(f\"  recall:    {mean_metrics['boundary_recall']:.3f} +/- {std_metrics['boundary_recall']:.3f}\")\n",
    "    print(f\"  F1:        {mean_metrics['boundary_f1']:.3f} +/- {std_metrics['boundary_f1']:.3f}\")\n",
    "    print(f\"  exact:     {mean_metrics['exact_match']:.3f} +/- {std_metrics['exact_match']:.3f}\")\n",
    "    print(f\"  threshold: {mean_metrics['best_threshold']:.3f} +/- {std_metrics['best_threshold']:.3f}\")\n",
    "    print(f\"\\nbest fold: {fold_results[best_fold_idx]['fold']} (exact={fold_results[best_fold_idx]['exact_match']:.3f})\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'fold_results': fold_results,\n",
    "        'mean_metrics': mean_metrics,\n",
    "        'std_metrics': std_metrics,\n",
    "        'best_fold_idx': best_fold_idx,\n",
    "        'all_metrics': all_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70cbcab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_vocab(word: str, vocab: dict, max_token_len: int = 4):\n",
    "    \"\"\"Greedy left-to-right tokenization using vocab.\"\"\"\n",
    "    i, toks = 0, []\n",
    "    while i < len(word):\n",
    "        matched = None\n",
    "        Lmax = min(max_token_len, len(word) - i)\n",
    "        for L in range(Lmax, 0, -1):\n",
    "            seg = word[i:i + L]\n",
    "            if seg in vocab:\n",
    "                matched = seg\n",
    "                break\n",
    "        toks.append(matched if matched else word[i])\n",
    "        i += len(toks[-1])\n",
    "    return toks\n",
    "\n",
    "@torch.no_grad()\n",
    "def segment_tokens(model, vocab, tokens, dt_clf=None, dt_vec=None, thr=0.5):\n",
    "    \"\"\"Segment a tokenized word and return the segmented string + probabilities.\"\"\"\n",
    "    ids = torch.tensor([[vocab.get(t, vocab[\"<UNK>\"]) for t in tokens]], dtype=torch.long)\n",
    "    mask_tok = torch.ones_like(ids, dtype=torch.bool)\n",
    "    T = len(tokens)\n",
    "    if T <= 1:\n",
    "        return \"\".join(tokens), np.array([])\n",
    "    \n",
    "    prior_list = prior_probs_for_sample(dt_clf, dt_vec, tokens)\n",
    "    prior = torch.tensor([prior_list], dtype=torch.float32)\n",
    "    logits = model(ids, prior, mask_tok)\n",
    "    probs = torch.softmax(logits, dim=-1)[0, :, 1].cpu().numpy()\n",
    "    cuts = (probs >= thr).astype(int)\n",
    "    \n",
    "    out = []\n",
    "    for i, tok in enumerate(tokens):\n",
    "        out.append(tok)\n",
    "        if i < T - 1 and cuts[i] == 1:\n",
    "            out.append(\"-\")\n",
    "    return \"\".join(out), probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "089a757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offsets_from_morphemes(morphs: List[str]) -> Set[int]:\n",
    "    \"\"\"Character offsets of boundaries between morphemes.\"\"\"\n",
    "    offs = []\n",
    "    s = 0\n",
    "    for i, m in enumerate(morphs):\n",
    "        s += len(m)\n",
    "        if i < len(morphs) - 1:\n",
    "            offs.append(s)\n",
    "    return set(offs)\n",
    "\n",
    "def offsets_from_tokens_and_mask(tokens: List[str], mask01: np.ndarray) -> Set[int]:\n",
    "    \"\"\"Character offsets where model predicted boundaries.\"\"\"\n",
    "    offs = set()\n",
    "    cum = 0\n",
    "    for i, t in enumerate(tokens):\n",
    "        cum += len(t)\n",
    "        if i < len(tokens) - 1 and mask01[i] == 1:\n",
    "            offs.add(cum)\n",
    "    return offs\n",
    "\n",
    "def f1_from_sets(pred: Set[int], gold: Set[int]) -> Tuple[float, float, float, int, int, int]:\n",
    "    \"\"\"P/R/F1 from predicted and gold boundary sets.\"\"\"\n",
    "    tp = len(pred & gold)\n",
    "    fp = len(pred - gold)\n",
    "    fn = len(gold - pred)\n",
    "    P = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    R = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    F1 = 2 * P * R / (P + R) if (P + R) > 0 else 0.0\n",
    "    return P, R, F1, tp, fp, fn\n",
    "\n",
    "def normalize_gold_variants(gold_variants):\n",
    "    \"\"\"Convert gold variants to proper list format.\"\"\"\n",
    "    if gold_variants is None:\n",
    "        return []\n",
    "    if isinstance(gold_variants, np.ndarray):\n",
    "        gold_variants = gold_variants.tolist()\n",
    "    if isinstance(gold_variants, list):\n",
    "        normalized = []\n",
    "        for variant in gold_variants:\n",
    "            if isinstance(variant, np.ndarray):\n",
    "                normalized.append(variant.tolist())\n",
    "            elif isinstance(variant, list):\n",
    "                normalized.append([item.tolist() if isinstance(item, np.ndarray) else item for item in variant])\n",
    "            else:\n",
    "                normalized.append(variant)\n",
    "        return normalized\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e0030d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_gold_df(df, model, vocab, out, max_token_len=4, use_tuned_thr=True, show_sample=5):\n",
    "    \"\"\"Evaluate model on test set with multiple gold variants per word.\"\"\"\n",
    "    dt_clf, dt_vec = out[\"dt_clf\"], out[\"dt_vec\"]\n",
    "    thr = float(out.get(\"best_thr\", 0.5)) if use_tuned_thr else 0.5\n",
    "\n",
    "    total_tp = total_fp = total_fn = 0\n",
    "    exact_hits = 0\n",
    "    n_eval = 0\n",
    "    examples = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        word = str(row[\"Word\"])\n",
    "        gold_variants = normalize_gold_variants(row[\"Gold\"])\n",
    "\n",
    "        if not isinstance(gold_variants, list) or len(gold_variants) == 0:\n",
    "            continue\n",
    "\n",
    "        toks = tokenize_with_vocab(word, vocab, max_token_len=max_token_len)\n",
    "        seg_string, probs = segment_tokens(model, vocab, toks, dt_clf=dt_clf, dt_vec=dt_vec, thr=thr)\n",
    "        mask01 = (probs >= thr).astype(int)\n",
    "        pred_set = offsets_from_tokens_and_mask(toks, mask01)\n",
    "\n",
    "        gold_sets = [offsets_from_morphemes(gv) for gv in gold_variants]\n",
    "\n",
    "        if any(pred_set == gs for gs in gold_sets):\n",
    "            exact_hits += 1\n",
    "\n",
    "        best = max((f1_from_sets(pred_set, gs) + (gs,) for gs in gold_sets), key=lambda z: z[2])\n",
    "        P, R, F1, tp, fp, fn, best_gs = best\n",
    "\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "        n_eval += 1\n",
    "\n",
    "        if len(examples) < show_sample:\n",
    "            best_morphs = None\n",
    "            for gv in gold_variants:\n",
    "                if offsets_from_morphemes(gv) == best_gs:\n",
    "                    best_morphs = gv\n",
    "                    break\n",
    "            gold_str = \"-\".join(best_morphs) if best_morphs else \"(ambig)\"\n",
    "            examples.append({\n",
    "                \"word\": word, \"tokens\": toks, \"pred_seg\": seg_string,\n",
    "                \"gold_best\": gold_str, \"P\": round(P, 3), \"R\": round(R, 3), \"F1\": round(F1, 3)\n",
    "            })\n",
    "\n",
    "    micro_P = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
    "    micro_R = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
    "    micro_F1 = 2 * micro_P * micro_R / (micro_P + micro_R) if (micro_P + micro_R) > 0 else 0.0\n",
    "    exact_rate = exact_hits / n_eval if n_eval > 0 else 0.0\n",
    "\n",
    "    print(f\"evaluated {n_eval} words\")\n",
    "    print(f\"boundary (micro) P/R/F1 = {micro_P:.3f}/{micro_R:.3f}/{micro_F1:.3f}\")\n",
    "    print(f\"exact match = {exact_rate:.3f}\")\n",
    "    if examples:\n",
    "        print(\"\\nsamples:\")\n",
    "        for ex in examples:\n",
    "            print(f\"- {ex['word']}\")\n",
    "            print(f\"  tokens: {ex['tokens']}\")\n",
    "            print(f\"  pred:   {ex['pred_seg']}\")\n",
    "            print(f\"  gold:   {ex['gold_best']}\")\n",
    "            print(f\"  P/R/F1: {ex['P']}/{ex['R']}/{ex['F1']}\\n\")\n",
    "\n",
    "    return {\n",
    "        \"n_eval\": n_eval, \"micro_precision\": micro_P, \"micro_recall\": micro_R,\n",
    "        \"micro_f1\": micro_F1, \"exact_match_rate\": exact_rate, \"examples\": examples\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e473794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_segmentation_valid(segmentation: list, allowed_suffixes: set) -> bool:\n",
    "    \"\"\"Check if all suffixes (non-root morphemes) are in the allowed set.\"\"\"\n",
    "    if len(segmentation) <= 1:\n",
    "        return True\n",
    "    for morpheme in segmentation[1:]:\n",
    "        if morpheme not in allowed_suffixes:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def evaluate_and_ignore_rejected(\n",
    "    df, model, vocab, out,\n",
    "    allowed_suffixes: list,\n",
    "    max_token_len=4,\n",
    "    use_tuned_thr=True,\n",
    "    show_sample=5\n",
    "):\n",
    "    \"\"\"Evaluate but skip predictions with invalid suffixes.\"\"\"\n",
    "    dt_clf, dt_vec = out[\"dt_clf\"], out[\"dt_vec\"]\n",
    "    thr = float(out.get(\"best_thr\", 0.5)) if use_tuned_thr else 0.5\n",
    "    allowed_suffixes_set = set(allowed_suffixes)\n",
    "\n",
    "    total_tp = total_fp = total_fn = 0\n",
    "    exact_hits = 0\n",
    "    n_total_words = 0\n",
    "    n_evaluated_words = 0\n",
    "    rejection_count = 0\n",
    "    examples = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        word = str(row[\"Word\"])\n",
    "        gold_variants = normalize_gold_variants(row[\"Gold\"])\n",
    "\n",
    "        if not isinstance(gold_variants, list) or len(gold_variants) == 0:\n",
    "            continue\n",
    "        \n",
    "        n_total_words += 1\n",
    "\n",
    "        toks = tokenize_with_vocab(word, vocab, max_token_len=max_token_len)\n",
    "        seg_string, probs = segment_tokens(model, vocab, toks, dt_clf=dt_clf, dt_vec=dt_vec, thr=thr)\n",
    "        predicted_morphs = seg_string.split('-')\n",
    "\n",
    "        if not is_segmentation_valid(predicted_morphs, allowed_suffixes_set):\n",
    "            rejection_count += 1\n",
    "            continue\n",
    "\n",
    "        n_evaluated_words += 1\n",
    "        \n",
    "        mask01 = (probs >= thr).astype(int)\n",
    "        pred_set = offsets_from_tokens_and_mask(toks, mask01)\n",
    "        gold_sets = [offsets_from_morphemes(gv) for gv in gold_variants]\n",
    "\n",
    "        if any(pred_set == gs for gs in gold_sets):\n",
    "            exact_hits += 1\n",
    "\n",
    "        best = max((f1_from_sets(pred_set, gs) + (gs,) for gs in gold_sets), key=lambda z: z[2])\n",
    "        P, R, F1, tp, fp, fn, best_gs = best\n",
    "\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "\n",
    "        if len(examples) < show_sample:\n",
    "            best_morphs = None\n",
    "            for gv in gold_variants:\n",
    "                if offsets_from_morphemes(gv) == best_gs:\n",
    "                    best_morphs = gv\n",
    "                    break\n",
    "            gold_str = \"-\".join(best_morphs) if best_morphs else \"(ambig)\"\n",
    "            examples.append({\n",
    "                \"word\": word, \"tokens\": toks, \"pred_seg\": seg_string,\n",
    "                \"gold_best\": gold_str, \"P\": round(P, 3), \"R\": round(R, 3), \"F1\": round(F1, 3)\n",
    "            })\n",
    "\n",
    "    micro_P = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
    "    micro_R = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
    "    micro_F1 = 2 * micro_P * micro_R / (micro_P + micro_R) if (micro_P + micro_R) > 0 else 0.0\n",
    "    exact_rate = exact_hits / n_evaluated_words if n_evaluated_words > 0 else 0.0\n",
    "\n",
    "    print(f\"tried {n_total_words} words\")\n",
    "    print(f\"rejected {rejection_count} ({rejection_count/n_total_words:.1%}) with invalid suffixes\")\n",
    "    print(f\"scoring {n_evaluated_words} valid predictions\")\n",
    "    print(f\"\\n--- final scores (valid predictions only) ---\")\n",
    "    print(f\"boundary (micro) P/R/F1 = {micro_P:.3f}/{micro_R:.3f}/{micro_F1:.3f}\")\n",
    "    print(f\"exact match = {exact_rate:.3f}\")\n",
    "\n",
    "    if examples:\n",
    "        print(\"\\nsamples:\")\n",
    "        for ex in examples:\n",
    "            print(f\"- {ex['word']}\")\n",
    "            print(f\"  tokens: {ex['tokens']}\")\n",
    "            print(f\"  pred:   {ex['pred_seg']}\")\n",
    "            print(f\"  gold:   {ex['gold_best']}\")\n",
    "            print(f\"  P/R/F1: {ex['P']}/{ex['R']}/{ex['F1']}\\n\")\n",
    "    \n",
    "    return {\"micro_f1\": micro_F1, \"exact_match_rate\": exact_rate, \"rejection_count\": rejection_count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2717e28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 88 suffixes\n"
     ]
    }
   ],
   "source": [
    "def read_suffixes(filename):\n",
    "    \"\"\"Read suffix list from file (format: 'number -suffix').\"\"\"\n",
    "    suffixes = []\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = line.split(maxsplit=1)\n",
    "            if len(parts) == 2:\n",
    "                _, suffix = parts\n",
    "                suffixes.append(suffix[1:])  # drop leading dash\n",
    "    return suffixes\n",
    "\n",
    "filename = os.path.join(DATA_FOLDER, \"suffixesCQ-Anettte-Rios_LS.txt\")\n",
    "suffix_list = read_suffixes(filename)\n",
    "print(f\"loaded {len(suffix_list)} suffixes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fa131fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "best = {\n",
    "    \"emb_dim\": 16,\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.25,\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 0.0001,\n",
    "    \"freeze_emb\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5874a743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for model b4157b221fb77816...\n",
      "loaded DT prior from models_DT-LSTM-MarkovFilter\\b4157b221fb77816\n",
      "loaded artifacts from models_DT-LSTM-MarkovFilter\\b4157b221fb77816\n",
      "found it! loading from models_DT-LSTM-MarkovFilter\\b4157b221fb77816\n",
      "skipping training, model ready\n"
     ]
    }
   ],
   "source": [
    "# Train or load the model\n",
    "model, vocab, out = run_segmentation_with_privK(\n",
    "    str_df,\n",
    "    epochs=50,\n",
    "    use_prior=True,\n",
    "    fuse_mode=\"logit_add\",\n",
    "    lambda_prior=0.1,\n",
    "    lambda_k=0.2,\n",
    "    batch_size=64,\n",
    "    hparams=best\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f10008da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "K-FOLD CV (k=5)\n",
      "================================================================================\n",
      "\n",
      "--- fold 1/5 ---\n",
      "train: 5064, val: 1266\n",
      "training DT prior...\n",
      "DT prior: 45 nodes, depth=6\n",
      "  ep 01 | loss=0.4402 | P/R/F1=0.685/0.837/0.753 | exact=0.235\n",
      "  ep 02 | loss=0.3713 | P/R/F1=0.775/0.815/0.794 | exact=0.353\n",
      "  ep 03 | loss=0.3173 | P/R/F1=0.815/0.898/0.854 | exact=0.478\n",
      "  ep 04 | loss=0.2742 | P/R/F1=0.890/0.892/0.891 | exact=0.604\n",
      "  ep 05 | loss=0.2415 | P/R/F1=0.916/0.888/0.901 | exact=0.636\n",
      "  ep 06 | loss=0.2206 | P/R/F1=0.914/0.923/0.918 | exact=0.682\n",
      "  ep 07 | loss=0.2030 | P/R/F1=0.909/0.951/0.929 | exact=0.718\n",
      "  ep 08 | loss=0.1881 | P/R/F1=0.936/0.948/0.942 | exact=0.761\n",
      "  ep 09 | loss=0.1804 | P/R/F1=0.937/0.951/0.944 | exact=0.771\n",
      "  ep 10 | loss=0.1722 | P/R/F1=0.953/0.942/0.948 | exact=0.788\n",
      "  ep 11 | loss=0.1602 | P/R/F1=0.947/0.956/0.952 | exact=0.798\n",
      "  ep 12 | loss=0.1552 | P/R/F1=0.959/0.951/0.955 | exact=0.818\n",
      "  ep 13 | loss=0.1503 | P/R/F1=0.955/0.957/0.956 | exact=0.814\n",
      "  ep 14 | loss=0.1404 | P/R/F1=0.959/0.967/0.963 | exact=0.847\n",
      "  ep 15 | loss=0.1372 | P/R/F1=0.956/0.970/0.963 | exact=0.845\n",
      "best threshold: 0.510 | exact=0.848 | F1=0.963\n",
      "  best epoch: 14\n",
      "  final (thr=0.510): P/R/F1=0.959/0.966/0.963 | exact=0.848\n",
      "\n",
      "--- fold 2/5 ---\n",
      "train: 5064, val: 1266\n",
      "training DT prior...\n",
      "DT prior: 45 nodes, depth=6\n",
      "  ep 01 | loss=0.4514 | P/R/F1=0.690/0.723/0.706 | exact=0.216\n",
      "  ep 02 | loss=0.3800 | P/R/F1=0.802/0.803/0.802 | exact=0.389\n",
      "  ep 03 | loss=0.3125 | P/R/F1=0.858/0.872/0.865 | exact=0.525\n",
      "  ep 04 | loss=0.2682 | P/R/F1=0.892/0.897/0.895 | exact=0.618\n",
      "  ep 05 | loss=0.2407 | P/R/F1=0.897/0.931/0.914 | exact=0.668\n",
      "  ep 06 | loss=0.2128 | P/R/F1=0.916/0.930/0.923 | exact=0.705\n",
      "  ep 07 | loss=0.1967 | P/R/F1=0.931/0.930/0.931 | exact=0.734\n",
      "  ep 08 | loss=0.1888 | P/R/F1=0.916/0.964/0.939 | exact=0.763\n",
      "  ep 09 | loss=0.1786 | P/R/F1=0.914/0.974/0.943 | exact=0.771\n",
      "  ep 10 | loss=0.1695 | P/R/F1=0.938/0.959/0.949 | exact=0.793\n",
      "  ep 11 | loss=0.1627 | P/R/F1=0.942/0.963/0.952 | exact=0.813\n",
      "  ep 12 | loss=0.1531 | P/R/F1=0.945/0.968/0.956 | exact=0.830\n",
      "  ep 13 | loss=0.1509 | P/R/F1=0.933/0.979/0.955 | exact=0.818\n",
      "  ep 14 | loss=0.1412 | P/R/F1=0.943/0.977/0.960 | exact=0.840\n",
      "  ep 15 | loss=0.1362 | P/R/F1=0.950/0.977/0.963 | exact=0.852\n",
      "best threshold: 0.570 | exact=0.855 | F1=0.964\n",
      "  best epoch: 15\n",
      "  final (thr=0.570): P/R/F1=0.954/0.975/0.964 | exact=0.855\n",
      "\n",
      "--- fold 3/5 ---\n",
      "train: 5064, val: 1266\n",
      "training DT prior...\n",
      "DT prior: 45 nodes, depth=6\n",
      "  ep 01 | loss=0.4491 | P/R/F1=0.721/0.725/0.723 | exact=0.222\n",
      "  ep 02 | loss=0.3784 | P/R/F1=0.754/0.869/0.807 | exact=0.372\n",
      "  ep 03 | loss=0.3302 | P/R/F1=0.821/0.888/0.853 | exact=0.502\n",
      "  ep 04 | loss=0.2858 | P/R/F1=0.891/0.878/0.885 | exact=0.595\n",
      "  ep 05 | loss=0.2543 | P/R/F1=0.910/0.909/0.910 | exact=0.672\n",
      "  ep 06 | loss=0.2265 | P/R/F1=0.909/0.934/0.922 | exact=0.712\n",
      "  ep 07 | loss=0.2069 | P/R/F1=0.920/0.949/0.934 | exact=0.751\n",
      "  ep 08 | loss=0.1942 | P/R/F1=0.920/0.964/0.941 | exact=0.766\n",
      "  ep 09 | loss=0.1811 | P/R/F1=0.944/0.945/0.945 | exact=0.786\n",
      "  ep 10 | loss=0.1710 | P/R/F1=0.949/0.945/0.947 | exact=0.803\n",
      "  ep 11 | loss=0.1632 | P/R/F1=0.939/0.967/0.953 | exact=0.816\n",
      "  ep 12 | loss=0.1553 | P/R/F1=0.948/0.964/0.956 | exact=0.833\n",
      "  ep 13 | loss=0.1486 | P/R/F1=0.960/0.951/0.955 | exact=0.832\n",
      "  ep 14 | loss=0.1457 | P/R/F1=0.952/0.967/0.960 | exact=0.842\n",
      "  ep 15 | loss=0.1389 | P/R/F1=0.959/0.961/0.960 | exact=0.849\n",
      "best threshold: 0.390 | exact=0.861 | F1=0.964\n",
      "  best epoch: 15\n",
      "  final (thr=0.390): P/R/F1=0.955/0.972/0.964 | exact=0.861\n",
      "\n",
      "--- fold 4/5 ---\n",
      "train: 5064, val: 1266\n",
      "training DT prior...\n",
      "DT prior: 45 nodes, depth=6\n",
      "  ep 01 | loss=0.4479 | P/R/F1=0.700/0.798/0.746 | exact=0.241\n",
      "  ep 02 | loss=0.3643 | P/R/F1=0.807/0.787/0.797 | exact=0.367\n",
      "  ep 03 | loss=0.3147 | P/R/F1=0.831/0.872/0.851 | exact=0.492\n",
      "  ep 04 | loss=0.2785 | P/R/F1=0.865/0.906/0.885 | exact=0.588\n",
      "  ep 05 | loss=0.2516 | P/R/F1=0.884/0.917/0.900 | exact=0.637\n",
      "  ep 06 | loss=0.2303 | P/R/F1=0.891/0.931/0.910 | exact=0.675\n",
      "  ep 07 | loss=0.2135 | P/R/F1=0.903/0.941/0.922 | exact=0.700\n",
      "  ep 08 | loss=0.1990 | P/R/F1=0.902/0.950/0.925 | exact=0.716\n",
      "  ep 09 | loss=0.1881 | P/R/F1=0.941/0.926/0.933 | exact=0.745\n",
      "  ep 10 | loss=0.1774 | P/R/F1=0.922/0.955/0.938 | exact=0.759\n",
      "  ep 11 | loss=0.1689 | P/R/F1=0.931/0.949/0.940 | exact=0.770\n",
      "  ep 12 | loss=0.1599 | P/R/F1=0.943/0.954/0.949 | exact=0.803\n",
      "  ep 13 | loss=0.1545 | P/R/F1=0.935/0.965/0.949 | exact=0.803\n",
      "  ep 14 | loss=0.1509 | P/R/F1=0.945/0.959/0.952 | exact=0.814\n",
      "  ep 15 | loss=0.1484 | P/R/F1=0.952/0.958/0.955 | exact=0.829\n",
      "best threshold: 0.450 | exact=0.833 | F1=0.956\n",
      "  best epoch: 15\n",
      "  final (thr=0.450): P/R/F1=0.947/0.965/0.956 | exact=0.833\n",
      "\n",
      "--- fold 5/5 ---\n",
      "train: 5064, val: 1266\n",
      "training DT prior...\n",
      "DT prior: 45 nodes, depth=6\n",
      "  ep 01 | loss=0.4549 | P/R/F1=0.715/0.680/0.697 | exact=0.184\n",
      "  ep 02 | loss=0.3742 | P/R/F1=0.798/0.808/0.803 | exact=0.380\n",
      "  ep 03 | loss=0.3252 | P/R/F1=0.803/0.901/0.849 | exact=0.469\n",
      "  ep 04 | loss=0.2885 | P/R/F1=0.877/0.888/0.882 | exact=0.577\n",
      "  ep 05 | loss=0.2571 | P/R/F1=0.868/0.932/0.898 | exact=0.611\n",
      "  ep 06 | loss=0.2366 | P/R/F1=0.887/0.934/0.910 | exact=0.657\n",
      "  ep 07 | loss=0.2175 | P/R/F1=0.899/0.944/0.921 | exact=0.691\n",
      "  ep 08 | loss=0.2017 | P/R/F1=0.909/0.944/0.926 | exact=0.713\n",
      "  ep 09 | loss=0.1913 | P/R/F1=0.931/0.936/0.933 | exact=0.737\n",
      "  ep 10 | loss=0.1822 | P/R/F1=0.924/0.953/0.938 | exact=0.754\n",
      "  ep 11 | loss=0.1706 | P/R/F1=0.931/0.952/0.941 | exact=0.765\n",
      "  ep 12 | loss=0.1659 | P/R/F1=0.945/0.947/0.946 | exact=0.786\n",
      "  ep 13 | loss=0.1607 | P/R/F1=0.930/0.964/0.947 | exact=0.784\n",
      "  ep 14 | loss=0.1500 | P/R/F1=0.940/0.962/0.951 | exact=0.799\n",
      "  ep 15 | loss=0.1479 | P/R/F1=0.951/0.952/0.952 | exact=0.810\n",
      "best threshold: 0.430 | exact=0.817 | F1=0.954\n",
      "  best epoch: 15\n",
      "  final (thr=0.430): P/R/F1=0.948/0.961/0.954 | exact=0.817\n",
      "\n",
      "================================================================================\n",
      "CV SUMMARY\n",
      "================================================================================\n",
      "  fold 1: P=0.959, R=0.966, F1=0.963, EM=0.848\n",
      "  fold 2: P=0.954, R=0.975, F1=0.964, EM=0.855\n",
      "  fold 3: P=0.955, R=0.972, F1=0.964, EM=0.861\n",
      "  fold 4: P=0.947, R=0.965, F1=0.956, EM=0.833\n",
      "  fold 5: P=0.948, R=0.961, F1=0.954, EM=0.817\n",
      "\n",
      "mean +/- std over 5 folds:\n",
      "  precision: 0.953 +/- 0.004\n",
      "  recall:    0.968 +/- 0.005\n",
      "  F1:        0.960 +/- 0.004\n",
      "  exact:     0.842 +/- 0.016\n",
      "  threshold: 0.470 +/- 0.063\n",
      "\n",
      "best fold: 3 (exact=0.861)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "avg exact match: 0.842 +/- 0.016\n",
      "avg boundary F1: 0.960 +/- 0.004\n"
     ]
    }
   ],
   "source": [
    "# Run k-fold cross-validation\n",
    "kfold_results = run_kfold_cross_validation(\n",
    "    df=str_df,\n",
    "    n_folds=5,\n",
    "    epochs=15,\n",
    "    use_prior=True,\n",
    "    fuse_mode=\"logit_add\",\n",
    "    lambda_prior=0.1,\n",
    "    lambda_k=0.2,\n",
    "    hparams=best,\n",
    "    max_depth=6,\n",
    "    min_leaf=8,\n",
    "    random_state=RNG\n",
    ")\n",
    "\n",
    "print(f\"\\navg exact match: {kfold_results['mean_metrics']['exact_match']:.3f} +/- {kfold_results['std_metrics']['exact_match']:.3f}\")\n",
    "print(f\"avg boundary F1: {kfold_results['mean_metrics']['boundary_f1']:.3f} +/- {kfold_results['std_metrics']['boundary_f1']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a34f39df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: pikunas\n",
      "tokens: ['p', 'i', 'k', 'u', 'n', 'a', 's']\n",
      "probs: [0.0, 0.6949999928474426, 0.0, 0.9259999990463257, 0.0, 0.9929999709129333]\n",
      "segmented (thr=0.430): pi-ku-na-s\n"
     ]
    }
   ],
   "source": [
    "# Example segmentation\n",
    "word = \"pikunas\"\n",
    "tokens = tokenize_with_vocab(word, vocab, max_token_len=4)\n",
    "thr = out.get(\"best_thr\", 0.5)\n",
    "\n",
    "seg_string, boundary_probs = segment_tokens(\n",
    "    model, vocab, tokens, dt_clf=out[\"dt_clf\"], dt_vec=out[\"dt_vec\"], thr=thr\n",
    ")\n",
    "\n",
    "print(f\"word: {word}\")\n",
    "print(f\"tokens: {tokens}\")\n",
    "print(f\"probs: {np.round(boundary_probs, 3).tolist()}\")\n",
    "print(f\"segmented (thr={thr:.3f}): {seg_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbfbd2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- standard evaluation ---\n",
      "evaluated 913 words\n",
      "boundary (micro) P/R/F1 = 0.787/0.845/0.815\n",
      "exact match = 0.541\n",
      "\n",
      "samples:\n",
      "- unupas\n",
      "  tokens: ['u', 'n', 'u', 'p', 'a', 's']\n",
      "  pred:   unupa-s\n",
      "  gold:   unu-pas\n",
      "  P/R/F1: 0.0/0.0/0.0\n",
      "\n",
      "- umankus\n",
      "  tokens: ['u', 'm', 'a', 'n', 'k', 'u', 's']\n",
      "  pred:   uma-nku-s\n",
      "  gold:   uma-nku-s\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- hikurin\n",
      "  tokens: ['h', 'i', 'k', 'u', 'r', 'i', 'n']\n",
      "  pred:   hiku-ri-n\n",
      "  gold:   hikuri-n\n",
      "  P/R/F1: 0.5/1.0/0.667\n",
      "\n",
      "- sutipi\n",
      "  tokens: ['s', 'u', 't', 'i', 'p', 'i']\n",
      "  pred:   suti-pi\n",
      "  gold:   suti-pi\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- pikunas\n",
      "  tokens: ['p', 'i', 'k', 'u', 'n', 'a', 's']\n",
      "  pred:   pi-ku-na-s\n",
      "  gold:   pi-kuna-s\n",
      "  P/R/F1: 0.667/1.0/0.8\n",
      "\n",
      "- atipaq\n",
      "  tokens: ['a', 't', 'i', 'p', 'a', 'q']\n",
      "  pred:   atipaq\n",
      "  gold:   ati-paq\n",
      "  P/R/F1: 0.0/0.0/0.0\n",
      "\n",
      "- tomani\n",
      "  tokens: ['t', 'o', 'm', 'a', 'n', 'i']\n",
      "  pred:   toma-ni\n",
      "  gold:   toma-ni\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- rantiq\n",
      "  tokens: ['r', 'a', 'n', 't', 'i', 'q']\n",
      "  pred:   rantiq\n",
      "  gold:   ranti-q\n",
      "  P/R/F1: 0.0/0.0/0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "print(\"\\n--- standard evaluation ---\")\n",
    "results = evaluate_on_gold_df(\n",
    "    acc_df, model, vocab, out,\n",
    "    max_token_len=4,\n",
    "    use_tuned_thr=True,\n",
    "    show_sample=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13eac74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- evaluation with suffix filter ---\n",
      "tried 913 words\n",
      "rejected 265 (29.0%) with invalid suffixes\n",
      "scoring 648 valid predictions\n",
      "\n",
      "--- final scores (valid predictions only) ---\n",
      "boundary (micro) P/R/F1 = 0.838/0.899/0.867\n",
      "exact match = 0.648\n",
      "\n",
      "samples:\n",
      "- unupas\n",
      "  tokens: ['u', 'n', 'u', 'p', 'a', 's']\n",
      "  pred:   unupa-s\n",
      "  gold:   unu-pas\n",
      "  P/R/F1: 0.0/0.0/0.0\n",
      "\n",
      "- umankus\n",
      "  tokens: ['u', 'm', 'a', 'n', 'k', 'u', 's']\n",
      "  pred:   uma-nku-s\n",
      "  gold:   uma-nku-s\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- hikurin\n",
      "  tokens: ['h', 'i', 'k', 'u', 'r', 'i', 'n']\n",
      "  pred:   hiku-ri-n\n",
      "  gold:   hikuri-n\n",
      "  P/R/F1: 0.5/1.0/0.667\n",
      "\n",
      "- sutipi\n",
      "  tokens: ['s', 'u', 't', 'i', 'p', 'i']\n",
      "  pred:   suti-pi\n",
      "  gold:   suti-pi\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- pikunas\n",
      "  tokens: ['p', 'i', 'k', 'u', 'n', 'a', 's']\n",
      "  pred:   pi-ku-na-s\n",
      "  gold:   pi-kuna-s\n",
      "  P/R/F1: 0.667/1.0/0.8\n",
      "\n",
      "- atipaq\n",
      "  tokens: ['a', 't', 'i', 'p', 'a', 'q']\n",
      "  pred:   atipaq\n",
      "  gold:   ati-paq\n",
      "  P/R/F1: 0.0/0.0/0.0\n",
      "\n",
      "- tomani\n",
      "  tokens: ['t', 'o', 'm', 'a', 'n', 'i']\n",
      "  pred:   toma-ni\n",
      "  gold:   toma-ni\n",
      "  P/R/F1: 1.0/1.0/1.0\n",
      "\n",
      "- rantiq\n",
      "  tokens: ['r', 'a', 'n', 't', 'i', 'q']\n",
      "  pred:   rantiq\n",
      "  gold:   ranti-q\n",
      "  P/R/F1: 0.0/0.0/0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with suffix filter\n",
    "print(\"\\n--- evaluation with suffix filter ---\")\n",
    "results_filtered = evaluate_and_ignore_rejected(\n",
    "    acc_df, model, vocab, out,\n",
    "    allowed_suffixes=suffix_list,\n",
    "    show_sample=8\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
