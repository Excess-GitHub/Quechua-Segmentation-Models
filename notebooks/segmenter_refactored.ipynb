{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f763dff9",
   "metadata": {},
   "source": [
    "# Segmenter: Grapheme-Level BiLSTM Morphology Parser\n",
    "\n",
    "Character-level BiLSTM for Quechua morphological segmentation using grapheme-level tokenization. Recognizes Quechua multigraphs like 'ch', 'll', 'rr'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8fff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import ast\n",
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import math\n",
    "import random\n",
    "import unicodedata\n",
    "import string\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "# ML & DL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e8e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "DATA_FOLDER = \"data\"\n",
    "MODEL_NAME = \"segmenter\"\n",
    "MODELS_FOLDER = f\"models_{MODEL_NAME}\"\n",
    "os.makedirs(DATA_FOLDER, exist_ok=True)\n",
    "os.makedirs(MODELS_FOLDER, exist_ok=True)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "# Special tokens\n",
    "PAD, UNK = \"<PAD>\", \"<UNK>\"\n",
    "\n",
    "# Text normalization constants\n",
    "APOSTROPHE_CHARS = {\"'\", \"'\", \"ʼ\", \"‛\", \"`\"}\n",
    "STD_APOS = \"\\u02BC\"\n",
    "_EXTRA_PUNCT = \"±，“”‘’\"\n",
    "_DELETE = str.maketrans(\"\", \"\", string.punctuation + _EXTRA_PUNCT)\n",
    "\n",
    "# Quechua multigraphs\n",
    "QUECHUA_MULTIGRAPHS = [\n",
    "    \"ch\" + STD_APOS, \"k\" + STD_APOS, \"p\" + STD_APOS, \"q\" + STD_APOS, \"t\" + STD_APOS,\n",
    "    \"ch\", \"ph\", \"qh\", \"kh\", \"ll\", \"rr\", \"sh\",\n",
    "]\n",
    "MG_SET = set(QUECHUA_MULTIGRAPHS)\n",
    "MAX_MG = max((len(mg) for mg in QUECHUA_MULTIGRAPHS), default=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6e5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s: str) -> str:\n",
    "    \"\"\"Normalize text: NFC compose, lowercase, unify apostrophes, strip punctuation.\"\"\"\n",
    "    s = unicodedata.normalize(\"NFC\", str(s)).lower()\n",
    "    s = \"\".join(STD_APOS if ch in APOSTROPHE_CHARS else ch for ch in s)\n",
    "    s = s.translate(_DELETE).strip()\n",
    "    return s\n",
    "\n",
    "def to_graphemes_quechua(s: str) -> list[str]:\n",
    "    \"\"\"Greedy longest-match multigraph fusion; fallback to Unicode grapheme clusters.\"\"\"\n",
    "    s = normalize_text(s)\n",
    "    tokens, i, n = [], 0, len(s)\n",
    "    while i < n:\n",
    "        match = None\n",
    "        for L in range(MAX_MG, 1, -1):\n",
    "            if i + L <= n:\n",
    "                cand = s[i:i+L]\n",
    "                if cand in MG_SET:\n",
    "                    match = cand\n",
    "                    break\n",
    "        if match:\n",
    "            tokens.append(match)\n",
    "            i += len(match)\n",
    "        else:\n",
    "            m = re.match(r\"\\X\", s[i:])\n",
    "            g = m.group(0)\n",
    "            tokens.append(g)\n",
    "            i += len(g)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e5f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading gold data...\n",
      "got 6,896 gold examples\n"
     ]
    }
   ],
   "source": [
    "# Load gold standard data\n",
    "print(\"loading gold data...\")\n",
    "gold_df = pd.read_parquet(os.path.join(DATA_FOLDER, \"insert_your_data.parquet\"))\n",
    "gold_df['Word'] = gold_df['word']\n",
    "gold_df['morph'] = gold_df['morph'].str.replace('-', ' ')\n",
    "gold_df['Morph_split_str'] = gold_df['morph']\n",
    "gold_df['Morph_split'] = gold_df['morph'].str.split(' ')\n",
    "gold_df = gold_df[['Word', 'Morph_split', 'Morph_split_str']]\n",
    "gold_df.drop_duplicates(subset='Word', keep='first', inplace=True)\n",
    "gold_df.dropna(subset=['Word'], inplace=True)\n",
    "print(f\"got {len(gold_df):,} gold examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa9c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize words and morphemes to graphemes\n",
    "gold_df['token_seq'] = gold_df['Word'].apply(lambda w: to_graphemes_quechua(w))\n",
    "gold_df['morph_token_splits'] = gold_df['Morph_split'].apply(\n",
    "    lambda var: [to_graphemes_quechua(m) for m in var]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e29e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_labels_tokens(tokens: list[str], morph_tokens: list[list[str]]) -> list[int]:\n",
    "    \"\"\"Generate binary boundary labels for a word given its morpheme token splits.\"\"\"\n",
    "    labels = [0] * len(tokens)\n",
    "    idx = 0\n",
    "    for mt in morph_tokens[:-1]:\n",
    "        idx += len(mt)\n",
    "        if 0 < idx <= len(tokens):\n",
    "            labels[idx-1] = 1\n",
    "    return labels\n",
    "\n",
    "gold_df['boundary_labels'] = gold_df.apply(\n",
    "    lambda row: get_boundary_labels_tokens(row['token_seq'], row['morph_token_splits']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "gold_df['num_morphemes'] = gold_df['Morph_split'].apply(len)\n",
    "gold_df['word_len_tokens'] = gold_df['token_seq'].apply(len)\n",
    "gold_df['char_seq'] = gold_df['token_seq']  # compatibility alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de94b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 42 graphemes\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(seqs: List[List[str]]):\n",
    "    \"\"\"Build vocabulary from grapheme token sequences.\"\"\"\n",
    "    toks = {t for seq in seqs for t in seq}\n",
    "    itos = [PAD, UNK] + sorted(toks)\n",
    "    stoi = {t: i for i, t in enumerate(itos)}\n",
    "    return stoi, itos\n",
    "\n",
    "stoi, itos = build_vocab(gold_df[\"char_seq\"].tolist())\n",
    "print(f\"vocab size: {len(itos)} graphemes\")\n",
    "\n",
    "def encode(seq: List[str]) -> List[int]:\n",
    "    \"\"\"Convert grapheme sequence to integer IDs.\"\"\"\n",
    "    return [stoi.get(t, stoi[UNK]) for t in seq]\n",
    "\n",
    "def encode_labels(labels: List[int]) -> List[int]:\n",
    "    \"\"\"Labels are already 0/1.\"\"\"\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ecbdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharBoundaryDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for grapheme-level boundary prediction.\"\"\"\n",
    "    def __init__(self, df):\n",
    "        self.x = df[\"char_seq\"].tolist()\n",
    "        self.y = df[\"boundary_labels\"].tolist()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "def pad_batch(batch, pad_id=0):\n",
    "    \"\"\"Collate function: pads sequences to the same length.\"\"\"\n",
    "    seqs, labels = zip(*batch)\n",
    "    x_ids = [encode(s) for s in seqs]\n",
    "    y_ids = [encode_labels(y) for y in labels]\n",
    "    lengths = [len(x) for x in x_ids]\n",
    "    maxlen = max(lengths)\n",
    "    \n",
    "    x_pad = [xi + [pad_id] * (maxlen - len(xi)) for xi in x_ids]\n",
    "    y_pad = [yi + [0] * (maxlen - len(yi)) for yi in y_ids]\n",
    "    mask = [[1] * len(xi) + [0] * (maxlen - len(xi)) for xi in x_ids]\n",
    "    \n",
    "    return (\n",
    "        torch.LongTensor(x_pad),\n",
    "        torch.FloatTensor(y_pad),\n",
    "        torch.BoolTensor(mask),\n",
    "        torch.LongTensor(lengths),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829541ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 6,206 samples\n",
      "validation: 690 samples\n"
     ]
    }
   ],
   "source": [
    "# Train/validation split\n",
    "rng = np.random.default_rng(42)\n",
    "indices = np.arange(len(gold_df))\n",
    "rng.shuffle(indices)\n",
    "split = int(0.9 * len(indices))\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "\n",
    "train_df = gold_df.iloc[train_idx].reset_index(drop=True)\n",
    "val_df = gold_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "print(f\"training: {len(train_df):,} samples\")\n",
    "print(f\"validation: {len(val_df):,} samples\")\n",
    "\n",
    "train_ds = CharBoundaryDataset(train_df)\n",
    "val_ds = CharBoundaryDataset(val_df)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=pad_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a1824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMBoundary(nn.Module):\n",
    "    \"\"\"Bidirectional LSTM for grapheme-level boundary prediction.\"\"\"\n",
    "    def __init__(self, vocab_size: int, emb_dim: int = 16, hidden_size: int = 16, \n",
    "                 num_layers: int = 1, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(hidden_size * 2, 1)\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"Forward pass through the model.\"\"\"\n",
    "        emb = self.emb(x)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.lstm(packed)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "        out = self.dropout(out)\n",
    "        logits = self.out(out).squeeze(-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a60af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pos_neg(df_):\n",
    "    \"\"\"Count positive and negative examples for class weighting.\"\"\"\n",
    "    pos = sum(sum(lbls) for lbls in df_['boundary_labels'])\n",
    "    total = sum(len(seq) for seq in df_['char_seq'])\n",
    "    neg = total - pos\n",
    "    return pos, neg\n",
    "\n",
    "pos, neg = count_pos_neg(gold_df)\n",
    "pos_weight_value = float(neg) / max(float(pos), 1.0)\n",
    "\n",
    "def masked_bce_loss(logits, targets, mask):\n",
    "    \"\"\"Compute masked binary cross-entropy loss.\"\"\"\n",
    "    loss_fn = nn.BCEWithLogitsLoss(reduction=\"none\",\n",
    "                                   pos_weight=torch.tensor(pos_weight_value, device=logits.device))\n",
    "    loss_per_token = loss_fn(logits, targets) * mask.float()\n",
    "    denom = mask.float().sum().clamp_min(1.0)\n",
    "    return loss_per_token.sum() / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30997739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_f1(logits, targets, mask, threshold=0.5):\n",
    "    \"\"\"Compute precision, recall, and F1 for boundary prediction.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= threshold).long()\n",
    "        t = targets.long()\n",
    "        m = mask.long()\n",
    "\n",
    "        tp = ((preds == 1) & (t == 1) & (m == 1)).sum().item()\n",
    "        fp = ((preds == 1) & (t == 0) & (m == 1)).sum().item()\n",
    "        fn = ((preds == 0) & (t == 1) & (m == 1)).sum().item()\n",
    "\n",
    "        prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        rec = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0.0\n",
    "        return prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_boundaries(words: List[str], model, stoi, threshold=0.5, device=device) -> List[List[int]]:\n",
    "    \"\"\"Predict boundary labels for a list of words.\"\"\"\n",
    "    model.eval()\n",
    "    token_lists = [to_graphemes_quechua(w) for w in words]\n",
    "    x_ids = [[stoi.get(t, stoi[UNK]) for t in toks] for toks in token_lists]\n",
    "    lengths = [len(x) for x in x_ids]\n",
    "    maxlen = max(lengths) if lengths else 0\n",
    "    pad_id = stoi[PAD]\n",
    "\n",
    "    x_pad = [xi + [pad_id] * (maxlen - len(xi)) for xi in x_ids]\n",
    "    mask = [[1] * len(xi) + [0] * (maxlen - len(xi)) for xi in x_ids]\n",
    "\n",
    "    x = torch.LongTensor(x_pad).to(device)\n",
    "    lengths_t = torch.LongTensor(lengths).to(device)\n",
    "    mask_t = torch.BoolTensor(mask).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x, lengths_t)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= threshold) & mask_t\n",
    "\n",
    "    out = []\n",
    "    for i, L in enumerate(lengths):\n",
    "        out.append(preds[i, :L].int().tolist())\n",
    "    return out\n",
    "\n",
    "def apply_boundaries_tokens(tokens: list[str], boundary_labels: List[int]) -> List[str]:\n",
    "    \"\"\"Reconstruct morphemes from grapheme token list and boundary labels.\"\"\"\n",
    "    segs, start = [], 0\n",
    "    for i, b in enumerate(boundary_labels):\n",
    "        if b == 1:\n",
    "            segs.append(\"\".join(tokens[start:i+1]))\n",
    "            start = i + 1\n",
    "    if start < len(tokens):\n",
    "        segs.append(\"\".join(tokens[start:]))\n",
    "    return segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd4f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_id(emb_dim, hidden_size, num_layers, dropout, epochs, batch_size, lr, weight_decay):\n",
    "    \"\"\"Hash training params to get unique model ID.\"\"\"\n",
    "    params_dict = {\n",
    "        'emb_dim': emb_dim,\n",
    "        'hidden_size': hidden_size,\n",
    "        'num_layers': num_layers,\n",
    "        'dropout': dropout,\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'lr': lr,\n",
    "        'weight_decay': weight_decay,\n",
    "        'vocab_size': len(itos)\n",
    "    }\n",
    "    params_str = json.dumps(params_dict, sort_keys=True)\n",
    "    return hashlib.md5(params_str.encode()).hexdigest()[:16]\n",
    "\n",
    "def save_model_checkpoint(model, stoi, itos, model_id, models_folder=MODELS_FOLDER):\n",
    "    \"\"\"Save model checkpoint.\"\"\"\n",
    "    model_dir = os.path.join(models_folder, model_id)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    checkpoint_path = os.path.join(model_dir, \"bilstm_grapheme_boundary.pt\")\n",
    "    torch.save({\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"stoi\": stoi,\n",
    "        \"itos\": itos\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    metadata_path = os.path.join(model_dir, \"metadata.json\")\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            'model_id': model_id,\n",
    "            'vocab_size': len(itos),\n",
    "            'model_name': MODEL_NAME\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"saved checkpoint to {model_dir}\")\n",
    "    return model_dir\n",
    "\n",
    "def load_model_checkpoint(model_id, models_folder=MODELS_FOLDER):\n",
    "    \"\"\"Load model checkpoint.\"\"\"\n",
    "    model_dir = os.path.join(models_folder, model_id)\n",
    "    checkpoint_path = os.path.join(model_dir, \"bilstm_grapheme_boundary.pt\")\n",
    "    \n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        return None\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    print(f\"loaded checkpoint from {model_dir}\")\n",
    "    return {\n",
    "        'model_state': checkpoint['model_state'],\n",
    "        'stoi': checkpoint['stoi'],\n",
    "        'itos': checkpoint['itos'],\n",
    "        'checkpoint_path': checkpoint_path,\n",
    "        'model_dir': model_dir\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14489a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for model df7336ba5b7b6893...\n",
      "loaded checkpoint from models_segmenter\\df7336ba5b7b6893\n",
      "found it! loading from models_segmenter\\df7336ba5b7b6893\n",
      "skipping training, model ready\n"
     ]
    }
   ],
   "source": [
    "# Model hyperparameters\n",
    "EMB_DIM = 64\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.1\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Generate model identifier\n",
    "model_id = generate_model_id(EMB_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT, EPOCHS, BATCH_SIZE, LR, WEIGHT_DECAY)\n",
    "\n",
    "# Try to load existing model\n",
    "print(f\"looking for model {model_id}...\")\n",
    "loaded = load_model_checkpoint(model_id, models_folder=MODELS_FOLDER)\n",
    "\n",
    "if loaded is not None:\n",
    "    print(f\"found it! loading from {loaded['model_dir']}\")\n",
    "    stoi = loaded['stoi']\n",
    "    itos = loaded['itos']\n",
    "    model = BiLSTMBoundary(vocab_size=len(itos), emb_dim=EMB_DIM, hidden_size=HIDDEN_SIZE,\n",
    "                           num_layers=NUM_LAYERS, dropout=DROPOUT).to(device)\n",
    "    model.load_state_dict(loaded['model_state'])\n",
    "    model.eval()\n",
    "    print(\"skipping training, model ready\")\n",
    "else:\n",
    "    print(f\"not found, training from scratch...\")\n",
    "    \n",
    "    model = BiLSTMBoundary(vocab_size=len(itos), emb_dim=EMB_DIM, hidden_size=HIDDEN_SIZE,\n",
    "                          num_layers=NUM_LAYERS, dropout=DROPOUT).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    best_val_f1 = 0.0\n",
    "    \n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_tokens = 0\n",
    "        for x, y, mask, lengths in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            mask = mask.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            logits = model(x, lengths)\n",
    "            loss = masked_bce_loss(logits, y, mask)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * mask.sum().item()\n",
    "            total_tokens += mask.sum().item()\n",
    "\n",
    "        train_loss = total_loss / max(total_tokens, 1)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_tokens = 0.0, 0\n",
    "        all_prec, all_rec, all_f1 = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y, mask, lengths in val_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                mask = mask.to(device)\n",
    "                lengths = lengths.to(device)\n",
    "\n",
    "                logits = model(x, lengths)\n",
    "                loss = masked_bce_loss(logits, y, mask)\n",
    "                val_loss += loss.item() * mask.sum().item()\n",
    "                val_tokens += mask.sum().item()\n",
    "\n",
    "                p, r, f = boundary_f1(logits, y, mask, threshold=0.5)\n",
    "                all_prec.append(p)\n",
    "                all_rec.append(r)\n",
    "                all_f1.append(f)\n",
    "\n",
    "        val_loss = val_loss / max(val_tokens, 1)\n",
    "        prec = np.mean(all_prec) if all_prec else 0.0\n",
    "        rec = np.mean(all_rec) if all_rec else 0.0\n",
    "        f1 = np.mean(all_f1) if all_f1 else 0.0\n",
    "\n",
    "        print(f\"epoch {epoch:02d} | train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  P={prec:.3f} R={rec:.3f} F1={f1:.3f}\")\n",
    "\n",
    "        if f1 > best_val_f1:\n",
    "            best_val_f1 = f1\n",
    "            save_model_checkpoint(model, stoi, itos, model_id, models_folder=MODELS_FOLDER)\n",
    "            print(\"  ↳ saved checkpoint (best F1 so far)\")\n",
    "    \n",
    "    print(f\"\\ntraining done! best validation F1: {best_val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6616821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_cross_validation(\n",
    "    df,\n",
    "    n_folds=5,\n",
    "    emb_dim=64,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.1,\n",
    "    epochs=15,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    random_state=42,\n",
    "    device=device\n",
    "):\n",
    "    \"\"\"K-fold cross-validation for more robust evaluation.\"\"\"\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"K-FOLD CV (k={n_folds})\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    indices = np.arange(len(df))\n",
    "    \n",
    "    fold_results = []\n",
    "    all_metrics = {\n",
    "        'boundary_precision': [],\n",
    "        'boundary_recall': [],\n",
    "        'boundary_f1': [],\n",
    "        'val_loss': []\n",
    "    }\n",
    "    \n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(kfold.split(indices), 1):\n",
    "        print(f\"\\n--- fold {fold_idx}/{n_folds} ---\")\n",
    "        print(f\"train: {len(train_indices)}, val: {len(val_indices)}\")\n",
    "        \n",
    "        train_df_fold = df.iloc[train_indices].reset_index(drop=True)\n",
    "        val_df_fold = df.iloc[val_indices].reset_index(drop=True)\n",
    "        \n",
    "        stoi_fold, itos_fold = build_vocab(train_df_fold[\"char_seq\"].tolist())\n",
    "        vocab_size = len(itos_fold)\n",
    "        \n",
    "        # Create fold-specific collate function that uses fold vocabulary\n",
    "        pad_id_fold = stoi_fold[PAD]\n",
    "        unk_id_fold = stoi_fold[UNK]\n",
    "        \n",
    "        def pad_batch_fold(batch):\n",
    "            seqs, labels = zip(*batch)\n",
    "            x_ids = [[stoi_fold.get(t, unk_id_fold) for t in s] for s in seqs]\n",
    "            # Clamp indices to valid range (safety check)\n",
    "            x_ids = [[min(max(idx, 0), vocab_size - 1) for idx in seq] for seq in x_ids]\n",
    "            y_ids = [encode_labels(y) for y in labels]\n",
    "            lengths = [len(x) for x in x_ids]\n",
    "            maxlen = max(lengths) if lengths else 0\n",
    "            \n",
    "            x_pad = [xi + [pad_id_fold] * (maxlen - len(xi)) for xi in x_ids]\n",
    "            y_pad = [yi + [0] * (maxlen - len(yi)) for yi in y_ids]\n",
    "            mask = [[1] * len(xi) + [0] * (maxlen - len(xi)) for xi in x_ids]\n",
    "            \n",
    "            return (\n",
    "                torch.LongTensor(x_pad),\n",
    "                torch.FloatTensor(y_pad),\n",
    "                torch.BoolTensor(mask),\n",
    "                torch.LongTensor(lengths),\n",
    "            )\n",
    "        \n",
    "        train_ds_fold = CharBoundaryDataset(train_df_fold)\n",
    "        val_ds_fold = CharBoundaryDataset(val_df_fold)\n",
    "        train_loader_fold = DataLoader(train_ds_fold, batch_size=batch_size, shuffle=True, collate_fn=pad_batch_fold)\n",
    "        val_loader_fold = DataLoader(val_ds_fold, batch_size=batch_size, shuffle=False, collate_fn=pad_batch_fold)\n",
    "        \n",
    "        model_fold = BiLSTMBoundary(\n",
    "            vocab_size=vocab_size,\n",
    "            emb_dim=emb_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer_fold = torch.optim.AdamW(model_fold.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        \n",
    "        best_val_f1 = 0.0\n",
    "        best_val_prec = 0.0\n",
    "        best_val_rec = 0.0\n",
    "        best_val_loss = float('inf')\n",
    "        best_epoch = 0\n",
    "        \n",
    "        for epoch in range(1, epochs + 1):\n",
    "            model_fold.train()\n",
    "            total_loss = 0.0\n",
    "            total_tokens = 0\n",
    "            for x, y, mask, lengths in train_loader_fold:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                mask = mask.to(device)\n",
    "                lengths = lengths.to(device)\n",
    "                \n",
    "                logits = model_fold(x, lengths)\n",
    "                loss = masked_bce_loss(logits, y, mask)\n",
    "                \n",
    "                optimizer_fold.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model_fold.parameters(), 1.0)\n",
    "                optimizer_fold.step()\n",
    "                \n",
    "                total_loss += loss.item() * mask.sum().item()\n",
    "                total_tokens += mask.sum().item()\n",
    "            \n",
    "            train_loss = total_loss / max(total_tokens, 1)\n",
    "            \n",
    "            model_fold.eval()\n",
    "            val_loss, val_tokens = 0.0, 0\n",
    "            all_prec, all_rec, all_f1 = [], [], []\n",
    "            with torch.no_grad():\n",
    "                for x, y, mask, lengths in val_loader_fold:\n",
    "                    x = x.to(device)\n",
    "                    y = y.to(device)\n",
    "                    mask = mask.to(device)\n",
    "                    lengths = lengths.to(device)\n",
    "                    \n",
    "                    logits = model_fold(x, lengths)\n",
    "                    loss = masked_bce_loss(logits, y, mask)\n",
    "                    val_loss += loss.item() * mask.sum().item()\n",
    "                    val_tokens += mask.sum().item()\n",
    "                    \n",
    "                    p, r, f = boundary_f1(logits, y, mask, threshold=0.5)\n",
    "                    all_prec.append(p)\n",
    "                    all_rec.append(r)\n",
    "                    all_f1.append(f)\n",
    "            \n",
    "            val_loss = val_loss / max(val_tokens, 1)\n",
    "            prec = np.mean(all_prec) if all_prec else 0.0\n",
    "            rec = np.mean(all_rec) if all_rec else 0.0\n",
    "            f1 = np.mean(all_f1) if all_f1 else 0.0\n",
    "            \n",
    "            print(f\"  ep {epoch:02d} | train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  P={prec:.3f} R={rec:.3f} F1={f1:.3f}\")\n",
    "            \n",
    "            if f1 > best_val_f1 or (np.isclose(f1, best_val_f1) and val_loss < best_val_loss):\n",
    "                best_val_f1 = f1\n",
    "                best_val_prec = prec\n",
    "                best_val_rec = rec\n",
    "                best_val_loss = val_loss\n",
    "                best_epoch = epoch\n",
    "        \n",
    "        print(f\"\\n  best epoch: {best_epoch}\")\n",
    "        print(f\"  best validation: P={best_val_prec:.3f} R={best_val_rec:.3f} F1={best_val_f1:.3f} Loss={best_val_loss:.4f}\")\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold_idx,\n",
    "            'boundary_precision': best_val_prec,\n",
    "            'boundary_recall': best_val_rec,\n",
    "            'boundary_f1': best_val_f1,\n",
    "            'val_loss': best_val_loss,\n",
    "            'best_epoch': best_epoch\n",
    "        })\n",
    "        \n",
    "        all_metrics['boundary_precision'].append(best_val_prec)\n",
    "        all_metrics['boundary_recall'].append(best_val_rec)\n",
    "        all_metrics['boundary_f1'].append(best_val_f1)\n",
    "        all_metrics['val_loss'].append(best_val_loss)\n",
    "    \n",
    "    mean_metrics = {k: np.mean(v) for k, v in all_metrics.items()}\n",
    "    std_metrics = {k: np.std(v) for k, v in all_metrics.items()}\n",
    "    best_fold_idx = max(range(len(fold_results)), key=lambda i: fold_results[i]['boundary_f1'])\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"CV SUMMARY\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    for r in fold_results:\n",
    "        print(f\"  fold {r['fold']}: P={r['boundary_precision']:.3f}, R={r['boundary_recall']:.3f}, \"\n",
    "              f\"F1={r['boundary_f1']:.3f}, Loss={r['val_loss']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nmean +/- std over {n_folds} folds:\")\n",
    "    print(f\"  precision: {mean_metrics['boundary_precision']:.3f} +/- {std_metrics['boundary_precision']:.3f}\")\n",
    "    print(f\"  recall:    {mean_metrics['boundary_recall']:.3f} +/- {std_metrics['boundary_recall']:.3f}\")\n",
    "    print(f\"  F1:        {mean_metrics['boundary_f1']:.3f} +/- {std_metrics['boundary_f1']:.3f}\")\n",
    "    print(f\"  loss:      {mean_metrics['val_loss']:.4f} +/- {std_metrics['val_loss']:.4f}\")\n",
    "    print(f\"\\nbest fold: {fold_results[best_fold_idx]['fold']} (F1={fold_results[best_fold_idx]['boundary_f1']:.3f})\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'fold_results': fold_results,\n",
    "        'mean_metrics': mean_metrics,\n",
    "        'std_metrics': std_metrics,\n",
    "        'best_fold_idx': best_fold_idx,\n",
    "        'all_metrics': all_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bd70ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "K-FOLD CV (k=5)\n",
      "================================================================================\n",
      "\n",
      "--- fold 1/5 ---\n",
      "train: 5516, val: 1380\n",
      "  ep 01 | train_loss=0.5466  val_loss=0.2688  P=0.759 R=0.970 F1=0.851\n",
      "  ep 02 | train_loss=0.2170  val_loss=0.1778  P=0.865 R=0.966 F1=0.912\n",
      "  ep 03 | train_loss=0.1602  val_loss=0.1429  P=0.889 R=0.978 F1=0.931\n",
      "  ep 04 | train_loss=0.1341  val_loss=0.1332  P=0.905 R=0.972 F1=0.937\n",
      "  ep 05 | train_loss=0.1164  val_loss=0.1173  P=0.898 R=0.982 F1=0.938\n",
      "  ep 06 | train_loss=0.1012  val_loss=0.1280  P=0.929 R=0.959 F1=0.944\n",
      "  ep 07 | train_loss=0.0853  val_loss=0.1164  P=0.928 R=0.971 F1=0.949\n",
      "  ep 08 | train_loss=0.0784  val_loss=0.0979  P=0.909 R=0.988 F1=0.947\n",
      "  ep 09 | train_loss=0.0621  val_loss=0.0948  P=0.915 R=0.988 F1=0.950\n",
      "  ep 10 | train_loss=0.0580  val_loss=0.1129  P=0.948 R=0.970 F1=0.959\n",
      "  ep 11 | train_loss=0.0512  val_loss=0.1007  P=0.931 R=0.981 F1=0.955\n",
      "  ep 12 | train_loss=0.0449  val_loss=0.0985  P=0.937 R=0.981 F1=0.958\n",
      "  ep 13 | train_loss=0.0377  val_loss=0.1118  P=0.944 R=0.974 F1=0.959\n",
      "  ep 14 | train_loss=0.0327  val_loss=0.0976  P=0.929 R=0.984 F1=0.956\n",
      "  ep 15 | train_loss=0.0365  val_loss=0.1119  P=0.947 R=0.969 F1=0.958\n",
      "\n",
      "  best epoch: 10\n",
      "  best validation: P=0.948 R=0.970 F1=0.959 Loss=0.1129\n",
      "\n",
      "--- fold 2/5 ---\n",
      "train: 5517, val: 1379\n",
      "  ep 01 | train_loss=0.5438  val_loss=0.2615  P=0.754 R=0.969 F1=0.848\n",
      "  ep 02 | train_loss=0.2016  val_loss=0.1852  P=0.877 R=0.958 F1=0.916\n",
      "  ep 03 | train_loss=0.1531  val_loss=0.1750  P=0.905 R=0.952 F1=0.928\n",
      "  ep 04 | train_loss=0.1255  val_loss=0.1480  P=0.891 R=0.970 F1=0.928\n",
      "  ep 05 | train_loss=0.1047  val_loss=0.1369  P=0.890 R=0.975 F1=0.931\n",
      "  ep 06 | train_loss=0.0881  val_loss=0.1396  P=0.927 R=0.959 F1=0.943\n",
      "  ep 07 | train_loss=0.0754  val_loss=0.1206  P=0.903 R=0.981 F1=0.940\n",
      "  ep 08 | train_loss=0.0655  val_loss=0.1287  P=0.937 R=0.961 F1=0.949\n",
      "  ep 09 | train_loss=0.0629  val_loss=0.1252  P=0.914 R=0.972 F1=0.942\n",
      "  ep 10 | train_loss=0.0502  val_loss=0.1184  P=0.922 R=0.978 F1=0.949\n",
      "  ep 11 | train_loss=0.0454  val_loss=0.1288  P=0.934 R=0.969 F1=0.951\n",
      "  ep 12 | train_loss=0.0443  val_loss=0.1205  P=0.926 R=0.975 F1=0.950\n",
      "  ep 13 | train_loss=0.0371  val_loss=0.1185  P=0.933 R=0.971 F1=0.951\n",
      "  ep 14 | train_loss=0.0342  val_loss=0.1272  P=0.924 R=0.977 F1=0.949\n",
      "  ep 15 | train_loss=0.0311  val_loss=0.1298  P=0.922 R=0.976 F1=0.948\n",
      "\n",
      "  best epoch: 13\n",
      "  best validation: P=0.933 R=0.971 F1=0.951 Loss=0.1185\n",
      "\n",
      "--- fold 3/5 ---\n",
      "train: 5517, val: 1379\n",
      "  ep 01 | train_loss=0.5358  val_loss=0.2599  P=0.794 R=0.949 F1=0.864\n",
      "  ep 02 | train_loss=0.2097  val_loss=0.1915  P=0.799 R=0.988 F1=0.883\n",
      "  ep 03 | train_loss=0.1576  val_loss=0.1408  P=0.874 R=0.978 F1=0.923\n",
      "  ep 04 | train_loss=0.1280  val_loss=0.1457  P=0.850 R=0.990 F1=0.914\n",
      "  ep 05 | train_loss=0.1092  val_loss=0.1160  P=0.917 R=0.978 F1=0.946\n",
      "  ep 06 | train_loss=0.0910  val_loss=0.1078  P=0.894 R=0.988 F1=0.939\n",
      "  ep 07 | train_loss=0.0826  val_loss=0.1005  P=0.920 R=0.981 F1=0.950\n",
      "  ep 08 | train_loss=0.0649  val_loss=0.1012  P=0.921 R=0.982 F1=0.950\n",
      "  ep 09 | train_loss=0.0589  val_loss=0.0973  P=0.924 R=0.983 F1=0.952\n",
      "  ep 10 | train_loss=0.0542  val_loss=0.1018  P=0.918 R=0.985 F1=0.950\n",
      "  ep 11 | train_loss=0.0478  val_loss=0.0999  P=0.928 R=0.981 F1=0.954\n",
      "  ep 12 | train_loss=0.0428  val_loss=0.0953  P=0.934 R=0.982 F1=0.957\n",
      "  ep 13 | train_loss=0.0381  val_loss=0.0975  P=0.942 R=0.979 F1=0.960\n",
      "  ep 14 | train_loss=0.0335  val_loss=0.1023  P=0.938 R=0.981 F1=0.959\n",
      "  ep 15 | train_loss=0.0329  val_loss=0.1019  P=0.917 R=0.985 F1=0.950\n",
      "\n",
      "  best epoch: 13\n",
      "  best validation: P=0.942 R=0.979 F1=0.960 Loss=0.0975\n",
      "\n",
      "--- fold 4/5 ---\n",
      "train: 5517, val: 1379\n",
      "  ep 01 | train_loss=0.5386  val_loss=0.2737  P=0.807 R=0.934 F1=0.866\n",
      "  ep 02 | train_loss=0.2185  val_loss=0.1832  P=0.863 R=0.963 F1=0.910\n",
      "  ep 03 | train_loss=0.1577  val_loss=0.1507  P=0.852 R=0.984 F1=0.913\n",
      "  ep 04 | train_loss=0.1273  val_loss=0.1312  P=0.899 R=0.974 F1=0.935\n",
      "  ep 05 | train_loss=0.1099  val_loss=0.1295  P=0.867 R=0.988 F1=0.923\n",
      "  ep 06 | train_loss=0.0921  val_loss=0.1187  P=0.901 R=0.979 F1=0.939\n",
      "  ep 07 | train_loss=0.0760  val_loss=0.1057  P=0.919 R=0.982 F1=0.949\n",
      "  ep 08 | train_loss=0.0640  val_loss=0.1172  P=0.890 R=0.990 F1=0.937\n",
      "  ep 09 | train_loss=0.0596  val_loss=0.1034  P=0.916 R=0.984 F1=0.948\n",
      "  ep 10 | train_loss=0.0531  val_loss=0.1021  P=0.914 R=0.988 F1=0.949\n",
      "  ep 11 | train_loss=0.0533  val_loss=0.1003  P=0.929 R=0.978 F1=0.953\n",
      "  ep 12 | train_loss=0.0417  val_loss=0.1036  P=0.931 R=0.980 F1=0.954\n",
      "  ep 13 | train_loss=0.0352  val_loss=0.1064  P=0.931 R=0.978 F1=0.953\n",
      "  ep 14 | train_loss=0.0343  val_loss=0.1112  P=0.928 R=0.977 F1=0.952\n",
      "  ep 15 | train_loss=0.0332  val_loss=0.1105  P=0.943 R=0.979 F1=0.960\n",
      "\n",
      "  best epoch: 15\n",
      "  best validation: P=0.943 R=0.979 F1=0.960 Loss=0.1105\n",
      "\n",
      "--- fold 5/5 ---\n",
      "train: 5517, val: 1379\n",
      "  ep 01 | train_loss=0.5417  val_loss=0.2658  P=0.748 R=0.972 F1=0.845\n",
      "  ep 02 | train_loss=0.2134  val_loss=0.1900  P=0.829 R=0.971 F1=0.894\n",
      "  ep 03 | train_loss=0.1600  val_loss=0.1520  P=0.887 R=0.968 F1=0.925\n",
      "  ep 04 | train_loss=0.1298  val_loss=0.1390  P=0.895 R=0.973 F1=0.933\n",
      "  ep 05 | train_loss=0.1091  val_loss=0.1263  P=0.882 R=0.985 F1=0.930\n",
      "  ep 06 | train_loss=0.0938  val_loss=0.1147  P=0.894 R=0.984 F1=0.937\n",
      "  ep 07 | train_loss=0.0798  val_loss=0.1157  P=0.908 R=0.975 F1=0.940\n",
      "  ep 08 | train_loss=0.0696  val_loss=0.1041  P=0.894 R=0.991 F1=0.939\n",
      "  ep 09 | train_loss=0.0594  val_loss=0.1101  P=0.918 R=0.978 F1=0.947\n",
      "  ep 10 | train_loss=0.0563  val_loss=0.1022  P=0.923 R=0.982 F1=0.952\n",
      "  ep 11 | train_loss=0.0457  val_loss=0.1077  P=0.935 R=0.975 F1=0.955\n",
      "  ep 12 | train_loss=0.0417  val_loss=0.1044  P=0.927 R=0.979 F1=0.952\n",
      "  ep 13 | train_loss=0.0405  val_loss=0.1124  P=0.927 R=0.977 F1=0.951\n",
      "  ep 14 | train_loss=0.0347  val_loss=0.1126  P=0.936 R=0.977 F1=0.956\n",
      "  ep 15 | train_loss=0.0351  val_loss=0.1172  P=0.929 R=0.978 F1=0.952\n",
      "\n",
      "  best epoch: 14\n",
      "  best validation: P=0.936 R=0.977 F1=0.956 Loss=0.1126\n",
      "\n",
      "================================================================================\n",
      "CV SUMMARY\n",
      "================================================================================\n",
      "  fold 1: P=0.948, R=0.970, F1=0.959, Loss=0.1129\n",
      "  fold 2: P=0.933, R=0.971, F1=0.951, Loss=0.1185\n",
      "  fold 3: P=0.942, R=0.979, F1=0.960, Loss=0.0975\n",
      "  fold 4: P=0.943, R=0.979, F1=0.960, Loss=0.1105\n",
      "  fold 5: P=0.936, R=0.977, F1=0.956, Loss=0.1126\n",
      "\n",
      "mean +/- std over 5 folds:\n",
      "  precision: 0.940 +/- 0.005\n",
      "  recall:    0.975 +/- 0.004\n",
      "  F1:        0.957 +/- 0.003\n",
      "  loss:      0.1104 +/- 0.0070\n",
      "\n",
      "best fold: 4 (F1=0.960)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "avg boundary F1: 0.957 +/- 0.003\n",
      "avg precision: 0.940 +/- 0.005\n",
      "avg recall: 0.975 +/- 0.004\n"
     ]
    }
   ],
   "source": [
    "# Run k-fold cross-validation\n",
    "kfold_results = run_kfold_cross_validation(\n",
    "    df=gold_df,\n",
    "    n_folds=5,\n",
    "    emb_dim=EMB_DIM,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    random_state=42,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"\\navg boundary F1: {kfold_results['mean_metrics']['boundary_f1']:.3f} +/- {kfold_results['std_metrics']['boundary_f1']:.3f}\")\n",
    "print(f\"avg precision: {kfold_results['mean_metrics']['boundary_precision']:.3f} +/- {kfold_results['std_metrics']['boundary_precision']:.3f}\")\n",
    "print(f\"avg recall: {kfold_results['mean_metrics']['boundary_recall']:.3f} +/- {kfold_results['std_metrics']['boundary_recall']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db970af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rikuchkani [0, 0, 0, 1, 0, 0, 1, 0, 0] -> ['riku', 'chka', 'ni']\n",
      "pikunas [0, 1, 0, 0, 0, 1, 0] -> ['pi', 'kuna', 's']\n",
      "ñichkanchus [0, 1, 0, 0, 1, 1, 0, 0, 0] -> ['ñi', 'chka', 'n', 'chus']\n"
     ]
    }
   ],
   "source": [
    "# Example predictions\n",
    "test_words = [\"rikuchkani\", \"pikunas\", \"ñichkanchus\"]\n",
    "pred_b = predict_boundaries(test_words, model, stoi, threshold=0.5)\n",
    "for w, b in zip(test_words, pred_b):\n",
    "    toks = to_graphemes_quechua(w)\n",
    "    print(f\"{w} {b} -> {apply_boundaries_tokens(toks, b)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_positions_from_labels(labels, L=None):\n",
    "    \"\"\"Convert per-token boundary labels into boundary positions.\"\"\"\n",
    "    if not labels:\n",
    "        return set()\n",
    "    if L is None:\n",
    "        L = len(labels)\n",
    "    upto = min(L - 1, len(labels))\n",
    "    return {i for i in range(upto) if labels[i] == 1}\n",
    "\n",
    "def boundary_positions_from_morpheme_tokens(morpheme_token_lists):\n",
    "    \"\"\"Given morpheme token lists, return boundary positions.\"\"\"\n",
    "    pos = set()\n",
    "    acc = 0\n",
    "    for k, toks in enumerate(morpheme_token_lists):\n",
    "        acc += len(toks)\n",
    "        if k < len(morpheme_token_lists) - 1:\n",
    "            pos.add(acc - 1)\n",
    "    return pos\n",
    "\n",
    "def prf_from_sets(pred_set, gold_set):\n",
    "    \"\"\"Compute precision, recall, F1 from boundary sets.\"\"\"\n",
    "    tp = len(pred_set & gold_set)\n",
    "    fp = len(pred_set - gold_set)\n",
    "    fn = len(gold_set - pred_set)\n",
    "\n",
    "    if tp + fp == 0:\n",
    "        precision = 1.0 if (tp + fn == 0) else 0.0\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "\n",
    "    if tp + fn == 0:\n",
    "        recall = 1.0 if (tp + fp == 0) else 0.0\n",
    "    else:\n",
    "        recall = tp / (tp + fn)\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        f1 = 1.0 if (tp + fp + fn) == 0 else 0.0\n",
    "    else:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    return tp, fp, fn, precision, recall, f1\n",
    "\n",
    "def best_variant_metrics_token_space(word_tokens, pred_boundary_labels, gold_variants):\n",
    "    \"\"\"Compare predicted boundaries against gold variants, pick best F1.\"\"\"\n",
    "    pred_b = boundary_positions_from_labels(pred_boundary_labels, L=len(word_tokens))\n",
    "\n",
    "    best = None\n",
    "    for variant in gold_variants:\n",
    "        variant_token_lists = [to_graphemes_quechua(m) for m in variant]\n",
    "        gold_b = boundary_positions_from_morpheme_tokens(variant_token_lists)\n",
    "        tp, fp, fn, P, R, F1 = prf_from_sets(pred_b, gold_b)\n",
    "        key = (F1, tp, -fn, -fp)\n",
    "        if (best is None) or (key > best[0]):\n",
    "            best = (key, gold_b, tp, fp, fn, P, R, F1)\n",
    "\n",
    "    if best is None:\n",
    "        gold_b = set()\n",
    "        tp, fp, fn, P, R, F1 = prf_from_sets(pred_b, gold_b)\n",
    "        return pred_b, gold_b, tp, fp, fn, P, R, F1\n",
    "\n",
    "    _, gold_b, tp, fp, fn, P, R, F1 = best\n",
    "    return pred_b, gold_b, tp, fp, fn, P, R, F1\n",
    "\n",
    "def is_correct_prediction(predicted, gold_variants):\n",
    "    \"\"\"Check if predicted segmentation matches any gold variant.\"\"\"\n",
    "    return any(predicted == variant for variant in gold_variants)\n",
    "\n",
    "def normalize_gold_variants(gold_variants):\n",
    "    \"\"\"Convert gold_variants to proper list format.\"\"\"\n",
    "    if gold_variants is None:\n",
    "        return []\n",
    "    if isinstance(gold_variants, np.ndarray):\n",
    "        gold_variants = gold_variants.tolist()\n",
    "    if isinstance(gold_variants, list):\n",
    "        normalized = []\n",
    "        for variant in gold_variants:\n",
    "            if isinstance(variant, np.ndarray):\n",
    "                normalized.append(variant.tolist())\n",
    "            elif isinstance(variant, list):\n",
    "                normalized.append([item.tolist() if isinstance(item, np.ndarray) else item for item in variant])\n",
    "            else:\n",
    "                normalized.append(variant)\n",
    "        return normalized\n",
    "    return []\n",
    "\n",
    "def split_count_metrics(predicted_segments, gold_variants):\n",
    "    \"\"\"Compute split-count accuracy variants.\"\"\"\n",
    "    pred_count = len(predicted_segments)\n",
    "    gold_counts = [len(gold) for gold in gold_variants]\n",
    "\n",
    "    exact = any(pred_count == g for g in gold_counts)\n",
    "    plus1 = any(pred_count == g + 1 for g in gold_counts)\n",
    "    minus1 = any(pred_count == g - 1 for g in gold_counts)\n",
    "    pm1 = any(abs(pred_count - g) <= 1 for g in gold_counts)\n",
    "\n",
    "    return {\"Exact\": exact, \"+1\": plus1, \"-1\": minus1, \"±1\": pm1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b204ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test data...\n",
      "loaded 913 test examples\n",
      "loaded checkpoint from models_segmenter\\df7336ba5b7b6893\n",
      "model loaded for evaluation\n",
      "exact segmentation accuracy: 0.5608\n",
      "boundary metrics (token space):\n",
      "  micro  - P: 0.8194  R: 0.8619  F1: 0.8401\n",
      "  macro  - P: 0.8257  R: 0.8471  F1: 0.8196\n",
      "\n",
      "=== split-count metrics ===\n",
      "split-count (exact):          0.6605\n",
      "split-count (+1):             0.1873\n",
      "split-count (−1):             0.1281\n",
      "split-count (±1):             0.9748\n",
      "overlap (exact ∩ split):      0.5608\n",
      "\n",
      "evaluation results saved to data\\bilstm_grapheme_eval_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "print(\"loading test data...\")\n",
    "df = pd.read_parquet(os.path.join(DATA_FOLDER, \"cleaned_data_df.parquet\"))\n",
    "print(f\"loaded {len(df):,} test examples\")\n",
    "\n",
    "# Load trained model\n",
    "EMB_DIM = 64\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.1\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "model_id = generate_model_id(EMB_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT, EPOCHS, BATCH_SIZE, LR, WEIGHT_DECAY)\n",
    "\n",
    "loaded = load_model_checkpoint(model_id, models_folder=MODELS_FOLDER)\n",
    "if loaded is None:\n",
    "    raise FileNotFoundError(f\"model checkpoint not found (model_id: {model_id})\")\n",
    "\n",
    "stoi, itos = loaded[\"stoi\"], loaded[\"itos\"]\n",
    "model = BiLSTMBoundary(vocab_size=len(itos), emb_dim=EMB_DIM, hidden_size=HIDDEN_SIZE,\n",
    "                       num_layers=NUM_LAYERS, dropout=DROPOUT)\n",
    "model.load_state_dict(loaded[\"model_state\"])\n",
    "model.eval()\n",
    "print(\"model loaded for evaluation\")\n",
    "\n",
    "# Evaluate on test set\n",
    "all_words = df[\"Word\"].tolist()\n",
    "all_boundaries = predict_boundaries(all_words, model, stoi, threshold=0.5, device='cpu')\n",
    "\n",
    "records = []\n",
    "micro_tp = micro_fp = micro_fn = 0\n",
    "macro_Ps, macro_Rs, macro_F1s = [], [], []\n",
    "\n",
    "for word, gold_variants, boundary_labels in zip(all_words, df[\"Gold\"], all_boundaries):\n",
    "    gold_variants = normalize_gold_variants(gold_variants)\n",
    "\n",
    "    toks = to_graphemes_quechua(word)\n",
    "    predicted_segments = apply_boundaries_tokens(toks, boundary_labels)\n",
    "\n",
    "    correct_exact = is_correct_prediction(predicted_segments, gold_variants)\n",
    "\n",
    "    pred_b, gold_b_chosen, tp, fp, fn, P, R, F1 = best_variant_metrics_token_space(\n",
    "        toks, boundary_labels, gold_variants\n",
    "    )\n",
    "\n",
    "    records.append({\n",
    "        \"Word\": word,\n",
    "        \"Prediction\": predicted_segments,\n",
    "        \"Gold\": gold_variants,\n",
    "        \"PredBoundaries(tok_idx)\": sorted(pred_b),\n",
    "        \"GoldBoundaries(Chosen tok_idx)\": sorted(gold_b_chosen),\n",
    "        \"TP\": tp, \"FP\": fp, \"FN\": fn,\n",
    "        \"P_word\": P, \"R_word\": R, \"F1_word\": F1,\n",
    "        \"CorrectExactSeg\": correct_exact\n",
    "    })\n",
    "\n",
    "    micro_tp += tp\n",
    "    micro_fp += fp\n",
    "    micro_fn += fn\n",
    "    macro_Ps.append(P)\n",
    "    macro_Rs.append(R)\n",
    "    macro_F1s.append(F1)\n",
    "\n",
    "results_df = pd.DataFrame(records)\n",
    "\n",
    "accuracy = results_df[\"CorrectExactSeg\"].mean()\n",
    "\n",
    "if micro_tp + micro_fp == 0:\n",
    "    P_micro = 1.0 if micro_tp + micro_fn == 0 else 0.0\n",
    "else:\n",
    "    P_micro = micro_tp / (micro_tp + micro_fp)\n",
    "\n",
    "if micro_tp + micro_fn == 0:\n",
    "    R_micro = 1.0 if micro_tp + micro_fp == 0 else 0.0\n",
    "else:\n",
    "    R_micro = micro_tp / (micro_tp + micro_fn)\n",
    "\n",
    "if P_micro + R_micro == 0:\n",
    "    F1_micro = 1.0 if (micro_tp + micro_fp + micro_fn) == 0 else 0.0\n",
    "else:\n",
    "    F1_micro = 2 * P_micro * R_micro / (P_micro + R_micro)\n",
    "\n",
    "P_macro = float(pd.Series(macro_Ps).mean()) if macro_Ps else 0.0\n",
    "R_macro = float(pd.Series(macro_Rs).mean()) if macro_Rs else 0.0\n",
    "F1_macro = float(pd.Series(macro_F1s).mean()) if macro_F1s else 0.0\n",
    "\n",
    "print(f\"exact segmentation accuracy: {accuracy:.4f}\")\n",
    "print(\"boundary metrics (token space):\")\n",
    "print(f\"  micro  - P: {P_micro:.4f}  R: {R_micro:.4f}  F1: {F1_micro:.4f}\")\n",
    "print(f\"  macro  - P: {P_macro:.4f}  R: {R_macro:.4f}  F1: {F1_macro:.4f}\")\n",
    "\n",
    "# Split-count metrics\n",
    "split_exact_flags = []\n",
    "split_plus1_flags = []\n",
    "split_minus1_flags = []\n",
    "split_pm1_flags = []\n",
    "overlap_flags = []\n",
    "\n",
    "for rec in records:\n",
    "    predicted_segments = rec[\"Prediction\"]\n",
    "    gold_variants = rec[\"Gold\"]\n",
    "    gold_variants = normalize_gold_variants(gold_variants)\n",
    "\n",
    "    split_metrics = split_count_metrics(predicted_segments, gold_variants)\n",
    "    rec[\"CorrectSplitCount\"] = split_metrics[\"Exact\"]\n",
    "    rec[\"SplitCount+1\"] = split_metrics[\"+1\"]\n",
    "    rec[\"SplitCount-1\"] = split_metrics[\"-1\"]\n",
    "    rec[\"SplitCount±1\"] = split_metrics[\"±1\"]\n",
    "\n",
    "    overlap = rec[\"CorrectExactSeg\"] and split_metrics[\"Exact\"]\n",
    "    rec[\"OverlapExactAndSplit\"] = overlap\n",
    "\n",
    "    split_exact_flags.append(split_metrics[\"Exact\"])\n",
    "    split_plus1_flags.append(split_metrics[\"+1\"])\n",
    "    split_minus1_flags.append(split_metrics[\"-1\"])\n",
    "    split_pm1_flags.append(split_metrics[\"±1\"])\n",
    "    overlap_flags.append(overlap)\n",
    "\n",
    "split_exact_acc = np.mean(split_exact_flags)\n",
    "split_plus1_acc = np.mean(split_plus1_flags)\n",
    "split_minus1_acc = np.mean(split_minus1_flags)\n",
    "split_pm1_acc = np.mean(split_pm1_flags)\n",
    "overlap_accuracy = np.mean(overlap_flags)\n",
    "\n",
    "print(\"\\n=== split-count metrics ===\")\n",
    "print(f\"split-count (exact):          {split_exact_acc:.4f}\")\n",
    "print(f\"split-count (+1):             {split_plus1_acc:.4f}\")\n",
    "print(f\"split-count (−1):             {split_minus1_acc:.4f}\")\n",
    "print(f\"split-count (±1):             {split_pm1_acc:.4f}\")\n",
    "print(f\"overlap (exact ∩ split):      {overlap_accuracy:.4f}\")\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(records)\n",
    "results_output_path = os.path.join(DATA_FOLDER, \"bilstm_grapheme_eval_results.csv\")\n",
    "results_df.to_csv(results_output_path, index=False)\n",
    "print(f\"\\nevaluation results saved to {results_output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
